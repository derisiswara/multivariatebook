[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"code version Quantitative Methods RStudio: Application Management Business Research, book released 2024 IPB Press. book written Muhammad Firdaus, Farit M Afendi, Deri Siswara, Nafisa Berliana Indah Pratiwi. can order full version , includes detailed explanations.Management quantitative analysis widely utilized students, lecturers, researchers Indonesia. book aims enhance reputation education research country presenting variety alternative analysis tools commonly used. Managers must accurately synthesize information decision-making process prioritize various options precisely. Additionally, large volumes transformed data customer identities characteristics consumer behavior survey results need synthesized properly.first chapter introduces RStudio software R programming language, second chapter focuses nonparametric statistical analysis including correlation analysis two nonparametric variables causality relationships. Chapter three discusses logistic regression analysis making practical decisions, followed discriminant analysis chapter four models problems involving one dependent variable influenced multiple independent variables.Chapter five covers principal component analysis (PCA) biplots reduce large selection research variables compact dimensions. Chapter six delves cluster analysis useful mapping multiple entities whereas chapter seven comprehensively discusses factor analysis along structural equation modeling (SEM), including PLS-SEM widely used various problems involving latent variables prosperity, loyalty, company performance.final chapter explores Analytic Hierarchy Process (AHP) aimed determining priority choices based hierarchical decision hierarchy using freely accessible RStudio software across methods presented book. Updates made frequently.book may contain bugs/errors readers can report Buku.rstudio.ipb@gmail.com","code":""},{"path":"basics-of-r.html","id":"basics-of-r","chapter":"1 Basics of R","heading":"1 Basics of R","text":"","code":""},{"path":"basics-of-r.html","id":"introduction","chapter":"1 Basics of R","heading":"1.1 Introduction","text":"","code":"\nA <- 2  \nA # Print A\n#> [1] 2\nA = 2\nA\n#> [1] 2\nB <- \"Halo Semua\"\nB\n#> [1] \"Halo Semua\"\na<-10 # Space is not sensitive but lettercase is sensitive.\nA\n#> [1] 2\na\n#> [1] 10\n# Arithmetic operation\nx <- 5\ny <- 3\nx + y     \n#> [1] 8\nx - y     \n#> [1] 2\nx * y     \n#> [1] 15\nx / y     \n#> [1] 1.666667\n# Logic operation\na <- TRUE\nb <- FALSE\na & b     \n#> [1] FALSE\na | b     \n#> [1] TRUE\n!a        \n#> [1] FALSE\nx <- 5\ny <- 3\nx > y     \n#> [1] TRUE\nx < y     \n#> [1] FALSE\nx == y    \n#> [1] FALSE\nx >= y    \n#> [1] TRUE\nx <= y    \n#> [1] FALSE"},{"path":"basics-of-r.html","id":"types-of-objects-in-r","chapter":"1 Basics of R","heading":"1.2 Types of Objects in R","text":"","code":""},{"path":"basics-of-r.html","id":"vector","chapter":"1 Basics of R","heading":"1.2.1 Vector","text":"","code":"\na1 <- c(2,4,7,3) # Numeric vector\na2 <- c(\"one\",\"two\",\"three\") # Character vector\na3 <- c(TRUE,TRUE,TRUE,FALSE,TRUE,FALSE) # Logical vector\na1\n#> [1] 2 4 7 3\na3[4]        \n#> [1] FALSE\na2[c(1,3)]   \n#> [1] \"one\"   \"three\"\na1[-1]       \n#> [1] 4 7 3\na1[2:4]      \n#> [1] 4 7 3\na <- c(1, 2, 3)\nb <- c(4, 5, 6)\nc <- c(a, b)      \nc                 \n#> [1] 1 2 3 4 5 6\nc[1:3]            \n#> [1] 1 2 3\nd <- a + b        \nd                 \n#> [1] 5 7 9\na4 <- 1:12 \nb1 <- matrix(a4,3,4)\nb2 <- matrix(a4,3,4,byrow=TRUE) \nb3 <- matrix(1:14,4,4)\n#> Warning in matrix(1:14, 4, 4): data length [14] is not a\n#> sub-multiple or multiple of the number of rows [4]\nb1\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    4    7   10\n#> [2,]    2    5    8   11\n#> [3,]    3    6    9   12\nb2\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    5    6    7    8\n#> [3,]    9   10   11   12\nb3\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    5    9   13\n#> [2,]    2    6   10   14\n#> [3,]    3    7   11    1\n#> [4,]    4    8   12    2\nb2[2,3]   \n#> [1] 7\nb2[1:2,]  \n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    5    6    7    8\nb2[c(1,3),-2] \n#>      [,1] [,2] [,3]\n#> [1,]    1    3    4\n#> [2,]    9   11   12\ndim(b2) \n#> [1] 3 4\nm1 <- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2, ncol = 3)\nm2 <- matrix(c(7, 8, 9, 10, 11, 12), nrow = 2, ncol = 3)\nm3 <- m1 + m2\nm3\n#>      [,1] [,2] [,3]\n#> [1,]    8   12   16\n#> [2,]   10   14   18\nm4 <- m1 %*% t(m2)\nm4\n#>      [,1] [,2]\n#> [1,]   89   98\n#> [2,]  116  128"},{"path":"basics-of-r.html","id":"factor","chapter":"1 Basics of R","heading":"1.2.2 Factor","text":"","code":"\na5 <- c(\"A\",\"B\",\"AB\",\"O\")\nd1 <- factor(a5) \nlevels(d1)\n#> [1] \"A\"  \"AB\" \"B\"  \"O\"\nlevels(d1) <- c(\"Darah A\",\"Darah AB\",\"Darah B\",\"Darah O\")\nd1\n#> [1] Darah A  Darah B  Darah AB Darah O \n#> Levels: Darah A Darah AB Darah B Darah O\na6 <- c(\"SMA\",\"SD\",\"SMP\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\")\nd5 <- factor(a6, levels=c(\"SD\",\"SMP\",\"SMA\")) # Skala pengukuran ordinal  \nlevels(d5) \n#> [1] \"SD\"  \"SMP\" \"SMA\"\nd5\n#>  [1] SMA SD  SMP SMA SMA SMA SMA SMA SMA SMA SMA SMA SMA\n#> Levels: SD SMP SMA"},{"path":"basics-of-r.html","id":"list","chapter":"1 Basics of R","heading":"1.2.3 List","text":"","code":"\na1; b2; d1\n#> [1] 2 4 7 3\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    5    6    7    8\n#> [3,]    9   10   11   12\n#> [1] Darah A  Darah B  Darah AB Darah O \n#> Levels: Darah A Darah AB Darah B Darah O\ne1 <- list(a1,b2,d1)\ne2 <- list(vect=a1,mat=b2,fac=d1) \ne1\n#> [[1]]\n#> [1] 2 4 7 3\n#> \n#> [[2]]\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    5    6    7    8\n#> [3,]    9   10   11   12\n#> \n#> [[3]]\n#> [1] Darah A  Darah B  Darah AB Darah O \n#> Levels: Darah A Darah AB Darah B Darah O\ne2\n#> $vect\n#> [1] 2 4 7 3\n#> \n#> $mat\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    5    6    7    8\n#> [3,]    9   10   11   12\n#> \n#> $fac\n#> [1] Darah A  Darah B  Darah AB Darah O \n#> Levels: Darah A Darah AB Darah B Darah O\ne1[[1]][2] \n#> [1] 4\ne2$fac \n#> [1] Darah A  Darah B  Darah AB Darah O \n#> Levels: Darah A Darah AB Darah B Darah O\ne2[2] \n#> $mat\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    5    6    7    8\n#> [3,]    9   10   11   12\nnames(e2)\n#> [1] \"vect\" \"mat\"  \"fac\""},{"path":"basics-of-r.html","id":"data-frame","chapter":"1 Basics of R","heading":"1.2.4 Data Frame","text":"","code":"\nAngka <- 11:15\nHuruf <- factor(LETTERS[6:10])\nf1 <- data.frame(Angka,Huruf)\nf1\n#>   Angka Huruf\n#> 1    11     F\n#> 2    12     G\n#> 3    13     H\n#> 4    14     I\n#> 5    15     J\nf1[1,2] \n#> [1] F\n#> Levels: F G H I J\nf1$Angka \n#> [1] 11 12 13 14 15\nf1[,\"Huruf\"] \n#> [1] F G H I J\n#> Levels: F G H I J\ncolnames(f1) \n#> [1] \"Angka\" \"Huruf\"\nstr(f1)\n#> 'data.frame':    5 obs. of  2 variables:\n#>  $ Angka: int  11 12 13 14 15\n#>  $ Huruf: Factor w/ 5 levels \"F\",\"G\",\"H\",\"I\",..: 1 2 3 4 5"},{"path":"basics-of-r.html","id":"data-frame-management","chapter":"1 Basics of R","heading":"1.3 Data Frame Management","text":"","code":"\ndata(iris) \nhead(iris) \n#>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#> 1          5.1         3.5          1.4         0.2  setosa\n#> 2          4.9         3.0          1.4         0.2  setosa\n#> 3          4.7         3.2          1.3         0.2  setosa\n#> 4          4.6         3.1          1.5         0.2  setosa\n#> 5          5.0         3.6          1.4         0.2  setosa\n#> 6          5.4         3.9          1.7         0.4  setosa\ntail(iris) \n#>     Sepal.Length Sepal.Width Petal.Length Petal.Width\n#> 145          6.7         3.3          5.7         2.5\n#> 146          6.7         3.0          5.2         2.3\n#> 147          6.3         2.5          5.0         1.9\n#> 148          6.5         3.0          5.2         2.0\n#> 149          6.2         3.4          5.4         2.3\n#> 150          5.9         3.0          5.1         1.8\n#>       Species\n#> 145 virginica\n#> 146 virginica\n#> 147 virginica\n#> 148 virginica\n#> 149 virginica\n#> 150 virginica\nstr(iris)\n#> 'data.frame':    150 obs. of  5 variables:\n#>  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n#>  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n#>  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n#>  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n#>  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ..."},{"path":"basics-of-r.html","id":"r-package","chapter":"1 Basics of R","heading":"1.3.1 R Package","text":"","code":"\n# install.packages(\"readxl\") - code to install R package\nlibrary(readxl)\n#> Warning: package 'readxl' was built under R version 4.2.3\n#install.packages(\"dplyr\")\nlibrary(dplyr)\n#> Warning: package 'dplyr' was built under R version 4.2.3\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union"},{"path":"basics-of-r.html","id":"data-management-with-dplyr","chapter":"1 Basics of R","heading":"1.3.2 Data Management With dplyr","text":"","code":"\nhead(iris)\n#>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#> 1          5.1         3.5          1.4         0.2  setosa\n#> 2          4.9         3.0          1.4         0.2  setosa\n#> 3          4.7         3.2          1.3         0.2  setosa\n#> 4          4.6         3.1          1.5         0.2  setosa\n#> 5          5.0         3.6          1.4         0.2  setosa\n#> 6          5.4         3.9          1.7         0.4  setosa\nirisbaru  <- mutate(iris, sepal2 = Sepal.Length + Sepal.Width)\nhead(irisbaru)\n#>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#> 1          5.1         3.5          1.4         0.2  setosa\n#> 2          4.9         3.0          1.4         0.2  setosa\n#> 3          4.7         3.2          1.3         0.2  setosa\n#> 4          4.6         3.1          1.5         0.2  setosa\n#> 5          5.0         3.6          1.4         0.2  setosa\n#> 6          5.4         3.9          1.7         0.4  setosa\n#>   sepal2\n#> 1    8.6\n#> 2    7.9\n#> 3    7.9\n#> 4    7.7\n#> 5    8.6\n#> 6    9.3\nirisetosa <- filter(iris, Species==\"setosa\")\nhead(irisetosa)\n#>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#> 1          5.1         3.5          1.4         0.2  setosa\n#> 2          4.9         3.0          1.4         0.2  setosa\n#> 3          4.7         3.2          1.3         0.2  setosa\n#> 4          4.6         3.1          1.5         0.2  setosa\n#> 5          5.0         3.6          1.4         0.2  setosa\n#> 6          5.4         3.9          1.7         0.4  setosa\nlevels(iris$Species)\n#> [1] \"setosa\"     \"versicolor\" \"virginica\"\nirisversicolor <- filter(iris, Species==\"setosa\"& Petal.Length==1.3)\nhead(irisversicolor)\n#>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#> 1          4.7         3.2          1.3         0.2  setosa\n#> 2          5.4         3.9          1.3         0.4  setosa\n#> 3          5.5         3.5          1.3         0.2  setosa\n#> 4          4.4         3.0          1.3         0.2  setosa\n#> 5          5.0         3.5          1.3         0.3  setosa\n#> 6          4.5         2.3          1.3         0.3  setosa\niris3 <- select(iris, Sepal.Length, Species)\nhead(iris3)\n#>   Sepal.Length Species\n#> 1          5.1  setosa\n#> 2          4.9  setosa\n#> 3          4.7  setosa\n#> 4          4.6  setosa\n#> 5          5.0  setosa\n#> 6          5.4  setosa\niris4 <- arrange(iris, Petal.Width)\nhead(iris4)\n#>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#> 1          4.9         3.1          1.5         0.1  setosa\n#> 2          4.8         3.0          1.4         0.1  setosa\n#> 3          4.3         3.0          1.1         0.1  setosa\n#> 4          5.2         4.1          1.5         0.1  setosa\n#> 5          4.9         3.6          1.4         0.1  setosa\n#> 6          5.1         3.5          1.4         0.2  setosa\niris4 <- arrange(iris, Species, desc(Petal.Width))\nhead(iris4)\n#>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#> 1          5.0         3.5          1.6         0.6  setosa\n#> 2          5.1         3.3          1.7         0.5  setosa\n#> 3          5.4         3.9          1.7         0.4  setosa\n#> 4          5.7         4.4          1.5         0.4  setosa\n#> 5          5.4         3.9          1.3         0.4  setosa\n#> 6          5.1         3.7          1.5         0.4  setosa\nnames(iris4)[1] <- \"length\" \nhead(iris4)\n#>   length Sepal.Width Petal.Length Petal.Width Species\n#> 1    5.0         3.5          1.6         0.6  setosa\n#> 2    5.1         3.3          1.7         0.5  setosa\n#> 3    5.4         3.9          1.7         0.4  setosa\n#> 4    5.7         4.4          1.5         0.4  setosa\n#> 5    5.4         3.9          1.3         0.4  setosa\n#> 6    5.1         3.7          1.5         0.4  setosa\nhead(iris4[,c(-1,-3)])\n#>   Sepal.Width Petal.Width Species\n#> 1         3.5         0.6  setosa\n#> 2         3.3         0.5  setosa\n#> 3         3.9         0.4  setosa\n#> 4         4.4         0.4  setosa\n#> 5         3.9         0.4  setosa\n#> 6         3.7         0.4  setosa\niris %>% group_by(Species) %>% summarise(rata2_Sepal.Width = mean(Sepal.Width))\n#> # A tibble: 3 × 2\n#>   Species    rata2_Sepal.Width\n#>   <fct>                  <dbl>\n#> 1 setosa                  3.43\n#> 2 versicolor              2.77\n#> 3 virginica               2.97"},{"path":"basics-of-r.html","id":"visualization","chapter":"1 Basics of R","heading":"1.4 Visualization","text":"","code":""},{"path":"basics-of-r.html","id":"histogram","chapter":"1 Basics of R","heading":"1.4.1 Histogram","text":"","code":"\nhist(iris$Sepal.Length)"},{"path":"basics-of-r.html","id":"box-plot","chapter":"1 Basics of R","heading":"1.4.2 Box Plot","text":"","code":"\nboxplot(iris$Sepal.Length)"},{"path":"basics-of-r.html","id":"barplot","chapter":"1 Basics of R","heading":"1.4.3 Barplot","text":"","code":"\ntable(iris$Species)\n#> \n#>     setosa versicolor  virginica \n#>         50         50         50\nbarplot(table(iris$Species))"},{"path":"basics-of-r.html","id":"pie-chart","chapter":"1 Basics of R","heading":"1.4.4 Pie Chart","text":"","code":"\npie(table(iris$Species))"},{"path":"basics-of-r.html","id":"scatter-plot","chapter":"1 Basics of R","heading":"1.4.5 Scatter Plot","text":"","code":"\nplot(iris$Sepal.Length,iris$Sepal.Width)\nplot(iris$Sepal.Length, iris$Sepal.Width, main = \"Sepal Length vs. Sepal Width\", \n     xlab = \"Sepal Length\", ylab = \"Sepal Width\", col = \"red\")"},{"path":"nonparametric-statistics.html","id":"nonparametric-statistics","chapter":"2 Nonparametric Statistics","heading":"2 Nonparametric Statistics","text":"","code":""},{"path":"nonparametric-statistics.html","id":"correlation","chapter":"2 Nonparametric Statistics","heading":"2.1 Correlation","text":"","code":"\n# Membuat data contoh\n# Membuat vektor untuk responden, X, dan Y\nX <- c(2, 1, 6, 11, 7, 11, 1, 12, 13, 13, 11)\nY <- c(9, 8, 16, 13, 11, 12, 7, 7, 13, 17, 10)\n\n# Membuat dataframe\ndataku <- data.frame(X = X, Y = Y)\n\n# Menampilkan data\ndataku\n#>     X  Y\n#> 1   2  9\n#> 2   1  8\n#> 3   6 16\n#> 4  11 13\n#> 5   7 11\n#> 6  11 12\n#> 7   1  7\n#> 8  12  7\n#> 9  13 13\n#> 10 13 17\n#> 11 11 10\n# Menggunakan fungsi cor.test untuk menghitung Tau-Kendall\ncor.test(dataku$X, dataku$Y, method = \"kendall\")\n#> Warning in cor.test.default(dataku$X, dataku$Y, method =\n#> \"kendall\"): Cannot compute exact p-value with ties\n#> \n#>  Kendall's rank correlation tau\n#> \n#> data:  dataku$X and dataku$Y\n#> z = 1.7529, p-value = 0.07962\n#> alternative hypothesis: true tau is not equal to 0\n#> sample estimates:\n#>       tau \n#> 0.4273658\n# Menggunakan fungsi cor.test untuk menghitung korelasi Spearman\ncor.test(dataku$X, dataku$Y, method = \"spearman\")\n#> Warning in cor.test.default(dataku$X, dataku$Y, method =\n#> \"spearman\"): Cannot compute exact p-value with ties\n#> \n#>  Spearman's rank correlation rho\n#> \n#> data:  dataku$X and dataku$Y\n#> S = 108.98, p-value = 0.1134\n#> alternative hypothesis: true rho is not equal to 0\n#> sample estimates:\n#>       rho \n#> 0.5046513"},{"path":"nonparametric-statistics.html","id":"chi-square-test","chapter":"2 Nonparametric Statistics","heading":"2.1.1 Chi-Square Test","text":"","code":"\n# Membuat data contoh\n# Data asli dalam bentuk tabel silang\nfrekuensi <- matrix(c(30, 21, 30, 19, 15, 35), nrow = 2)\nrownames(frekuensi) <- c(\"Kontrak\", \"Tetap\")\ncolnames(frekuensi) <- c(\"Rendah\", \"Sedang\", \"Tinggi\")\n\n# Inisiasi vektor kosong untuk menyimpan data\nStatus_Pegawai <- c()\nTingkat_Produktivitas <- c()\n\n# Mengulang setiap kombinasi sesuai dengan frekuensinya\nfor (i in 1:nrow(frekuensi)) {\n  for (j in 1:ncol(frekuensi)) {\n    Status_Pegawai <- c(Status_Pegawai, \n                        rep(rownames(frekuensi)[i],\n                            frekuensi[i, j]))\n    \n    Tingkat_Produktivitas <- c(Tingkat_Produktivitas, \n                               rep(colnames(frekuensi)[j], \n                                   frekuensi[i, j]))\n  }\n}\n\n# Membuat dataframe\ndataku2 <- data.frame(Status_Pegawai, \n                      Tingkat_Produktivitas)\n# Menampilkan data\nhead(dataku2)\n#>   Status_Pegawai Tingkat_Produktivitas\n#> 1        Kontrak                Rendah\n#> 2        Kontrak                Rendah\n#> 3        Kontrak                Rendah\n#> 4        Kontrak                Rendah\n#> 5        Kontrak                Rendah\n#> 6        Kontrak                Rendah\n# Transformasi menejadi factor\ndataku2$Status_Pegawai <- as.factor(dataku2$Status_Pegawai)\ndataku2$Tingkat_Produktivitas <- as.factor(dataku2$Tingkat_Produktivitas)\n\nsummary(dataku2)\n#>  Status_Pegawai Tingkat_Produktivitas\n#>  Kontrak:75     Rendah:51            \n#>  Tetap  :75     Sedang:49            \n#>                 Tinggi:50\n# Melakukan tabel kontingensi\ndataku2_kt <- table(dataku2$Status_Pegawai, dataku2$Tingkat_Produktivitas)\ndataku2_kt\n#>          \n#>           Rendah Sedang Tinggi\n#>   Kontrak     30     30     15\n#>   Tetap       21     19     35\n# Melakukan uji Chi-Square\nchisq.test(dataku2_kt)\n#> \n#>  Pearson's Chi-squared test\n#> \n#> data:  dataku2_kt\n#> X-squared = 12.058, df = 2, p-value = 0.002408"},{"path":"nonparametric-statistics.html","id":"difference-test","chapter":"2 Nonparametric Statistics","heading":"2.2 Difference Test","text":"","code":""},{"path":"nonparametric-statistics.html","id":"two-sample-test-independent","chapter":"2 Nonparametric Statistics","heading":"2.2.1 Two sample test (Independent)","text":"","code":""},{"path":"nonparametric-statistics.html","id":"mann-whitney-test","chapter":"2 Nonparametric Statistics","heading":"2.2.1.1 Mann-Whitney Test","text":"","code":"\n# Membuat data contoh\n# Vektor data untuk efisiensi pada skala besar dan kecil\nefisiensi_besar <- c(1.31, 1.25, 1.32, 1.3, 1.33, 1.31, 1.35, 1.34, 0.28, 1.34, 1.28)\nefisiensi_kecil <- c(1.21, 1.28, 1.32, 1.25, 1.27, 1.31, 1.26, 1.31, 1.24, 1.22)\nwilcox.test(efisiensi_besar, efisiensi_kecil)\n#> Warning in wilcox.test.default(efisiensi_besar,\n#> efisiensi_kecil): cannot compute exact p-value with ties\n#> \n#>  Wilcoxon rank sum test with continuity correction\n#> \n#> data:  efisiensi_besar and efisiensi_kecil\n#> W = 82.5, p-value = 0.05614\n#> alternative hypothesis: true location shift is not equal to 0"},{"path":"nonparametric-statistics.html","id":"chi-square-test-1","chapter":"2 Nonparametric Statistics","heading":"2.2.1.2 Chi-Square Test","text":"","code":""},{"path":"nonparametric-statistics.html","id":"more-than-two-sample-test-independent","chapter":"2 Nonparametric Statistics","heading":"2.2.2 More than two sample test (Independent)","text":"","code":""},{"path":"nonparametric-statistics.html","id":"kruskal-wallis-test","chapter":"2 Nonparametric Statistics","heading":"2.2.2.1 Kruskal-Wallis Test","text":"","code":"\n# Membuat data contoh\n# Membuat vektor untuk Industri A, B, dan C\nindustri_A <- c(2.33, 2.79, 3.01, 2.33, 1.22, 2.79, 1.9, 1.65)\nindustri_B <- c(2.33, 2.33, 2.79, 3.01, 1.99, 2.45)\nindustri_C <- c(1.06, 1.37, 1.09, 1.65, 1.44, 1.11) \n\n# Membuat vektor industri\nindustri <- c(rep(\"Industri A\", length(industri_A)), \n              rep(\"Industri B\", length(industri_B)), \n              rep(\"Industri C\", length(industri_C)))\n\n# Menggabungkan semua vektor value\nnilai <- c(industri_A, industri_B, industri_C)\n\n# Membuat data frame\ndataku4 <- data.frame(industri, nilai)\n\n# Menampilkan data frame\ndataku4$industri <- as.factor(dataku4$industri)\ndataku4\n#>      industri nilai\n#> 1  Industri A  2.33\n#> 2  Industri A  2.79\n#> 3  Industri A  3.01\n#> 4  Industri A  2.33\n#> 5  Industri A  1.22\n#> 6  Industri A  2.79\n#> 7  Industri A  1.90\n#> 8  Industri A  1.65\n#> 9  Industri B  2.33\n#> 10 Industri B  2.33\n#> 11 Industri B  2.79\n#> 12 Industri B  3.01\n#> 13 Industri B  1.99\n#> 14 Industri B  2.45\n#> 15 Industri C  1.06\n#> 16 Industri C  1.37\n#> 17 Industri C  1.09\n#> 18 Industri C  1.65\n#> 19 Industri C  1.44\n#> 20 Industri C  1.11\n# Uji kruskal wallis\nkruskal.test(nilai ~ industri, data = dataku4)\n#> \n#>  Kruskal-Wallis rank sum test\n#> \n#> data:  nilai by industri\n#> Kruskal-Wallis chi-squared = 10.619, df = 2, p-value\n#> = 0.004943\n# Post hoc kruskal-wallis - Uji Dun\n#installed.packages(\"FSA\")\nlibrary(FSA)\n#> Warning: package 'FSA' was built under R version 4.2.3\n#> ## FSA v0.9.5. See citation('FSA') if used in publication.\n#> ## Run fishR() for related website and fishR('IFAR') for related book.\ndunnTest(nilai ~ industri, data = dataku4)\n#> Dunn (1964) Kruskal-Wallis multiple comparison\n#>   p-values adjusted with the Holm method.\n#>                Comparison          Z     P.unadj      P.adj\n#> 1 Industri A - Industri B -0.6428883 0.520296550 0.52029655\n#> 2 Industri A - Industri C  2.6109139 0.009030062 0.01806012\n#> 3 Industri B - Industri C  3.0436533 0.002337243 0.00701173"},{"path":"nonparametric-statistics.html","id":"chi-square-test-2","chapter":"2 Nonparametric Statistics","heading":"2.2.2.2 Chi-Square Test","text":"","code":""},{"path":"nonparametric-statistics.html","id":"two-sample-test-dependent","chapter":"2 Nonparametric Statistics","heading":"2.2.3 Two sample test (Dependent)","text":"","code":""},{"path":"nonparametric-statistics.html","id":"sign-test","chapter":"2 Nonparametric Statistics","heading":"2.2.3.1 Sign Test","text":"Interpretation: https://www.geeksforgeeks.org/sign-test--r/","code":"\n# Membuat data contoh\n# Data Skor Kepuasan\nproduk_lama <- c(16, 15, 18, 16, 17, 18, 20, 15, 14, 16, 19, 17)\nproduk_baru <- c(18, 17, 16, 19, 17, 20, 18, 16, 15, 18, 20, 18)\n# Data Responden\nresponden <- c(1:12)\n# Membuat data frame\ndataku5 <- data.frame(Responden = c(rep(responden, 2)),\n                      Produk = factor(c(rep(\"Produk Lama\", length(produk_lama)), \n                                        rep(\"Produk Baru\", length(produk_baru)))),\n                      Skor_Kepuasan = c(produk_lama, produk_baru))\n# Menampilkan data frame\ndataku5\n#>    Responden      Produk Skor_Kepuasan\n#> 1          1 Produk Lama            16\n#> 2          2 Produk Lama            15\n#> 3          3 Produk Lama            18\n#> 4          4 Produk Lama            16\n#> 5          5 Produk Lama            17\n#> 6          6 Produk Lama            18\n#> 7          7 Produk Lama            20\n#> 8          8 Produk Lama            15\n#> 9          9 Produk Lama            14\n#> 10        10 Produk Lama            16\n#> 11        11 Produk Lama            19\n#> 12        12 Produk Lama            17\n#> 13         1 Produk Baru            18\n#> 14         2 Produk Baru            17\n#> 15         3 Produk Baru            16\n#> 16         4 Produk Baru            19\n#> 17         5 Produk Baru            17\n#> 18         6 Produk Baru            20\n#> 19         7 Produk Baru            18\n#> 20         8 Produk Baru            16\n#> 21         9 Produk Baru            15\n#> 22        10 Produk Baru            18\n#> 23        11 Produk Baru            20\n#> 24        12 Produk Baru            18\n# Menghitung perbedaan\ndiff <- dataku5[dataku5$Produk == 'Produk Baru', ]$Skor_Kepuasan - dataku5[dataku5$Produk == 'Produk Lama', ]$Skor_Kepuasan\n\n# Menghitung jumlah perbedaan yang positif\njumlah_positif <- sum(diff > 0)\n# Melakukan uji tanda\nbinom.test(jumlah_positif, length(diff), \n           p = 0.5, \n           alternative = \"two.sided\")\n#> \n#>  Exact binomial test\n#> \n#> data:  jumlah_positif and length(diff)\n#> number of successes = 9, number of trials = 12,\n#> p-value = 0.146\n#> alternative hypothesis: true probability of success is not equal to 0.5\n#> 95 percent confidence interval:\n#>  0.4281415 0.9451394\n#> sample estimates:\n#> probability of success \n#>                   0.75"},{"path":"nonparametric-statistics.html","id":"more-than-two-sample-test-dependent","chapter":"2 Nonparametric Statistics","heading":"2.2.4 More than two sample test (Dependent)","text":"","code":""},{"path":"nonparametric-statistics.html","id":"friedman-test","chapter":"2 Nonparametric Statistics","heading":"2.2.4.1 Friedman Test","text":"","code":"\n# Membuat data contoh\ndataku6 <- matrix(c(1.24,1.50,1.62,\n              1.71,1.85,2.05,\n              1.37,2.12,1.68,\n              2.53,1.87,2.62,\n              1.23,1.34,1.51,\n              1.94,2.33,2.86,\n              1.72,1.43,2.86), nrow = 7, byrow = TRUE,\n              dimnames = list(Person= as.character(1:7),\n              Obat = c(\"Obat A\",\"Obat B\",\"Obat C\")))\ndataku6\n#>       Obat\n#> Person Obat A Obat B Obat C\n#>      1   1.24   1.50   1.62\n#>      2   1.71   1.85   2.05\n#>      3   1.37   2.12   1.68\n#>      4   2.53   1.87   2.62\n#>      5   1.23   1.34   1.51\n#>      6   1.94   2.33   2.86\n#>      7   1.72   1.43   2.86\nfriedman.test(dataku6)\n#> \n#>  Friedman rank sum test\n#> \n#> data:  dataku6\n#> Friedman chi-squared = 8.8571, df = 2, p-value =\n#> 0.01193"},{"path":"nonparametric-statistics.html","id":"cochran-test","chapter":"2 Nonparametric Statistics","heading":"2.2.4.2 Cochran Test","text":"","code":"\n# Membuat data contoh\n## Input data\nresponden <- c(1:8)\nproduk_A <- c(\"Tidak\",\"Tidak\",\"Ya\",\"Ya\",\"Ya\",\"Tidak\",\"Tidak\",\"Tidak\")\nproduk_B <- c(\"Tidak\",\"Ya\",\"Ya\",\"Ya\",\"Tidak\",\"Tidak\",\"Ya\",\"Tidak\")\nproduk_C <- c(\"Ya\",\"Tidak\",\"Tidak\",\"Ya\",\"Tidak\",\"Ya\",\"Ya\",\"Tidak\")\ndataku7 <- data.frame(responden, produk_A, produk_B, produk_C)\ndataku7$produk_A <- as.factor(dataku7$produk_A)\ndataku7$produk_B <- as.factor(dataku7$produk_B)\ndataku7$produk_C <- as.factor(dataku7$produk_C)\ndataku7\n#>   responden produk_A produk_B produk_C\n#> 1         1    Tidak    Tidak       Ya\n#> 2         2    Tidak       Ya    Tidak\n#> 3         3       Ya       Ya    Tidak\n#> 4         4       Ya       Ya       Ya\n#> 5         5       Ya    Tidak    Tidak\n#> 6         6    Tidak    Tidak       Ya\n#> 7         7    Tidak       Ya       Ya\n#> 8         8    Tidak    Tidak    Tidak\ndataku7 <-ifelse(dataku7==\"Ya\", 1,0)\n#install.packages(\"nonpar\")\nlibrary(nonpar)\ncochrans.q(as.matrix(dataku7[,-1]), alpha = 0.05)\n#> \n#>  Cochran's Q Test \n#>  \n#>  H0: There is no difference in the effectiveness of treatments. \n#>  HA: There is a difference in the effectiveness of treatments. \n#>  \n#>  Q = 0.333333333333333 \n#>  \n#>  Degrees of Freedom = 2 \n#>  \n#>  Significance Level = 0.05 \n#>  The p-value is  0.846481724890614 \n#>   \n#> "},{"path":"logistic-regression.html","id":"logistic-regression","chapter":"3 Logistic Regression","heading":"3 Logistic Regression","text":"","code":""},{"path":"logistic-regression.html","id":"regresi-logistik-biner","chapter":"3 Logistic Regression","heading":"3.1 Regresi Logistik Biner","text":"","code":""},{"path":"logistic-regression.html","id":"data","chapter":"3 Logistic Regression","heading":"3.1.1 Data","text":"","code":"\ncredit <- read.csv(\"Data/credit.csv\")\nhead(credit[,1:5],10)\n#>    creditability account.balance duration credit.amount\n#> 1              1               1       18          1049\n#> 2              1               1        9          2799\n#> 3              1               2       12           841\n#> 4              1               1       12          2122\n#> 5              1               1       12          2171\n#> 6              1               1       10          2241\n#> 7              1               1        8          3398\n#> 8              1               1        6          1361\n#> 9              1               4       18          1098\n#> 10             1               2       24          3758\n#>    saving.balance\n#> 1               1\n#> 2               1\n#> 3               2\n#> 4               1\n#> 5               1\n#> 6               1\n#> 7               1\n#> 8               1\n#> 9               1\n#> 10              3\nstr(credit)\n#> 'data.frame':    1000 obs. of  14 variables:\n#>  $ creditability   : int  1 1 1 1 1 1 1 1 1 1 ...\n#>  $ account.balance : int  1 1 2 1 1 1 1 1 4 2 ...\n#>  $ duration        : int  18 9 12 12 12 10 8 6 18 24 ...\n#>  $ credit.amount   : int  1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ...\n#>  $ saving.balance  : int  1 1 2 1 1 1 1 1 1 3 ...\n#>  $ employment.year : int  2 3 4 3 3 2 4 2 1 1 ...\n#>  $ installment.rate: int  4 2 2 3 4 1 1 2 4 1 ...\n#>  $ marital.status  : int  2 3 2 3 3 3 3 3 2 2 ...\n#>  $ duration.address: int  4 2 4 2 4 3 4 4 4 4 ...\n#>  $ age             : int  21 36 23 39 38 48 39 40 65 23 ...\n#>  $ dependents      : int  1 2 1 2 1 2 1 2 1 1 ...\n#>  $ number.of.credit: int  1 2 1 2 2 2 2 1 2 1 ...\n#>  $ occupation      : int  3 3 2 2 2 2 2 2 1 1 ...\n#>  $ previous.credit : int  4 4 2 4 4 4 4 4 4 2 ...\nlibrary(dplyr)\n#> Warning: package 'dplyr' was built under R version 4.2.3\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\ncredit <- credit %>% mutate(across(-c(duration,\n                            credit.amount,\n                            age),as.factor))\nstr(credit)\n#> 'data.frame':    1000 obs. of  14 variables:\n#>  $ creditability   : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 2 2 2 2 ...\n#>  $ account.balance : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 1 2 1 1 1 1 1 4 2 ...\n#>  $ duration        : int  18 9 12 12 12 10 8 6 18 24 ...\n#>  $ credit.amount   : int  1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ...\n#>  $ saving.balance  : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 2 1 1 1 1 1 1 3 ...\n#>  $ employment.year : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 2 3 4 3 3 2 4 2 1 1 ...\n#>  $ installment.rate: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 4 2 2 3 4 1 1 2 4 1 ...\n#>  $ marital.status  : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 2 3 2 3 3 3 3 3 2 2 ...\n#>  $ duration.address: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 4 2 4 2 4 3 4 4 4 4 ...\n#>  $ age             : int  21 36 23 39 38 48 39 40 65 23 ...\n#>  $ dependents      : Factor w/ 2 levels \"1\",\"2\": 1 2 1 2 1 2 1 2 1 1 ...\n#>  $ number.of.credit: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 1 2 2 2 2 1 2 1 ...\n#>  $ occupation      : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 3 3 2 2 2 2 2 2 1 1 ...\n#>  $ previous.credit : Factor w/ 5 levels \"0\",\"1\",\"2\",\"3\",..: 5 5 3 5 5 5 5 5 5 3 ..."},{"path":"logistic-regression.html","id":"pemodelan","chapter":"3 Logistic Regression","heading":"3.1.2 Pemodelan","text":"","code":"\nlogreg1 <- glm(creditability~.,data=credit,family = \"binomial\")\nsummary(logreg1)\n#> \n#> Call:\n#> glm(formula = creditability ~ ., family = \"binomial\", data = credit)\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -2.5496  -0.7882   0.4288   0.7441   2.0738  \n#> \n#> Coefficients:\n#>                     Estimate Std. Error z value Pr(>|z|)\n#> (Intercept)        2.990e-01  8.942e-01   0.334 0.738097\n#> account.balance2   4.346e-01  2.013e-01   2.159 0.030852\n#> account.balance3   9.490e-01  3.602e-01   2.635 0.008421\n#> account.balance4   1.804e+00  2.222e-01   8.119 4.69e-16\n#> duration          -2.705e-02  8.818e-03  -3.068 0.002156\n#> credit.amount     -1.025e-04  4.161e-05  -2.465 0.013718\n#> saving.balance2    1.293e-01  2.701e-01   0.479 0.632222\n#> saving.balance3    4.144e-01  3.987e-01   1.039 0.298644\n#> saving.balance4    1.241e+00  5.032e-01   2.467 0.013629\n#> saving.balance5    8.811e-01  2.463e-01   3.577 0.000347\n#> employment.year2  -1.432e-01  4.109e-01  -0.348 0.727561\n#> employment.year3   2.530e-01  3.957e-01   0.639 0.522582\n#> employment.year4   7.646e-01  4.258e-01   1.796 0.072572\n#> employment.year5   2.386e-01  3.962e-01   0.602 0.547012\n#> installment.rate2 -2.841e-01  2.953e-01  -0.962 0.336089\n#> installment.rate3 -5.122e-01  3.217e-01  -1.592 0.111374\n#> installment.rate4 -9.279e-01  2.872e-01  -3.230 0.001236\n#> marital.status2    1.744e-01  3.742e-01   0.466 0.641255\n#> marital.status3    7.482e-01  3.670e-01   2.039 0.041468\n#> marital.status4    5.577e-01  4.371e-01   1.276 0.201928\n#> duration.address2 -7.104e-01  2.832e-01  -2.509 0.012122\n#> duration.address3 -5.443e-01  3.163e-01  -1.721 0.085314\n#> duration.address4 -4.386e-01  2.762e-01  -1.588 0.112244\n#> age                1.125e-02  8.468e-03   1.329 0.183990\n#> dependents2       -2.607e-01  2.387e-01  -1.092 0.274669\n#> number.of.credit2 -4.177e-01  2.315e-01  -1.805 0.071133\n#> number.of.credit3 -4.131e-01  5.951e-01  -0.694 0.487625\n#> number.of.credit4 -4.589e-01  9.908e-01  -0.463 0.643240\n#> occupation2       -8.953e-02  6.276e-01  -0.143 0.886557\n#> occupation3       -1.487e-01  6.048e-01  -0.246 0.805804\n#> occupation4        1.276e-02  6.087e-01   0.021 0.983277\n#> previous.credit1  -3.136e-01  5.178e-01  -0.606 0.544686\n#> previous.credit2   6.063e-01  4.149e-01   1.461 0.143896\n#> previous.credit3   8.090e-01  4.531e-01   1.785 0.074205\n#> previous.credit4   1.511e+00  4.169e-01   3.625 0.000288\n#>                      \n#> (Intercept)          \n#> account.balance2  *  \n#> account.balance3  ** \n#> account.balance4  ***\n#> duration          ** \n#> credit.amount     *  \n#> saving.balance2      \n#> saving.balance3      \n#> saving.balance4   *  \n#> saving.balance5   ***\n#> employment.year2     \n#> employment.year3     \n#> employment.year4  .  \n#> employment.year5     \n#> installment.rate2    \n#> installment.rate3    \n#> installment.rate4 ** \n#> marital.status2      \n#> marital.status3   *  \n#> marital.status4      \n#> duration.address2 *  \n#> duration.address3 .  \n#> duration.address4    \n#> age                  \n#> dependents2          \n#> number.of.credit2 .  \n#> number.of.credit3    \n#> number.of.credit4    \n#> occupation2          \n#> occupation3          \n#> occupation4          \n#> previous.credit1     \n#> previous.credit2     \n#> previous.credit3  .  \n#> previous.credit4  ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 1221.7  on 999  degrees of freedom\n#> Residual deviance:  956.0  on 965  degrees of freedom\n#> AIC: 1026\n#> \n#> Number of Fisher Scoring iterations: 5"},{"path":"logistic-regression.html","id":"odds-ratio","chapter":"3 Logistic Regression","heading":"3.1.3 Odds Ratio","text":"","code":"\nbeta = round(coef(logreg1),2)\nOR = round(exp(beta),2)\ncbind(beta, OR)\n#>                    beta   OR\n#> (Intercept)        0.30 1.35\n#> account.balance2   0.43 1.54\n#> account.balance3   0.95 2.59\n#> account.balance4   1.80 6.05\n#> duration          -0.03 0.97\n#> credit.amount      0.00 1.00\n#> saving.balance2    0.13 1.14\n#> saving.balance3    0.41 1.51\n#> saving.balance4    1.24 3.46\n#> saving.balance5    0.88 2.41\n#> employment.year2  -0.14 0.87\n#> employment.year3   0.25 1.28\n#> employment.year4   0.76 2.14\n#> employment.year5   0.24 1.27\n#> installment.rate2 -0.28 0.76\n#> installment.rate3 -0.51 0.60\n#> installment.rate4 -0.93 0.39\n#> marital.status2    0.17 1.19\n#> marital.status3    0.75 2.12\n#> marital.status4    0.56 1.75\n#> duration.address2 -0.71 0.49\n#> duration.address3 -0.54 0.58\n#> duration.address4 -0.44 0.64\n#> age                0.01 1.01\n#> dependents2       -0.26 0.77\n#> number.of.credit2 -0.42 0.66\n#> number.of.credit3 -0.41 0.66\n#> number.of.credit4 -0.46 0.63\n#> occupation2       -0.09 0.91\n#> occupation3       -0.15 0.86\n#> occupation4        0.01 1.01\n#> previous.credit1  -0.31 0.73\n#> previous.credit2   0.61 1.84\n#> previous.credit3   0.81 2.25\n#> previous.credit4   1.51 4.53"},{"path":"logistic-regression.html","id":"multikolineratitas","chapter":"3 Logistic Regression","heading":"3.1.4 Multikolineratitas","text":"","code":"\nlibrary(car)\n#> Warning: package 'car' was built under R version 4.2.3\n#> Loading required package: carData\n#> \n#> Attaching package: 'car'\n#> The following object is masked from 'package:dplyr':\n#> \n#>     recode\nvif(logreg1)\n#>                      GVIF Df GVIF^(1/(2*Df))\n#> account.balance  1.283532  3        1.042480\n#> duration         1.828834  1        1.352344\n#> credit.amount    2.284117  1        1.511330\n#> saving.balance   1.286469  4        1.031989\n#> employment.year  2.406179  4        1.116005\n#> installment.rate 1.443706  3        1.063114\n#> marital.status   1.439516  3        1.062599\n#> duration.address 1.502426  3        1.070201\n#> age              1.365556  1        1.168570\n#> dependents       1.177252  1        1.085012\n#> number.of.credit 2.060162  3        1.128020\n#> occupation       1.893863  3        1.112307\n#> previous.credit  2.136438  4        1.099541"},{"path":"logistic-regression.html","id":"akurasi","chapter":"3 Logistic Regression","heading":"3.1.5 Akurasi","text":"","code":"\npred_clas <- ifelse(logreg1$fitted.values > 0.5, 1, 0)\nconf_matrix <- table(credit$creditability, pred_clas)\nconf_matrix\n#>    pred_clas\n#>       0   1\n#>   0 145 155\n#>   1  68 632\npaste0(\"Akurasi Model:\")\n#> [1] \"Akurasi Model:\"\naccuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\naccuracy\n#> [1] 0.777"},{"path":"logistic-regression.html","id":"kebaikan-model","chapter":"3 Logistic Regression","heading":"3.1.6 Kebaikan Model","text":"","code":"\n#install.packages(\"performance\")\nlibrary(performance)\n#> Warning: package 'performance' was built under R version\n#> 4.2.3\n#Outliers\nperformance::check_outliers(logreg1)\n#> OK: No outliers detected.\n#> - Based on the following method and threshold: cook (0.8).\n#> - For variable: (Whole model)\n#Metrik\nperformance(logreg1)\n#> # Indices of model performance\n#> \n#> AIC      |     AICc |      BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n#> -----------------------------------------------------------------------------------------------------------\n#> 1025.995 | 1028.609 | 1197.767 |     0.254 | 0.395 | 0.995 |    0.478 |      -Inf |           0.001 | 0.687\n#Goodness Of Fit\nperformance_hosmer(logreg1)\n#> # Hosmer-Lemeshow Goodness-of-Fit Test\n#> \n#>   Chi-squared: 8.472\n#>            df: 8    \n#>       p-value: 0.389\n#> Summary: model seems to fit well."},{"path":"logistic-regression.html","id":"regresi-logistik-nominal-atau-multinominal","chapter":"3 Logistic Regression","heading":"3.2 Regresi Logistik Nominal atau Multinominal","text":"","code":""},{"path":"logistic-regression.html","id":"data-1","chapter":"3 Logistic Regression","heading":"3.2.1 Data","text":"","code":"\nlibrary(readxl)\n#> Warning: package 'readxl' was built under R version 4.2.3\nstudents <- read_excel(\"Data/students.xlsx\")\nhead(students,10)\n#> # A tibble: 10 × 6\n#>    gender ses    prog      read write  math\n#>    <chr>  <chr>  <chr>    <dbl> <dbl> <dbl>\n#>  1 female low    vocation    34    35    41\n#>  2 male   middle general     34    33    41\n#>  3 male   high   vocation    39    39    44\n#>  4 male   low    vocation    37    37    42\n#>  5 male   middle vocation    39    31    40\n#>  6 female high   general     42    36    42\n#>  7 male   middle vocation    31    36    46\n#>  8 male   middle vocation    50    31    40\n#>  9 female middle vocation    39    41    33\n#> 10 male   middle vocation    34    37    46\nstr(students)\n#> tibble [200 × 6] (S3: tbl_df/tbl/data.frame)\n#>  $ gender: chr [1:200] \"female\" \"male\" \"male\" \"male\" ...\n#>  $ ses   : chr [1:200] \"low\" \"middle\" \"high\" \"low\" ...\n#>  $ prog  : chr [1:200] \"vocation\" \"general\" \"vocation\" \"vocation\" ...\n#>  $ read  : num [1:200] 34 34 39 37 39 42 31 50 39 34 ...\n#>  $ write : num [1:200] 35 33 39 37 31 36 36 31 41 37 ...\n#>  $ math  : num [1:200] 41 41 44 42 40 42 46 40 33 46 ..."},{"path":"logistic-regression.html","id":"ubah-jadi-faktor","chapter":"3 Logistic Regression","heading":"3.2.2 Ubah jadi faktor","text":"","code":"\nlibrary(dplyr)\nstudents <- students %>% mutate(across(-c(read,write,math),as.factor))\nstudents$prog2 <- relevel(students$prog, ref = \"academic\")\nstr(students)\n#> tibble [200 × 7] (S3: tbl_df/tbl/data.frame)\n#>  $ gender: Factor w/ 2 levels \"female\",\"male\": 1 2 2 2 2 1 2 2 1 2 ...\n#>  $ ses   : Factor w/ 3 levels \"high\",\"low\",\"middle\": 2 3 1 2 3 1 3 3 3 3 ...\n#>  $ prog  : Factor w/ 3 levels \"academic\",\"general\",..: 3 2 3 3 3 2 3 3 3 3 ...\n#>  $ read  : num [1:200] 34 34 39 37 39 42 31 50 39 34 ...\n#>  $ write : num [1:200] 35 33 39 37 31 36 36 31 41 37 ...\n#>  $ math  : num [1:200] 41 41 44 42 40 42 46 40 33 46 ...\n#>  $ prog2 : Factor w/ 3 levels \"academic\",\"general\",..: 3 2 3 3 3 2 3 3 3 3 ...\ntable(students$ses, students$prog)\n#>         \n#>          academic general vocation\n#>   high         42       9        7\n#>   low          19      16       12\n#>   middle       44      20       31\ntable(students$gender, students$prog)\n#>         \n#>          academic general vocation\n#>   female       58      24       27\n#>   male         47      21       23"},{"path":"logistic-regression.html","id":"pemodelan-1","chapter":"3 Logistic Regression","heading":"3.2.3 Pemodelan","text":"","code":"\n#install.packages(\"nnet\")\nlibrary(nnet)\n#> Warning: package 'nnet' was built under R version 4.2.3\nlogmultinom <- multinom(prog2 ~ ses + gender + write + read, data = students)\n#> # weights:  21 (12 variable)\n#> initial  value 219.722458 \n#> iter  10 value 176.754587\n#> final  value 174.725397 \n#> converged\nsummary(logmultinom)\n#> Call:\n#> multinom(formula = prog2 ~ ses + gender + write + read, data = students)\n#> \n#> Coefficients:\n#>          (Intercept)    seslow sesmiddle gendermale\n#> general     2.621831 1.0038426 0.5651588  0.1273914\n#> vocation    6.505182 0.6239396 1.1539447 -0.3105237\n#>                write        read\n#> general  -0.02860308 -0.04730781\n#> vocation -0.08243508 -0.07108839\n#> \n#> Std. Errors:\n#>          (Intercept)    seslow sesmiddle gendermale\n#> general     1.434514 0.5323398 0.4713812  0.4137756\n#> vocation    1.524572 0.6200276 0.5231819  0.4414783\n#>               write       read\n#> general  0.02686316 0.02480868\n#> vocation 0.02793343 0.02752520\n#> \n#> Residual Deviance: 349.4508 \n#> AIC: 373.4508\nz <- summary(logmultinom)$coefficients/summary(logmultinom)$standard.errors\n# 2-tailed z test\np <- (1 - pnorm(abs(z), 0, 1)) * 2\np\n#>           (Intercept)     seslow  sesmiddle gendermale\n#> general  6.759775e-02 0.05933302 0.23055043  0.7581770\n#> vocation 1.982164e-05 0.31426675 0.02741006  0.4818237\n#>                write        read\n#> general  0.286980200 0.056532815\n#> vocation 0.003166173 0.009804037"},{"path":"logistic-regression.html","id":"odds-ratio-1","chapter":"3 Logistic Regression","heading":"3.2.4 Odds Ratio","text":"","code":"\nexp(coef(logmultinom))\n#>          (Intercept)   seslow sesmiddle gendermale\n#> general      13.7609 2.728747  1.759727   1.135862\n#> vocation    668.5973 1.866266  3.170676   0.733063\n#>              write      read\n#> general  0.9718021 0.9537938\n#> vocation 0.9208712 0.9313796"},{"path":"logistic-regression.html","id":"multikolineratitas-1","chapter":"3 Logistic Regression","heading":"3.2.5 Multikolineratitas","text":"","code":"\nlibrary(car)\nvif(logmultinom)\n#> Warning in vif.default(logmultinom): No intercept: vifs may\n#> not be sensible.\n#>             GVIF Df GVIF^(1/(2*Df))\n#> ses     6.640420  2        1.605273\n#> gender  2.650955  1        1.628175\n#> write  66.396002  1        8.148374\n#> read   53.940932  1        7.344449"},{"path":"logistic-regression.html","id":"akurasi-1","chapter":"3 Logistic Regression","heading":"3.2.6 Akurasi","text":"","code":"\ndf <- students[,c(\"ses\",\"gender\",\"write\",\"read\")]\n#install.packages(\"caret\")\nlibrary(caret)\n#> Warning: package 'caret' was built under R version 4.2.3\n#> Loading required package: ggplot2\n#> Warning: package 'ggplot2' was built under R version 4.2.3\n#> Loading required package: lattice\n#> Warning: package 'lattice' was built under R version 4.2.3\nprediksi <- predict(logmultinom, df, type = \"class\")\nconfusionMatrix(as.factor(prediksi), \n                students$prog2)\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction academic general vocation\n#>   academic       90      25       21\n#>   general         3       7        4\n#>   vocation       12      13       25\n#> \n#> Overall Statistics\n#>                                          \n#>                Accuracy : 0.61           \n#>                  95% CI : (0.5387, 0.678)\n#>     No Information Rate : 0.525          \n#>     P-Value [Acc > NIR] : 0.009485       \n#>                                          \n#>                   Kappa : 0.3094         \n#>                                          \n#>  Mcnemar's Test P-Value : 1.959e-05      \n#> \n#> Statistics by Class:\n#> \n#>                      Class: academic Class: general\n#> Sensitivity                   0.8571         0.1556\n#> Specificity                   0.5158         0.9548\n#> Pos Pred Value                0.6618         0.5000\n#> Neg Pred Value                0.7656         0.7957\n#> Prevalence                    0.5250         0.2250\n#> Detection Rate                0.4500         0.0350\n#> Detection Prevalence          0.6800         0.0700\n#> Balanced Accuracy             0.6865         0.5552\n#>                      Class: vocation\n#> Sensitivity                   0.5000\n#> Specificity                   0.8333\n#> Pos Pred Value                0.5000\n#> Neg Pred Value                0.8333\n#> Prevalence                    0.2500\n#> Detection Rate                0.1250\n#> Detection Prevalence          0.2500\n#> Balanced Accuracy             0.6667"},{"path":"logistic-regression.html","id":"kebaikan-model-1","chapter":"3 Logistic Regression","heading":"3.2.7 Kebaikan Model","text":"","code":"\nlogmultinom0 <- multinom(prog2 ~ 1, data = students)\n#> # weights:  6 (2 variable)\n#> initial  value 219.722458 \n#> final  value 204.096674 \n#> converged\n#install.packages(\"lmtest\")\nlibrary(lmtest)\n#> Loading required package: zoo\n#> Warning: package 'zoo' was built under R version 4.2.3\n#> \n#> Attaching package: 'zoo'\n#> The following objects are masked from 'package:base':\n#> \n#>     as.Date, as.Date.numeric\nlrtest(logmultinom0,logmultinom)\n#> Likelihood ratio test\n#> \n#> Model 1: prog2 ~ 1\n#> Model 2: prog2 ~ ses + gender + write + read\n#>   #Df  LogLik Df  Chisq Pr(>Chisq)    \n#> 1   2 -204.10                         \n#> 2  12 -174.72 10 58.743  6.263e-09 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"logistic-regression.html","id":"regresi-logistik-ordinal","chapter":"3 Logistic Regression","heading":"3.3 Regresi Logistik Ordinal","text":"","code":""},{"path":"logistic-regression.html","id":"data-2","chapter":"3 Logistic Regression","heading":"3.3.1 Data","text":"","code":"\ncrash <- read.csv(\"Data/crash.csv\")\nhead(crash,10)\n#>    Gender Location SeatBelt Respon\n#> 1  Female    Urban      Yes      1\n#> 2    Male    Urban      Yes      1\n#> 3    Male    Urban       No      1\n#> 4  Female    Urban       No      1\n#> 5    Male    Rural      Yes      1\n#> 6  Female    Rural      Yes      1\n#> 7    Male    Rural       No      1\n#> 8  Female    Rural       No      1\n#> 9  Female    Urban       No      3\n#> 10 Female    Rural       No      3\nlibrary(dplyr)\ncrash <- crash %>% mutate(across(-c(Respon),as.factor))\nstr(crash)\n#> 'data.frame':    80 obs. of  4 variables:\n#>  $ Gender  : Factor w/ 2 levels \"Female\",\"Male\": 1 2 2 1 2 1 2 1 1 1 ...\n#>  $ Location: Factor w/ 2 levels \"Rural\",\"Urban\": 2 2 2 2 1 1 1 1 2 1 ...\n#>  $ SeatBelt: Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 1 2 2 1 1 1 1 ...\n#>  $ Respon  : int  1 1 1 1 1 1 1 1 3 3 ...\ncrash$Respon <- ordered(crash$Respon, levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"))\nstr(crash)\n#> 'data.frame':    80 obs. of  4 variables:\n#>  $ Gender  : Factor w/ 2 levels \"Female\",\"Male\": 1 2 2 1 2 1 2 1 1 1 ...\n#>  $ Location: Factor w/ 2 levels \"Rural\",\"Urban\": 2 2 2 2 1 1 1 1 2 1 ...\n#>  $ SeatBelt: Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 1 2 2 1 1 1 1 ...\n#>  $ Respon  : Ord.factor w/ 5 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 1 1 1 1 1 1 1 1 3 3 ..."},{"path":"logistic-regression.html","id":"pemodelan-2","chapter":"3 Logistic Regression","heading":"3.3.2 Pemodelan","text":"","code":"\n#install.packages(\"MASS\")\nlibrary(MASS)\n#> Warning: package 'MASS' was built under R version 4.2.3\n#> \n#> Attaching package: 'MASS'\n#> The following object is masked from 'package:dplyr':\n#> \n#>     select\norderlog <- polr(Respon~., method='logistic',data=crash)\nsummary(orderlog)\n#> \n#> Re-fitting to get Hessian\n#> Call:\n#> polr(formula = Respon ~ ., data = crash, method = \"logistic\")\n#> \n#> Coefficients:\n#>                  Value Std. Error t value\n#> GenderMale    -0.05369     0.3974 -0.1351\n#> LocationUrban  0.05661     0.3958  0.1430\n#> SeatBeltYes   -0.31102     0.3974 -0.7827\n#> \n#> Intercepts:\n#>     Value   Std. Error t value\n#> 1|2 -1.5425  0.4450    -3.4664\n#> 2|3 -0.5523  0.4060    -1.3603\n#> 3|4  0.2649  0.3966     0.6678\n#> 4|5  1.2472  0.4264     2.9249\n#> \n#> Residual Deviance: 256.8444 \n#> AIC: 270.8444"},{"path":"logistic-regression.html","id":"odds-ratio-2","chapter":"3 Logistic Regression","heading":"3.3.3 Odds Ratio","text":"","code":"\nkoefisien<-coef(summary(orderlog)) \n#> \n#> Re-fitting to get Hessian\nexp(koefisien[,1])\n#>    GenderMale LocationUrban   SeatBeltYes           1|2 \n#>     0.9477303     1.0582414     0.7327004     0.2138542 \n#>           2|3           3|4           4|5 \n#>     0.5756362     1.3032362     3.4805710\n# menghitung pvalue\np <- pnorm(abs(koefisien[,\"t value\"]), lower.tail = FALSE)*2\n(ctabel<-cbind(round(koefisien,2), \"pvalue\"=round(p,3))) \n#>               Value Std. Error t value pvalue\n#> GenderMale    -0.05       0.40   -0.14  0.893\n#> LocationUrban  0.06       0.40    0.14  0.886\n#> SeatBeltYes   -0.31       0.40   -0.78  0.434\n#> 1|2           -1.54       0.44   -3.47  0.001\n#> 2|3           -0.55       0.41   -1.36  0.174\n#> 3|4            0.26       0.40    0.67  0.504\n#> 4|5            1.25       0.43    2.92  0.003"},{"path":"logistic-regression.html","id":"multikolineratitas-2","chapter":"3 Logistic Regression","heading":"3.3.4 Multikolineratitas","text":"","code":"\nlibrary(car)\nvif(orderlog)\n#> \n#> Re-fitting to get Hessian\n#>   Gender Location SeatBelt \n#> 1.002035 1.001265 1.001814"},{"path":"logistic-regression.html","id":"akurasi-2","chapter":"3 Logistic Regression","heading":"3.3.5 Akurasi","text":"","code":"\ndf <- crash[,1:3]\nprediksi <- predict(orderlog, df, type = \"class\")\nconfusionMatrix(as.factor(prediksi), \n                crash$Respon)\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  1  2  3  4  5\n#>          1 10  8  7  7  8\n#>          2  0  0  0  0  0\n#>          3  0  0  0  0  0\n#>          4  0  0  0  0  0\n#>          5  6  8  9  9  8\n#> \n#> Overall Statistics\n#>                                           \n#>                Accuracy : 0.225           \n#>                  95% CI : (0.1391, 0.3321)\n#>     No Information Rate : 0.2             \n#>     P-Value [Acc > NIR] : 0.3292          \n#>                                           \n#>                   Kappa : 0.0312          \n#>                                           \n#>  Mcnemar's Test P-Value : NA              \n#> \n#> Statistics by Class:\n#> \n#>                      Class: 1 Class: 2 Class: 3 Class: 4\n#> Sensitivity            0.6250      0.0      0.0      0.0\n#> Specificity            0.5312      1.0      1.0      1.0\n#> Pos Pred Value         0.2500      NaN      NaN      NaN\n#> Neg Pred Value         0.8500      0.8      0.8      0.8\n#> Prevalence             0.2000      0.2      0.2      0.2\n#> Detection Rate         0.1250      0.0      0.0      0.0\n#> Detection Prevalence   0.5000      0.0      0.0      0.0\n#> Balanced Accuracy      0.5781      0.5      0.5      0.5\n#>                      Class: 5\n#> Sensitivity               0.5\n#> Specificity               0.5\n#> Pos Pred Value            0.2\n#> Neg Pred Value            0.8\n#> Prevalence                0.2\n#> Detection Rate            0.1\n#> Detection Prevalence      0.5\n#> Balanced Accuracy         0.5"},{"path":"logistic-regression.html","id":"kebaikan-model-2","chapter":"3 Logistic Regression","heading":"3.3.6 Kebaikan Model","text":"","code":"\norderlog0 <-polr(Respon~1, method = \"logistic\", data = crash)\n#install.packages(\"lmtest\")\nlibrary(lmtest)\nlrtest(orderlog0,orderlog)\n#> Likelihood ratio test\n#> \n#> Model 1: Respon ~ 1\n#> Model 2: Respon ~ Gender + Location + SeatBelt\n#>   #Df  LogLik Df  Chisq Pr(>Chisq)\n#> 1   4 -128.75                     \n#> 2   7 -128.42  3 0.6657     0.8813"},{"path":"discriminant-analysis.html","id":"discriminant-analysis","chapter":"4 Discriminant Analysis","heading":"4 Discriminant Analysis","text":"","code":""},{"path":"discriminant-analysis.html","id":"analisis-diskriminan-dua-grup","chapter":"4 Discriminant Analysis","heading":"4.1 Analisis Diskriminan Dua Grup","text":"","code":""},{"path":"discriminant-analysis.html","id":"data-3","chapter":"4 Discriminant Analysis","heading":"4.1.1 Data","text":"","code":"\nlibrary(readxl)\n#> Warning: package 'readxl' was built under R version 4.2.3\npinjaman <- read_excel(\"Data/pinjaman.xlsx\")\nhead(pinjaman,10)\n#> # A tibble: 10 × 6\n#>       X1    X2    X3    X4    X5     Y\n#>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n#>  1    98    35    12     4     4     1\n#>  2    65    44     5     3     1     1\n#>  3    22    50     0     2     7     1\n#>  4    78    60    34     5     5     1\n#>  5    50    31     4     2     2     1\n#>  6    21    30     5     3     7     1\n#>  7    42    32    21     4    11     1\n#>  8    20    41    10     2     3     1\n#>  9    33    25     0     3     6     1\n#> 10    57    32     8     2     5     1\nstr(pinjaman)\n#> tibble [32 × 6] (S3: tbl_df/tbl/data.frame)\n#>  $ X1: num [1:32] 98 65 22 78 50 21 42 20 33 57 ...\n#>  $ X2: num [1:32] 35 44 50 60 31 30 32 41 25 32 ...\n#>  $ X3: num [1:32] 12 5 0 34 4 5 21 10 0 8 ...\n#>  $ X4: num [1:32] 4 3 2 5 2 3 4 2 3 2 ...\n#>  $ X5: num [1:32] 4 1 7 5 2 7 11 3 6 5 ...\n#>  $ Y : num [1:32] 1 1 1 1 1 1 1 1 1 1 ...\npinjaman$Y <- as.factor(pinjaman$Y)\nstr(pinjaman)\n#> tibble [32 × 6] (S3: tbl_df/tbl/data.frame)\n#>  $ X1: num [1:32] 98 65 22 78 50 21 42 20 33 57 ...\n#>  $ X2: num [1:32] 35 44 50 60 31 30 32 41 25 32 ...\n#>  $ X3: num [1:32] 12 5 0 34 4 5 21 10 0 8 ...\n#>  $ X4: num [1:32] 4 3 2 5 2 3 4 2 3 2 ...\n#>  $ X5: num [1:32] 4 1 7 5 2 7 11 3 6 5 ...\n#>  $ Y : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 2 2 2 2 ...\nlibrary(psych)\n#> Warning: package 'psych' was built under R version 4.2.3\npairs.panels(pinjaman[1:5],\n             gap = 0,\n             bg = c(\"red\", \"green\")[pinjaman$Y],\n             pch = 21)"},{"path":"discriminant-analysis.html","id":"pemodelan-linier","chapter":"4 Discriminant Analysis","heading":"4.1.2 Pemodelan Linier","text":"","code":"\nlibrary(MASS)\n#> Warning: package 'MASS' was built under R version 4.2.3\nmodellda1 <- lda(Y ~ X1 + X2 + X3 + X4 + X5, data=pinjaman)\nmodellda1\n#> Call:\n#> lda(Y ~ X1 + X2 + X3 + X4 + X5, data = pinjaman)\n#> \n#> Prior probabilities of groups:\n#>      0      1 \n#> 0.4375 0.5625 \n#> \n#> Group means:\n#>         X1       X2       X3       X4       X5\n#> 0 23.07143 26.78571 23.21429 3.428571 4.071429\n#> 1 44.33333 34.38889 11.72222 2.888889 4.500000\n#> \n#> Coefficients of linear discriminants:\n#>             LD1\n#> X1  0.037015853\n#> X2 -0.004820049\n#> X3 -0.043555291\n#> X4 -0.477408359\n#> X5 -0.008483836"},{"path":"discriminant-analysis.html","id":"uji-signifikansi-fungsi-diskriminan","chapter":"4 Discriminant Analysis","heading":"4.1.3 Uji Signifikansi Fungsi Diskriminan","text":"","code":"\nm <- manova(cbind(pinjaman$X1,pinjaman$X2,pinjaman$X3,\n                  pinjaman$X4,pinjaman$X5) ~ pinjaman$Y)\nsummary(m, test = 'Wilks')\n#>            Df   Wilks approx F num Df den Df  Pr(>F)  \n#> pinjaman$Y  1 0.62715   3.0915      5     26 0.02544 *\n#> Residuals  30                                         \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"discriminant-analysis.html","id":"akurasi-3","chapter":"4 Discriminant Analysis","heading":"4.1.4 Akurasi","text":"","code":"\np <- predict(modellda1, pinjaman)\nldahist(data = p$x, g = pinjaman$Y)\nlibrary(caret)\n#> Warning: package 'caret' was built under R version 4.2.3\n#> Loading required package: ggplot2\n#> Warning: package 'ggplot2' was built under R version 4.2.3\n#> \n#> Attaching package: 'ggplot2'\n#> The following objects are masked from 'package:psych':\n#> \n#>     %+%, alpha\n#> Loading required package: lattice\n#> Warning: package 'lattice' was built under R version 4.2.3\nconfusionMatrix(p$class,pinjaman$Y)\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  0  1\n#>          0  9  4\n#>          1  5 14\n#>                                           \n#>                Accuracy : 0.7188          \n#>                  95% CI : (0.5325, 0.8625)\n#>     No Information Rate : 0.5625          \n#>     P-Value [Acc > NIR] : 0.0523          \n#>                                           \n#>                   Kappa : 0.424           \n#>                                           \n#>  Mcnemar's Test P-Value : 1.0000          \n#>                                           \n#>             Sensitivity : 0.6429          \n#>             Specificity : 0.7778          \n#>          Pos Pred Value : 0.6923          \n#>          Neg Pred Value : 0.7368          \n#>              Prevalence : 0.4375          \n#>          Detection Rate : 0.2812          \n#>    Detection Prevalence : 0.4062          \n#>       Balanced Accuracy : 0.7103          \n#>                                           \n#>        'Positive' Class : 0               \n#> \nmean(p$class==pinjaman$Y)\n#> [1] 0.71875\n#install.packages(\"klaR\")\nlibrary(klaR)\n#> Warning: package 'klaR' was built under R version 4.2.3\n#Partition plot\npartimat(Y~., data = pinjaman, method = \"lda\")\npartimat(Y~., data = pinjaman, method = \"qda\")"},{"path":"discriminant-analysis.html","id":"pemodelan-quadratik","chapter":"4 Discriminant Analysis","heading":"4.1.5 Pemodelan Quadratik","text":"","code":"\nmodellda2 <- qda(Y ~ X1 + X2 + X3 + X4 + X5, data=pinjaman)\nmodellda2\n#> Call:\n#> qda(Y ~ X1 + X2 + X3 + X4 + X5, data = pinjaman)\n#> \n#> Prior probabilities of groups:\n#>      0      1 \n#> 0.4375 0.5625 \n#> \n#> Group means:\n#>         X1       X2       X3       X4       X5\n#> 0 23.07143 26.78571 23.21429 3.428571 4.071429\n#> 1 44.33333 34.38889 11.72222 2.888889 4.500000\np <- predict(modellda2, pinjaman)\nmean(p$class==pinjaman$Y)\n#> [1] 0.84375"},{"path":"discriminant-analysis.html","id":"tipe-diskriminan-lainnya","chapter":"4 Discriminant Analysis","heading":"4.1.6 Tipe Diskriminan Lainnya","text":"","code":"\n# Mixture discriminant analysis - MDA\n# install.packages(\"mda\")\nlibrary(mda)\n#> Warning: package 'mda' was built under R version 4.2.3\n#> Loading required package: class\n#> Warning: package 'class' was built under R version 4.2.3\n#> Loaded mda 0.5-4\nmodellda3 <- mda(Y ~ X1 + X2 + X3 + X4 + X5, data=pinjaman)\np <- predict(modellda3, pinjaman)\nmean(p==pinjaman$Y)\n#> [1] 0.875\n# Flexible discriminant analysis - FDA\nmodellda4 <- fda(Y ~ X1 + X2 + X3 + X4 + X5, data=pinjaman)\np <- predict(modellda4, pinjaman)\nmean(p==pinjaman$Y)\n#> [1] 0.71875\n# Regularized discriminant analysis - RDA\nmodellda5 <- rda(Y ~ X1 + X2 + X3 + X4 + X5, data=pinjaman)\np <- predict(modellda5, pinjaman)\nmean(p$class==pinjaman$Y)\n#> [1] 0.75"},{"path":"discriminant-analysis.html","id":"analisis-diskriminan-tiga-grup","chapter":"4 Discriminant Analysis","heading":"4.2 Analisis Diskriminan Tiga Grup","text":"","code":""},{"path":"discriminant-analysis.html","id":"data-4","chapter":"4 Discriminant Analysis","heading":"4.2.1 Data","text":"","code":"\ndata(\"iris\")\nhead(iris)\n#>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#> 1          5.1         3.5          1.4         0.2  setosa\n#> 2          4.9         3.0          1.4         0.2  setosa\n#> 3          4.7         3.2          1.3         0.2  setosa\n#> 4          4.6         3.1          1.5         0.2  setosa\n#> 5          5.0         3.6          1.4         0.2  setosa\n#> 6          5.4         3.9          1.7         0.4  setosa\nstr(iris)\n#> 'data.frame':    150 obs. of  5 variables:\n#>  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n#>  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n#>  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n#>  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n#>  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\nlibrary(MASS)\nlda.iris <- lda(Species ~ ., iris)\nlda.iris \n#> Call:\n#> lda(Species ~ ., data = iris)\n#> \n#> Prior probabilities of groups:\n#>     setosa versicolor  virginica \n#>  0.3333333  0.3333333  0.3333333 \n#> \n#> Group means:\n#>            Sepal.Length Sepal.Width Petal.Length\n#> setosa            5.006       3.428        1.462\n#> versicolor        5.936       2.770        4.260\n#> virginica         6.588       2.974        5.552\n#>            Petal.Width\n#> setosa           0.246\n#> versicolor       1.326\n#> virginica        2.026\n#> \n#> Coefficients of linear discriminants:\n#>                     LD1         LD2\n#> Sepal.Length  0.8293776  0.02410215\n#> Sepal.Width   1.5344731  2.16452123\n#> Petal.Length -2.2012117 -0.93192121\n#> Petal.Width  -2.8104603  2.83918785\n#> \n#> Proportion of trace:\n#>    LD1    LD2 \n#> 0.9912 0.0088"},{"path":"discriminant-analysis.html","id":"uji-signifikansi-fungsi-diskriminan-1","chapter":"4 Discriminant Analysis","heading":"4.2.2 Uji Signifikansi Fungsi Diskriminan","text":"","code":"\nm <- manova(cbind(iris$Sepal.Length,iris$Sepal.Width,iris$Petal.Length,\n                  iris$Petal.Width) ~ iris$Species)\nsummary(m, test = 'Wilks')\n#>               Df    Wilks approx F num Df den Df    Pr(>F)\n#> iris$Species   2 0.023439   199.15      8    288 < 2.2e-16\n#> Residuals    147                                          \n#>                 \n#> iris$Species ***\n#> Residuals       \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"discriminant-analysis.html","id":"akurasi-4","chapter":"4 Discriminant Analysis","heading":"4.2.3 Akurasi","text":"","code":"\np <- predict(lda.iris, iris)\nldahist(data = p$x, g = iris$Species)\ntable(p$class,iris$Species)\n#>             \n#>              setosa versicolor virginica\n#>   setosa         50          0         0\n#>   versicolor      0         48         1\n#>   virginica       0          2        49\nmean(p$class==iris$Species)\n#> [1] 0.98"},{"path":"discriminant-analysis.html","id":"visualisasi","chapter":"4 Discriminant Analysis","heading":"4.2.4 Visualisasi","text":"","code":"\nlibrary(ggplot2)\nlda.data <- cbind(iris,  p$x)\nggplot(lda.data, aes(LD1, LD2)) +\n  geom_point(aes(color = Species)) + theme_classic()"},{"path":"discriminant-analysis.html","id":"pemodelan-quadratik-1","chapter":"4 Discriminant Analysis","heading":"4.2.5 Pemodelan Quadratik","text":"","code":"\nqda.iris <- qda(Species ~ ., data=iris)\nqda.iris\n#> Call:\n#> qda(Species ~ ., data = iris)\n#> \n#> Prior probabilities of groups:\n#>     setosa versicolor  virginica \n#>  0.3333333  0.3333333  0.3333333 \n#> \n#> Group means:\n#>            Sepal.Length Sepal.Width Petal.Length\n#> setosa            5.006       3.428        1.462\n#> versicolor        5.936       2.770        4.260\n#> virginica         6.588       2.974        5.552\n#>            Petal.Width\n#> setosa           0.246\n#> versicolor       1.326\n#> virginica        2.026\np <- predict(qda.iris, iris)\nmean(p$class==iris$Species)\n#> [1] 0.98"},{"path":"discriminant-analysis.html","id":"tipe-diskriminan-lainnya-1","chapter":"4 Discriminant Analysis","heading":"4.2.6 Tipe Diskriminan Lainnya","text":"","code":"\n# Mixture discriminant analysis - MDA\n# install.packages(\"mda\")\nlibrary(mda)\nmda.iris <- mda(Species ~ ., data=iris)\nmda.iris\n#> Call:\n#> mda(formula = Species ~ ., data = iris)\n#> \n#> Dimension: 4 \n#> \n#> Percent Between-Group Variance Explained:\n#>     v1     v2     v3     v4 \n#>  95.06  97.78  99.59 100.00 \n#> \n#> Degrees of Freedom (per dimension): 5 \n#> \n#> Training Misclassification Error: 0.01333 ( N = 150 )\n#> \n#> Deviance: 13.302\np <- predict(mda.iris, iris)\nmean(p==iris$Species)\n#> [1] 0.9866667\n# Flexible discriminant analysis - FDA\nfda.iris <- fda(Species ~ ., data=iris)\nfda.iris\n#> Call:\n#> fda(formula = Species ~ ., data = iris)\n#> \n#> Dimension: 2 \n#> \n#> Percent Between-Group Variance Explained:\n#>     v1     v2 \n#>  99.12 100.00 \n#> \n#> Degrees of Freedom (per dimension): 5 \n#> \n#> Training Misclassification Error: 0.02 ( N = 150 )\np <- predict(fda.iris, iris)\nmean(p==iris$Species)\n#> [1] 0.98\n# Regularized discriminant analysis - RDA\nrda.iris <- rda(Species ~ ., data=iris)\nrda.iris\n#> Call: \n#> rda(formula = Species ~ ., data = iris)\n#> \n#> Regularization parameters: \n#>     gamma    lambda \n#> 0.3041035 0.3917318 \n#> \n#> Prior probabilities of groups: \n#>     setosa versicolor  virginica \n#>  0.3333333  0.3333333  0.3333333 \n#> \n#> Misclassification rate: \n#>        apparent: 1.333 %\n#> cross-validated: 1.333 %\np <- predict(rda.iris, iris)\nmean(p$class==iris$Species)\n#> [1] 0.9866667"},{"path":"cluster-analysis.html","id":"cluster-analysis","chapter":"5 Cluster Analysis","heading":"5 Cluster Analysis","text":"","code":""},{"path":"cluster-analysis.html","id":"metode-berhirarki","chapter":"5 Cluster Analysis","heading":"5.1 Metode berhirarki","text":"Ref:\nhttps://rpubs.com/odenipinedo/cluster-analysis--R","code":"\nlibrary(readxl)\n#> Warning: package 'readxl' was built under R version 4.2.3\nProvinsi <- read_excel(\"Data/provinsi.xlsx\")\nProv.scaled = scale(Provinsi[,c(4:8)])\nrownames(Prov.scaled) = Provinsi$Provinsi\nhead(Prov.scaled)\n#>                IPM         UHH        RLS         PPK\n#> Aceh    0.20822137  0.04044611  0.7444782 -0.62264434\n#> Sumut   0.20085709 -0.39282591  1.0245728 -0.11277090\n#> Sumbar  0.36532598 -0.23835502  0.4747574  0.01481560\n#> Riau    0.50033775  0.59428078  0.5162529  0.19012890\n#> Jambi   0.05848104  0.50762638 -0.1165536 -0.18648754\n#> Sumsel -0.21890679 -0.08765171 -0.2825356 -0.02582306\n#>              Gini\n#> Aceh   -0.8089350\n#> Sumut  -0.6516207\n#> Sumbar -1.2546590\n#> Riau   -0.9138112\n#> Jambi  -0.6778397\n#> Sumsel  0.1349510\n## membuat dissimilarity matrix\ndprov = dist(Prov.scaled, method=\"euclidean\")\nc.comp = hclust(dprov, method = \"complete\")\ncor(dprov , cophenetic(c.comp))\n#> [1] 0.7853523\nc.sing = hclust(dprov, method = \"single\")\ncor(dprov , cophenetic(c.sing))\n#> [1] 0.7905858\nc.avrg = hclust(dprov, method = \"average\")\ncor(dprov , cophenetic(c.avrg))\n#> [1] 0.8092689\nc.ward = hclust(dprov, method = \"ward.D\")\ncor(dprov , cophenetic(c.ward))\n#> [1] 0.5336018\nc.ctrd = hclust(dprov, method = \"centroid\")\ncor(dprov , cophenetic(c.ctrd))\n#> [1] 0.7700878\nlibrary(factoextra)\n#> Loading required package: ggplot2\n#> Warning: package 'ggplot2' was built under R version 4.2.3\n#> Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\nfviz_dend(c.avrg, cex = 0.5, \n          main = \"Cluster Dendrogram average linkage\")\n#> Warning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use\n#> \"none\" instead as of ggplot2 3.3.4.\n#> ℹ The deprecated feature was likely used in the factoextra\n#>   package.\n#>   Please report the issue at\n#>   <https://github.com/kassambara/factoextra/issues>.\n#> This warning is displayed once every 8 hours.\n#> Call `lifecycle::last_lifecycle_warnings()` to see where\n#> this warning was generated.\navg_coph <- cophenetic(c.avrg)\navg_clust <- cutree(c.avrg, k = 4)\ntable(avg_clust)\n#> avg_clust\n#>  1  2  3  4 \n#> 26  1  1  6\nfviz_dend(c.avrg, k = 4, \n          k_colors = \"jco\", \n          rect = T, \n          main = \"Average Linkage Cluster\")\nlibrary(clValid)\n#> Warning: package 'clValid' was built under R version 4.2.3\n#> Loading required package: cluster\n#> Warning: package 'cluster' was built under R version 4.2.3\nlibrary(cluster)\n# internal measures\ninternal <- clValid(Prov.scaled, nClust = 2:6, \n                    clMethods = \"hierarchical\", \n                    validation = \"internal\", \n                    metric = \"euclidean\",\n                    method = \"average\")\nsummary(internal)\n#> \n#> Clustering Methods:\n#>  hierarchical \n#> \n#> Cluster sizes:\n#>  2 3 4 5 6 \n#> \n#> Validation Measures:\n#>                                  2       3       4       5       6\n#>                                                                   \n#> hierarchical Connectivity   4.5246 10.3012 11.6345 18.3198 24.1508\n#>              Dunn           0.3637  0.3703  0.3703  0.3224  0.3592\n#>              Silhouette     0.4915  0.3484  0.3092  0.2567  0.3117\n#> \n#> Optimal Scores:\n#> \n#>              Score  Method       Clusters\n#> Connectivity 4.5246 hierarchical 2       \n#> Dunn         0.3703 hierarchical 3       \n#> Silhouette   0.4915 hierarchical 2\nfviz_dend(c.avrg, k = 2, \n          k_colors = \"jco\", \n          rect = T, \n          main = \"Average Linkage Cluster\")\ngroup = cutree(c.avrg, k = 2)\ngroup\n#>      Aceh     Sumut    Sumbar      Riau     Jambi    Sumsel \n#>         1         1         1         1         1         1 \n#>  Bengkulu   Lampung     Babel     Kepri       DKI     Jabar \n#>         1         1         1         1         2         1 \n#>    Jateng       DIY     Jatim    Banten      Bali       NTB \n#>         1         2         1         1         1         1 \n#>       NTT    Kalbar   Kalteng    Kalsel    Kaltim   Kaltara \n#>         1         1         1         1         1         1 \n#>     Sulut   Sulteng    Sulsel    Sultra Gorontalo    Sulbar \n#>         1         1         1         1         1         1 \n#>    Maluku     Malut     Pabar     Papua \n#>         1         1         1         1\nfviz_cluster(list(data = Prov.scaled, \n                  cluster = group)) + \n  theme_minimal()\nprcomp(Prov.scaled)\n#> Standard deviations (1, .., p=5):\n#> [1] 1.7653705 1.0227284 0.7270850 0.5299864 0.1671984\n#> \n#> Rotation (n x k) = (5 x 5):\n#>             PC1         PC2          PC3           PC4\n#> IPM  -0.5601680 -0.05311199 -0.005227509 -0.0006949187\n#> UHH  -0.4513030  0.05646383 -0.811065327  0.2024129889\n#> RLS  -0.4591728 -0.33781331  0.497619343  0.5648220282\n#> PPK  -0.5069166  0.09086739  0.227624805 -0.7546468667\n#> Gini -0.1213811  0.93360390  0.206658283  0.2655422416\n#>              PC5\n#> IPM  -0.82665781\n#> UHH   0.30714735\n#> RLS   0.32923179\n#> PPK   0.33685862\n#> Gini  0.02073819"},{"path":"cluster-analysis.html","id":"metode-tidak-berhirarki---kmeans","chapter":"5 Cluster Analysis","heading":"5.2 Metode tidak berhirarki - kmeans","text":"","code":"\nfviz_nbclust(Prov.scaled, kmeans, method = \"wss\")\nfviz_nbclust(Prov.scaled, kmeans, method = \"silhouette\")\nset.seed(1)\nkm = kmeans(Prov.scaled, centers=4)\nkm\n#> K-means clustering with 4 clusters of sizes 5, 7, 16, 6\n#> \n#> Cluster means:\n#>           IPM        UHH        RLS         PPK       Gini\n#> 1  1.67223995  1.1202353  1.3689855  1.75840321  0.6331131\n#> 2  0.22785944  0.6620973 -0.1491572  0.09292014  0.9739608\n#> 3 -0.08819085 -0.1001318  0.1246391 -0.24567350 -0.7991029\n#> 4 -1.42419372 -1.4389581 -1.2991755 -0.91861351  0.4670591\n#> \n#> Clustering vector:\n#>      Aceh     Sumut    Sumbar      Riau     Jambi    Sumsel \n#>         3         3         3         3         3         3 \n#>  Bengkulu   Lampung     Babel     Kepri       DKI     Jabar \n#>         3         3         3         1         1         2 \n#>    Jateng       DIY     Jatim    Banten      Bali       NTB \n#>         2         1         2         2         1         4 \n#>       NTT    Kalbar   Kalteng    Kalsel    Kaltim   Kaltara \n#>         4         3         3         3         1         3 \n#>     Sulut   Sulteng    Sulsel    Sultra Gorontalo    Sulbar \n#>         2         3         2         2         4         4 \n#>    Maluku     Malut     Pabar     Papua \n#>         3         3         4         4 \n#> \n#> Within cluster sum of squares by cluster:\n#> [1] 17.054859  7.933134 22.111511  7.711994\n#>  (between_SS / total_SS =  66.8 %)\n#> \n#> Available components:\n#> \n#> [1] \"cluster\"      \"centers\"      \"totss\"       \n#> [4] \"withinss\"     \"tot.withinss\" \"betweenss\"   \n#> [7] \"size\"         \"iter\"         \"ifault\"\nfviz_cluster(list(data = Prov.scaled, cluster = km$cluster)) + theme_minimal()"},{"path":"pca-analysis-and-biplot.html","id":"pca-analysis-and-biplot","chapter":"6 PCA Analysis and Biplot","heading":"6 PCA Analysis and Biplot","text":"","code":""},{"path":"pca-analysis-and-biplot.html","id":"pca","chapter":"6 PCA Analysis and Biplot","heading":"6.1 PCA","text":"","code":"\n# impor data dari excel, beri nama: Provinsi\nlibrary(readxl)\n#> Warning: package 'readxl' was built under R version 4.2.3\nProvinsi = read_excel(\"Data/provinsi.xlsx\")\nProv.scaled = scale(Provinsi[,c(4:8)])\nround(cor(Prov.scaled),3)\n#>        IPM   UHH    RLS   PPK   Gini\n#> IPM  1.000 0.780  0.811 0.872  0.159\n#> UHH  0.780 1.000  0.447 0.581  0.153\n#> RLS  0.811 0.447  1.000 0.637 -0.059\n#> PPK  0.872 0.581  0.637 1.000  0.249\n#> Gini 0.159 0.153 -0.059 0.249  1.000\n# PCA langkah manual\nProv.eigen = eigen(cov(Prov.scaled))\nProv.eigen\n#> eigen() decomposition\n#> $values\n#> [1] 3.11653307 1.04597347 0.52865259 0.28088555 0.02795532\n#> \n#> $vectors\n#>            [,1]        [,2]         [,3]          [,4]\n#> [1,] -0.5601680 -0.05311199  0.005227509 -0.0006949187\n#> [2,] -0.4513030  0.05646383  0.811065327  0.2024129889\n#> [3,] -0.4591728 -0.33781331 -0.497619343  0.5648220282\n#> [4,] -0.5069166  0.09086739 -0.227624805 -0.7546468667\n#> [5,] -0.1213811  0.93360390 -0.206658283  0.2655422416\n#>             [,5]\n#> [1,]  0.82665781\n#> [2,] -0.30714735\n#> [3,] -0.32923179\n#> [4,] -0.33685862\n#> [5,] -0.02073819\nProv.eigen$values\n#> [1] 3.11653307 1.04597347 0.52865259 0.28088555 0.02795532\nProv.eigen$values/5\n#> [1] 0.623306615 0.209194694 0.105730518 0.056177109\n#> [5] 0.005591064\ncumsum(Prov.eigen$values/5)\n#> [1] 0.6233066 0.8325013 0.9382318 0.9944089 1.0000000\nProv.pc = as.matrix(Prov.scaled) %*% Prov.eigen$vectors\nround(Prov.pc,3)\n#>         [,1]   [,2]   [,3]   [,4]   [,5]\n#>  [1,] -0.063 -1.072 -0.028  0.684  0.141\n#>  [2,] -0.269 -0.998 -0.667  0.411  0.001\n#>  [3,] -0.170 -1.363 -0.172 -0.125  0.240\n#>  [4,] -0.771 -1.003  0.373  0.025  0.016\n#>  [5,] -0.032 -0.585  0.653 -0.002  0.008\n#>  [6,]  0.289  0.226  0.046 -0.122 -0.055\n#>  [7,]  0.167 -0.380 -0.246  0.160  0.149\n#>  [8,]  0.632 -0.498  0.644 -0.115 -0.054\n#>  [9,] -0.057 -1.798  0.675 -1.464 -0.089\n#> [10,] -2.171 -0.475 -1.111 -0.280 -0.100\n#> [11,] -5.201  0.488 -1.517 -0.455 -0.423\n#> [12,] -0.699  0.908  0.818  0.388 -0.141\n#> [13,] -0.467  0.567  1.901 -0.226 -0.064\n#> [14,] -3.637  1.770  0.377  0.349  0.361\n#> [15,] -0.211  1.726  0.527 -0.300  0.118\n#> [16,] -0.763  0.414 -0.365 -0.198  0.007\n#> [17,] -1.962  0.494  0.024 -0.719  0.052\n#> [18,]  1.779  0.864 -0.537 -0.824  0.322\n#> [19,]  2.630  0.251 -0.136  0.131  0.011\n#> [20,]  1.501 -0.351  1.137 -0.243 -0.049\n#> [21,]  0.004 -0.801  0.195 -0.277 -0.039\n#> [22,]  0.104 -0.191 -0.358 -0.828  0.030\n#> [23,] -2.225 -0.963  0.752  0.305  0.020\n#> [24,] -0.162 -1.278  1.179  0.698 -0.173\n#> [25,] -1.101  0.544 -0.154  0.823 -0.143\n#> [26,]  0.847 -0.438 -0.472  0.097  0.061\n#> [27,] -0.276  1.813 -0.105  0.254  0.105\n#> [28,] -0.147  0.982  0.109  0.925 -0.004\n#> [29,]  1.266  1.405 -0.356 -0.169  0.136\n#> [30,]  2.501 -0.280 -0.787 -0.540  0.062\n#> [31,]  0.929 -1.487 -1.397  0.735  0.080\n#> [32,]  1.193 -0.966 -0.326  0.739 -0.008\n#> [33,]  2.735  0.936 -0.533  0.218 -0.091\n#> [34,]  3.806  1.539 -0.145 -0.057 -0.487\n# dengan fungsi prcomp\npc = prcomp(x = Prov.scaled, center=TRUE, scale=TRUE)\nsummary(pc)\n#> Importance of components:\n#>                           PC1    PC2    PC3     PC4     PC5\n#> Standard deviation     1.7654 1.0227 0.7271 0.52999 0.16720\n#> Proportion of Variance 0.6233 0.2092 0.1057 0.05618 0.00559\n#> Cumulative Proportion  0.6233 0.8325 0.9382 0.99441 1.00000\nround(pc$x,3)#scores\n#>          PC1    PC2    PC3    PC4    PC5\n#>  [1,] -0.063 -1.072  0.028  0.684 -0.141\n#>  [2,] -0.269 -0.998  0.667  0.411 -0.001\n#>  [3,] -0.170 -1.363  0.172 -0.125 -0.240\n#>  [4,] -0.771 -1.003 -0.373  0.025 -0.016\n#>  [5,] -0.032 -0.585 -0.653 -0.002 -0.008\n#>  [6,]  0.289  0.226 -0.046 -0.122  0.055\n#>  [7,]  0.167 -0.380  0.246  0.160 -0.149\n#>  [8,]  0.632 -0.498 -0.644 -0.115  0.054\n#>  [9,] -0.057 -1.798 -0.675 -1.464  0.089\n#> [10,] -2.171 -0.475  1.111 -0.280  0.100\n#> [11,] -5.201  0.488  1.517 -0.455  0.423\n#> [12,] -0.699  0.908 -0.818  0.388  0.141\n#> [13,] -0.467  0.567 -1.901 -0.226  0.064\n#> [14,] -3.637  1.770 -0.377  0.349 -0.361\n#> [15,] -0.211  1.726 -0.527 -0.300 -0.118\n#> [16,] -0.763  0.414  0.365 -0.198 -0.007\n#> [17,] -1.962  0.494 -0.024 -0.719 -0.052\n#> [18,]  1.779  0.864  0.537 -0.824 -0.322\n#> [19,]  2.630  0.251  0.136  0.131 -0.011\n#> [20,]  1.501 -0.351 -1.137 -0.243  0.049\n#> [21,]  0.004 -0.801 -0.195 -0.277  0.039\n#> [22,]  0.104 -0.191  0.358 -0.828 -0.030\n#> [23,] -2.225 -0.963 -0.752  0.305 -0.020\n#> [24,] -0.162 -1.278 -1.179  0.698  0.173\n#> [25,] -1.101  0.544  0.154  0.823  0.143\n#> [26,]  0.847 -0.438  0.472  0.097 -0.061\n#> [27,] -0.276  1.813  0.105  0.254 -0.105\n#> [28,] -0.147  0.982 -0.109  0.925  0.004\n#> [29,]  1.266  1.405  0.356 -0.169 -0.136\n#> [30,]  2.501 -0.280  0.787 -0.540 -0.062\n#> [31,]  0.929 -1.487  1.397  0.735 -0.080\n#> [32,]  1.193 -0.966  0.326  0.739  0.008\n#> [33,]  2.735  0.936  0.533  0.218  0.091\n#> [34,]  3.806  1.539  0.145 -0.057  0.487\nround(pc$rotation,3)  #loadings\n#>         PC1    PC2    PC3    PC4    PC5\n#> IPM  -0.560 -0.053 -0.005 -0.001 -0.827\n#> UHH  -0.451  0.056 -0.811  0.202  0.307\n#> RLS  -0.459 -0.338  0.498  0.565  0.329\n#> PPK  -0.507  0.091  0.228 -0.755  0.337\n#> Gini -0.121  0.934  0.207  0.266  0.021\nplot(pc)\nscreeplot(x = pc, type=\"line\", main=\"Scree plot\")\n# korelasi variabel asli dengan PC\ndata = cbind(Prov.pc, Prov.scaled)\nkorelasi = cor(data)\nkorelasi[6:10,1:2]\n#>                            \n#> IPM  -0.9889040 -0.05431915\n#> UHH  -0.7967169  0.05774717\n#> RLS  -0.8106101 -0.34549128\n#> PPK  -0.8948956  0.09293267\n#> Gini -0.2142826  0.95482326"},{"path":"pca-analysis-and-biplot.html","id":"biplot","chapter":"6 PCA Analysis and Biplot","heading":"6.2 Biplot","text":"","code":"\n# biplot\nlibrary(factoextra)\n#> Loading required package: ggplot2\n#> Warning: package 'ggplot2' was built under R version 4.2.3\n#> Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\nfviz_pca(pc)\n# alternatif bentuk biplot\n# install.packages(\"remotes\")\n# remotes::install_github(\"vqv/ggbiplot\")\nlibrary(ggbiplot)\n#> Loading required package: plyr\n#> Warning: package 'plyr' was built under R version 4.2.3\n#> Loading required package: scales\n#> Warning: package 'scales' was built under R version 4.2.3\n#> Loading required package: grid\nggbiplot(pc)\nbiplot = ggbiplot(pcobj = pc,\n                  choices = c(1,2),\n                  obs.scale = 1, var.scale = 1,\n                  labels = row.names(Provinsi),\n                  varname.size = 3,\n                  varname.abbrev = FALSE,\n                  var.axes = TRUE,\n                  group = Provinsi$Region)\nbiplot\nbiplot2 = biplot + theme_bw() + \n  theme(legend.position=\"bottom\") + \n  labs(\n  title = \"PCA Indikator Kualitas Hidup Provinsi\", \n  color = \"Region\")\nbiplot2"},{"path":"factor-analysis-and-structural-equation-modeling-sem.html","id":"factor-analysis-and-structural-equation-modeling-sem","chapter":"7 Factor Analysis and Structural Equation Modeling (SEM)","heading":"7 Factor Analysis and Structural Equation Modeling (SEM)","text":"","code":""},{"path":"factor-analysis-and-structural-equation-modeling-sem.html","id":"analisis-faktor","chapter":"7 Factor Analysis and Structural Equation Modeling (SEM)","heading":"7.1 Analisis Faktor","text":"","code":"\nharga <- read.csv(\"Data/harga.csv\")\nhead(harga)\n#>          City Bread Burger Milk Oranges Tomatoes\n#> 1    Atlanta   24.5   94.5 73.9    80.1     41.6\n#> 2  Baltimore   26.5   91.0 67.5    74.6     33.3\n#> 3     Boston   29.7  100.8 61.4   104.0     59.6\n#> 4    Buffalo   22.8   86.6 65.3   118.4     61.2\n#> 5    Chicago   26.7   86.7 62.7   105.9     60.2\n#> 6 Cincinnati   25.3  102.5 63.3    99.3     45.6\nstr(harga)\n#> 'data.frame':    23 obs. of  6 variables:\n#>  $ City    : chr  \"Atlanta \" \"Baltimore \" \"Boston \" \"Buffalo \" ...\n#>  $ Bread   : num  24.5 26.5 29.7 22.8 26.7 25.3 22.8 23.3 24.1 29.3 ...\n#>  $ Burger  : num  94.5 91 100.8 86.6 86.7 ...\n#>  $ Milk    : num  73.9 67.5 61.4 65.3 62.7 63.3 52.4 62.5 51.5 80.2 ...\n#>  $ Oranges : num  80.1 74.6 104 118.4 105.9 ...\n#>  $ Tomatoes: num  41.6 33.3 59.6 61.2 60.2 45.6 60.1 60.8 60.5 71.7 ..."},{"path":"factor-analysis-and-structural-equation-modeling-sem.html","id":"efa","chapter":"7 Factor Analysis and Structural Equation Modeling (SEM)","heading":"7.1.1 EFA","text":"","code":"\nlibrary(corrplot)\n#> corrplot 0.92 loaded\ncorrplot(cor(harga[,2:6]), method=\"number\")\nlibrary(psych)\n#> Warning: package 'psych' was built under R version 4.2.3\nKMO(harga[,2:6])\n#> Kaiser-Meyer-Olkin factor adequacy\n#> Call: KMO(r = harga[, 2:6])\n#> Overall MSA =  0.52\n#> MSA for each item = \n#>    Bread   Burger     Milk  Oranges Tomatoes \n#>     0.52     0.58     0.59     0.49     0.48\n# Bartlett's Test of Sphericity\ncortest.bartlett(harga[,2:6])\n#> R was not square, finding R from data\n#> $chisq\n#> [1] 36.46285\n#> \n#> $p.value\n#> [1] 7.006877e-05\n#> \n#> $df\n#> [1] 10\n# Anti image correlation (AIC)\ncorrplot(KMO(harga[,2:6])$ImCo, method=\"number\") \n# Determinan positif\ndet(cor(harga[,2:6]))\n#> [1] 0.1541406\n# Principal component analysis (PCA)\npca1 = princomp(harga[,2:6], scores=TRUE, cor=TRUE)\nsummary(pca1)\n#> Importance of components:\n#>                           Comp.1    Comp.2    Comp.3\n#> Standard deviation     1.4841538 1.2325047 0.8824610\n#> Proportion of Variance 0.4405425 0.3038136 0.1557475\n#> Cumulative Proportion  0.4405425 0.7443561 0.9001036\n#>                            Comp.4     Comp.5\n#> Standard deviation     0.55357732 0.43935672\n#> Proportion of Variance 0.06128957 0.03860687\n#> Cumulative Proportion  0.96139313 1.00000000\nscree(harga[,2:6])\n# Menentukan faktor loading Analisis faktor loading\nloadings(pca1)\n#> \n#> Loadings:\n#>          Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\n#> Bread     0.436  0.484  0.354  0.597  0.306\n#> Burger    0.542  0.292  0.307 -0.657 -0.309\n#> Milk      0.346  0.308 -0.866        -0.163\n#> Oranges   0.410 -0.579  0.108  0.399 -0.571\n#> Tomatoes  0.478 -0.500 -0.137 -0.211  0.677\n#> \n#>                Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\n#> SS loadings       1.0    1.0    1.0    1.0    1.0\n#> Proportion Var    0.2    0.2    0.2    0.2    0.2\n#> Cumulative Var    0.2    0.4    0.6    0.8    1.0\n# Rotasi untuk mengkonfirmasi hasil analisis loading\nfa1 = factanal(harga[,2:6], factor=2, rotation=\"varimax\")\nfa1\n#> \n#> Call:\n#> factanal(x = harga[, 2:6], factors = 2, rotation = \"varimax\")\n#> \n#> Uniquenesses:\n#>    Bread   Burger     Milk  Oranges Tomatoes \n#>    0.239    0.318    0.830    0.420    0.005 \n#> \n#> Loadings:\n#>          Factor1 Factor2\n#> Bread             0.868 \n#> Burger    0.195   0.803 \n#> Milk      0.135   0.390 \n#> Oranges   0.756         \n#> Tomatoes  0.985   0.157 \n#> \n#>                Factor1 Factor2\n#> SS loadings      1.605   1.583\n#> Proportion Var   0.321   0.317\n#> Cumulative Var   0.321   0.638\n#> \n#> Test of the hypothesis that 2 factors are sufficient.\n#> The chi square statistic is 1.16 on 1 degree of freedom.\n#> The p-value is 0.282\n# Diagram jalur hasil analisis EFA dan menampilkan faktor loading-nya\nfa.diagram(fa1$loadings, digits = 3)"},{"path":"factor-analysis-and-structural-equation-modeling-sem.html","id":"cfa","chapter":"7 Factor Analysis and Structural Equation Modeling (SEM)","heading":"7.1.2 CFA","text":"","code":"\n# Spesifikasi model\nattach(harga)\nmodel1 <- \"\nF1 =~ Tomatoes + Oranges\nF2 =~ Bread + Burger + Milk\nF1 ~~ F2 \"\nlibrary(lavaan)\n#> Warning: package 'lavaan' was built under R version 4.2.3\n#> This is lavaan 0.6-17\n#> lavaan is FREE software! Please report any bugs.\n#> \n#> Attaching package: 'lavaan'\n#> The following object is masked from 'package:psych':\n#> \n#>     cor2cov\nfitmod = cfa(model1, data = harga)\n#> Warning in lav_object_post_check(object): lavaan WARNING:\n#> some estimated ov variances are negative\nsummary(fitmod, fit.measures = TRUE, standardized = TRUE)\n#> lavaan 0.6.17 ended normally after 85 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        11\n#> \n#>   Number of observations                            23\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 3.642\n#>   Degrees of freedom                                 4\n#>   P-value (Chi-square)                           0.457\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                                43.007\n#>   Degrees of freedom                                10\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    1.000\n#>   Tucker-Lewis Index (TLI)                       1.027\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)               -367.812\n#>   Loglikelihood unrestricted model (H1)       -365.991\n#>                                                       \n#>   Akaike (AIC)                                 757.623\n#>   Bayesian (BIC)                               770.114\n#>   Sample-size adjusted Bayesian (SABIC)        736.072\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.000\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.302\n#>   P-value H_0: RMSEA <= 0.050                    0.487\n#>   P-value H_0: RMSEA >= 0.080                    0.469\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.065\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   F1 =~                                               \n#>     Tomatoes          1.000                           \n#>     Oranges           0.934    0.580    1.611    0.107\n#>   F2 =~                                               \n#>     Bread             1.000                           \n#>     Burger            4.700    2.464    1.907    0.056\n#>     Milk              1.307    0.858    1.523    0.128\n#>    Std.lv  Std.all\n#>                   \n#>    10.659    1.062\n#>     9.952    0.715\n#>                   \n#>     1.622    0.662\n#>     7.623    1.032\n#>     2.119    0.312\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   F1 ~~                                               \n#>     F2                5.161    4.482    1.151    0.250\n#>    Std.lv  Std.all\n#>                   \n#>     0.299    0.299\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .Tomatoes        -12.966   66.742   -0.194    0.846\n#>    .Oranges          94.906   64.476    1.472    0.141\n#>    .Bread             3.381    1.581    2.138    0.033\n#>    .Burger           -3.518   27.199   -0.129    0.897\n#>    .Milk             41.714   12.439    3.354    0.001\n#>     F1              113.605   72.842    1.560    0.119\n#>     F2                2.631    1.912    1.376    0.169\n#>    Std.lv  Std.all\n#>   -12.966   -0.129\n#>    94.906    0.489\n#>     3.381    0.562\n#>    -3.518   -0.064\n#>    41.714    0.903\n#>     1.000    1.000\n#>     1.000    1.000\nfitmeasures(fitmod)\n#>                  npar                  fmin \n#>                11.000                 0.079 \n#>                 chisq                    df \n#>                 3.642                 4.000 \n#>                pvalue        baseline.chisq \n#>                 0.457                43.007 \n#>           baseline.df       baseline.pvalue \n#>                10.000                 0.000 \n#>                   cfi                   tli \n#>                 1.000                 1.027 \n#>                  nnfi                   rfi \n#>                 1.027                 0.788 \n#>                   nfi                  pnfi \n#>                 0.915                 0.366 \n#>                   ifi                   rni \n#>                 1.009                 1.011 \n#>                  logl     unrestricted.logl \n#>              -367.812              -365.991 \n#>                   aic                   bic \n#>               757.623               770.114 \n#>                ntotal                  bic2 \n#>                23.000               736.072 \n#>                 rmsea        rmsea.ci.lower \n#>                 0.000                 0.000 \n#>        rmsea.ci.upper        rmsea.ci.level \n#>                 0.302                 0.900 \n#>          rmsea.pvalue        rmsea.close.h0 \n#>                 0.487                 0.050 \n#> rmsea.notclose.pvalue     rmsea.notclose.h0 \n#>                 0.469                 0.080 \n#>                   rmr            rmr_nomean \n#>                 2.823                 2.823 \n#>                  srmr          srmr_bentler \n#>                 0.065                 0.065 \n#>   srmr_bentler_nomean                  crmr \n#>                 0.065                 0.080 \n#>           crmr_nomean            srmr_mplus \n#>                 0.080                 0.065 \n#>     srmr_mplus_nomean                 cn_05 \n#>                 0.065                60.915 \n#>                 cn_01                   gfi \n#>                84.843                 0.947 \n#>                  agfi                  pgfi \n#>                 0.803                 0.253 \n#>                   mfi                  ecvi \n#>                 1.008                 1.115\nlibrary(semPlot)\nsemPaths(fitmod, what='std', layout='tree', title = TRUE, \n         posCol = 1, nDigits = 3, \n         edge.label.cex=0.7, \n         exoVar = FALSE, \n         sizeMan = 5, \n         sizeLat = 5)\n# Estimasi Reliabilitas alpha cronbach\npsych::alpha(harga[,2:6])\n#> Number of categories should be increased  in order to count frequencies.\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = harga[, 2:6])\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N ase mean  sd\n#>       0.63      0.67    0.77      0.29 2.1 0.1   67 5.8\n#>  median_r\n#>      0.26\n#> \n#>     95% confidence boundaries \n#>          lower alpha upper\n#> Feldt     0.32  0.63  0.82\n#> Duhachek  0.42  0.63  0.83\n#> \n#>  Reliability if an item is dropped:\n#>          raw_alpha std.alpha G6(smc) average_r S/N alpha se\n#> Bread         0.64      0.63    0.68      0.30 1.7    0.110\n#> Burger        0.56      0.54    0.63      0.23 1.2    0.107\n#> Milk          0.64      0.68    0.78      0.34 2.1    0.091\n#> Oranges       0.55      0.65    0.66      0.32 1.9    0.140\n#> Tomatoes      0.37      0.59    0.61      0.26 1.4    0.197\n#>          var.r med.r\n#> Bread    0.065  0.26\n#> Burger   0.083  0.13\n#> Milk     0.096  0.26\n#> Oranges  0.043  0.32\n#> Tomatoes 0.062  0.27\n#> \n#>  Item statistics \n#>           n raw.r std.r r.cor r.drop mean   sd\n#> Bread    23  0.38  0.64  0.56   0.30   25  2.5\n#> Burger   23  0.62  0.77  0.72   0.41   92  7.6\n#> Milk     23  0.42  0.56  0.36   0.20   62  7.0\n#> Oranges  23  0.82  0.61  0.56   0.49  103 14.2\n#> Tomatoes 23  0.86  0.71  0.68   0.71   52 10.3"},{"path":"factor-analysis-and-structural-equation-modeling-sem.html","id":"model-persamaan-struktural-sem","chapter":"7 Factor Analysis and Structural Equation Modeling (SEM)","heading":"7.2 Model Persamaan Struktural (SEM)","text":"","code":"\nlibrary(lavaan)  \nlibrary(semPlot)\nlibrary(readxl)\n#> Warning: package 'readxl' was built under R version 4.2.3\ndatasem <- read_excel(\"Data/Datalikert.xlsx\")\nhead(datasem[,1:5])\n#> # A tibble: 6 × 5\n#>   Perusahaan Provinsi   Pulau    A1    A2\n#>        <dbl> <chr>      <chr> <dbl> <dbl>\n#> 1          1 Jawa Barat Jawa      4     5\n#> 2          2 Jawa Timur Jawa      5     5\n#> 3          3 Jawa Timur Jawa      4     4\n#> 4          4 Jawa Barat Jawa      4     4\n#> 5          5 Jawa Timur Jawa      4     4\n#> 6          6 Jawa Timur Jawa      4     4\nstr(datasem)\n#> tibble [300 × 45] (S3: tbl_df/tbl/data.frame)\n#>  $ Perusahaan: num [1:300] 1 2 3 4 5 6 7 8 9 10 ...\n#>  $ Provinsi  : chr [1:300] \"Jawa Barat\" \"Jawa Timur\" \"Jawa Timur\" \"Jawa Barat\" ...\n#>  $ Pulau     : chr [1:300] \"Jawa\" \"Jawa\" \"Jawa\" \"Jawa\" ...\n#>  $ A1        : num [1:300] 4 5 4 4 4 4 4 5 4 5 ...\n#>  $ A2        : num [1:300] 5 5 4 4 4 4 4 5 4 5 ...\n#>  $ A3        : num [1:300] 5 5 4 3 4 5 4 5 3 5 ...\n#>  $ A4        : num [1:300] 4 5 4 4 3 4 4 5 3 5 ...\n#>  $ A5        : num [1:300] 4 4 4 4 4 4 4 5 3 5 ...\n#>  $ A6        : num [1:300] 4 5 4 4 4 4 4 5 3 4 ...\n#>  $ A7        : num [1:300] 5 5 5 4 4 4 4 5 3 5 ...\n#>  $ A8        : num [1:300] 5 5 5 4 4 4 4 5 3 4 ...\n#>  $ Atotal    : num [1:300] 36 39 34 31 31 33 32 40 26 38 ...\n#>  $ B1        : num [1:300] 4 4 4 4 3 5 3 3 3 4 ...\n#>  $ B2        : num [1:300] 4 4 4 3 4 4 3 3 2 4 ...\n#>  $ Btotal    : num [1:300] 8 8 8 7 7 9 6 6 5 8 ...\n#>  $ C1        : num [1:300] 4 4 4 4 4 4 4 5 3 4 ...\n#>  $ C2        : num [1:300] 4 4 4 4 4 4 4 4 3 4 ...\n#>  $ Ctotal    : num [1:300] 8 8 8 8 8 8 8 9 6 8 ...\n#>  $ D1        : num [1:300] 4 5 4 4 4 4 4 4 3 4 ...\n#>  $ D2        : num [1:300] 4 5 4 3 4 5 4 4 2 4 ...\n#>  $ D3        : num [1:300] 4 5 4 4 4 4 4 4 3 4 ...\n#>  $ D4        : num [1:300] 4 5 4 5 4 4 4 4 3 4 ...\n#>  $ Dtotal    : num [1:300] 16 20 16 16 16 17 16 16 11 16 ...\n#>  $ E1        : num [1:300] 5 5 4 4 4 4 4 4 3 5 ...\n#>  $ E2        : num [1:300] 5 5 4 4 4 5 4 4 3 5 ...\n#>  $ E3        : num [1:300] 5 5 4 4 4 5 4 5 4 5 ...\n#>  $ E4        : num [1:300] 4 5 4 3 4 5 4 4 3 4 ...\n#>  $ E5        : num [1:300] 4 5 4 4 3 5 4 4 3 4 ...\n#>  $ E6        : num [1:300] 4 5 4 4 4 4 4 4 3 4 ...\n#>  $ E7        : num [1:300] 4 5 4 4 4 5 4 4 3 4 ...\n#>  $ E8        : num [1:300] 4 5 4 4 3 5 4 4 3 4 ...\n#>  $ E9        : num [1:300] 4 5 4 4 4 4 4 4 3 4 ...\n#>  $ E10       : num [1:300] 4 5 4 4 4 5 4 5 3 4 ...\n#>  $ E11       : num [1:300] 4 5 4 3 3 5 4 5 3 4 ...\n#>  $ E12       : num [1:300] 5 5 4 4 4 5 4 5 3 5 ...\n#>  $ Etotal    : num [1:300] 52 60 48 46 45 57 48 52 37 52 ...\n#>  $ F1        : num [1:300] 5 5 4 4 4 5 4 4 2 4 ...\n#>  $ F2        : num [1:300] 4 5 4 4 4 5 4 4 3 3 ...\n#>  $ F3        : num [1:300] 4 5 4 4 4 4 4 4 2 3 ...\n#>  $ F4        : num [1:300] 4 5 4 4 4 5 4 5 3 4 ...\n#>  $ F5        : num [1:300] 4 5 4 4 3 5 4 4 3 3 ...\n#>  $ F6        : num [1:300] 4 5 4 4 3 4 4 5 3 4 ...\n#>  $ F7        : num [1:300] 4 5 4 4 3 4 4 4 3 4 ...\n#>  $ F8        : num [1:300] 4 5 4 4 4 5 4 4 3 4 ...\n#>  $ Ftotal    : num [1:300] 33 40 32 32 29 37 32 34 22 29 ...\nattach(datasem)\ntable(A1)\n#> A1\n#>   1   2   3   4   5 \n#>   3   4  37 121 135\nbarplot(table(A1))\n# Spesifikasi Model\nsem.model = \"\nfaktor =~ A1 + A2 + A3 + A4\npermintaan =~ B1 + B2  \nindustri =~ C1 + C2  \nstrategi =~ D1 + D2 + D3 + D4\nregulasi =~ E1 + E2 + E3 + E4 + E5 + E6\nkesempatan =~ F1 + F2 + F3 + F4\nkesempatan ~ faktor + permintaan + industri + strategi + regulasi\"\nsem.fit = sem(sem.model, data = datasem)\nsummary(sem.fit, fit.measures=TRUE)\n#> lavaan 0.6.17 ended normally after 90 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        59\n#> \n#>   Number of observations                           300\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                               555.757\n#>   Degrees of freedom                               194\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              7355.210\n#>   Degrees of freedom                               231\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.949\n#>   Tucker-Lewis Index (TLI)                       0.940\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -4608.159\n#>   Loglikelihood unrestricted model (H1)      -4330.280\n#>                                                       \n#>   Akaike (AIC)                                9334.318\n#>   Bayesian (BIC)                              9552.841\n#>   Sample-size adjusted Bayesian (SABIC)       9365.728\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.079\n#>   90 Percent confidence interval - lower         0.071\n#>   90 Percent confidence interval - upper         0.087\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    0.410\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.035\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   faktor =~                                           \n#>     A1                1.000                           \n#>     A2                1.266    0.089   14.271    0.000\n#>     A3                1.312    0.094   13.991    0.000\n#>     A4                1.261    0.091   13.913    0.000\n#>   permintaan =~                                       \n#>     B1                1.000                           \n#>     B2                1.020    0.063   16.072    0.000\n#>   industri =~                                         \n#>     C1                1.000                           \n#>     C2                1.035    0.044   23.446    0.000\n#>   strategi =~                                         \n#>     D1                1.000                           \n#>     D2                0.973    0.033   29.472    0.000\n#>     D3                0.972    0.043   22.590    0.000\n#>     D4                0.817    0.042   19.325    0.000\n#>   regulasi =~                                         \n#>     E1                1.000                           \n#>     E2                0.929    0.039   23.666    0.000\n#>     E3                0.950    0.043   22.088    0.000\n#>     E4                1.015    0.039   25.697    0.000\n#>     E5                0.985    0.042   23.464    0.000\n#>     E6                0.913    0.045   20.186    0.000\n#>   kesempatan =~                                       \n#>     F1                1.000                           \n#>     F2                1.006    0.038   26.712    0.000\n#>     F3                1.033    0.042   24.672    0.000\n#>     F4                0.943    0.046   20.414    0.000\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   kesempatan ~                                        \n#>     faktor            0.016    0.111    0.146    0.884\n#>     permintaan        0.042    0.059    0.705    0.481\n#>     industri          0.129    0.133    0.976    0.329\n#>     strategi          0.131    0.091    1.449    0.147\n#>     regulasi          0.685    0.077    8.860    0.000\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   faktor ~~                                           \n#>     permintaan        0.233    0.034    6.785    0.000\n#>     industri          0.327    0.037    8.729    0.000\n#>     strategi          0.292    0.035    8.242    0.000\n#>     regulasi          0.343    0.039    8.730    0.000\n#>   permintaan ~~                                       \n#>     industri          0.366    0.043    8.447    0.000\n#>     strategi          0.391    0.045    8.713    0.000\n#>     regulasi          0.332    0.043    7.797    0.000\n#>   industri ~~                                         \n#>     strategi          0.437    0.043   10.274    0.000\n#>     regulasi          0.416    0.043    9.764    0.000\n#>   strategi ~~                                         \n#>     regulasi          0.405    0.042    9.580    0.000\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .A1                0.323    0.029   11.229    0.000\n#>    .A2                0.161    0.018    8.902    0.000\n#>    .A3                0.205    0.022    9.430    0.000\n#>    .A4                0.198    0.021    9.552    0.000\n#>    .B1                0.269    0.032    8.457    0.000\n#>    .B2                0.078    0.025    3.161    0.002\n#>    .C1                0.122    0.014    8.515    0.000\n#>    .C2                0.106    0.014    7.549    0.000\n#>    .D1                0.093    0.011    8.749    0.000\n#>    .D2                0.063    0.008    7.476    0.000\n#>    .D3                0.182    0.017   10.625    0.000\n#>    .D4                0.200    0.018   11.219    0.000\n#>    .E1                0.145    0.014   10.563    0.000\n#>    .E2                0.114    0.011   10.395    0.000\n#>    .E3                0.156    0.014   10.845    0.000\n#>    .E4                0.091    0.010    9.488    0.000\n#>    .E5                0.133    0.013   10.462    0.000\n#>    .E6                0.198    0.018   11.224    0.000\n#>    .F1                0.139    0.014    9.697    0.000\n#>    .F2                0.090    0.011    8.221    0.000\n#>    .F3                0.140    0.015    9.540    0.000\n#>    .F4                0.233    0.021   10.912    0.000\n#>     faktor            0.321    0.047    6.841    0.000\n#>     permintaan        0.525    0.065    8.048    0.000\n#>     industri          0.480    0.049    9.751    0.000\n#>     strategi          0.522    0.050   10.406    0.000\n#>     regulasi          0.542    0.055    9.811    0.000\n#>    .kesempatan        0.122    0.015    8.068    0.000\nsem.fit = sem(sem.model, data = datasem, std.lv=TRUE)\nsummary(sem.fit, fit.measures=TRUE, standardized=TRUE)\n#> lavaan 0.6.17 ended normally after 90 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        59\n#> \n#>   Number of observations                           300\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                               555.757\n#>   Degrees of freedom                               194\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              7355.210\n#>   Degrees of freedom                               231\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.949\n#>   Tucker-Lewis Index (TLI)                       0.940\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -4608.159\n#>   Loglikelihood unrestricted model (H1)      -4330.280\n#>                                                       \n#>   Akaike (AIC)                                9334.318\n#>   Bayesian (BIC)                              9552.841\n#>   Sample-size adjusted Bayesian (SABIC)       9365.728\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.079\n#>   90 Percent confidence interval - lower         0.071\n#>   90 Percent confidence interval - upper         0.087\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    0.410\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.035\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   faktor =~                                           \n#>     A1                0.566    0.041   13.681    0.000\n#>     A2                0.717    0.038   18.699    0.000\n#>     A3                0.743    0.041   18.064    0.000\n#>     A4                0.714    0.040   17.894    0.000\n#>   permintaan =~                                       \n#>     B1                0.725    0.045   16.097    0.000\n#>     B2                0.739    0.038   19.509    0.000\n#>   industri =~                                         \n#>     C1                0.692    0.036   19.503    0.000\n#>     C2                0.717    0.036   20.132    0.000\n#>   strategi =~                                         \n#>     D1                0.723    0.035   20.812    0.000\n#>     D2                0.703    0.033   21.615    0.000\n#>     D3                0.702    0.038   18.344    0.000\n#>     D4                0.590    0.036   16.459    0.000\n#>   regulasi =~                                         \n#>     E1                0.736    0.038   19.623    0.000\n#>     E2                0.684    0.034   19.941    0.000\n#>     E3                0.699    0.037   18.967    0.000\n#>     E4                0.747    0.035   21.120    0.000\n#>     E5                0.725    0.037   19.819    0.000\n#>     E6                0.673    0.038   17.720    0.000\n#>   kesempatan =~                                       \n#>     F1                0.350    0.022   16.135    0.000\n#>     F2                0.352    0.021   16.722    0.000\n#>     F3                0.361    0.022   16.227    0.000\n#>     F4                0.330    0.022   14.833    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.566    0.706\n#>     0.717    0.872\n#>     0.743    0.854\n#>     0.714    0.849\n#>                   \n#>     0.725    0.813\n#>     0.739    0.935\n#>                   \n#>     0.692    0.893\n#>     0.717    0.911\n#>                   \n#>     0.723    0.922\n#>     0.703    0.941\n#>     0.702    0.855\n#>     0.590    0.797\n#>                   \n#>     0.736    0.888\n#>     0.684    0.897\n#>     0.699    0.870\n#>     0.747    0.927\n#>     0.725    0.894\n#>     0.673    0.834\n#>                   \n#>     0.771    0.900\n#>     0.776    0.933\n#>     0.796    0.905\n#>     0.727    0.833\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   kesempatan ~                                        \n#>     faktor            0.026    0.180    0.146    0.884\n#>     permintaan        0.086    0.123    0.705    0.481\n#>     industri          0.256    0.263    0.973    0.331\n#>     strategi          0.272    0.188    1.447    0.148\n#>     regulasi          1.443    0.190    7.608    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.012    0.012\n#>     0.039    0.039\n#>     0.116    0.116\n#>     0.123    0.123\n#>     0.654    0.654\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   faktor ~~                                           \n#>     permintaan        0.568    0.046   12.297    0.000\n#>     industri          0.833    0.025   33.258    0.000\n#>     strategi          0.715    0.033   21.548    0.000\n#>     regulasi          0.822    0.023   35.175    0.000\n#>   permintaan ~~                                       \n#>     industri          0.729    0.035   20.610    0.000\n#>     strategi          0.746    0.032   23.194    0.000\n#>     regulasi          0.623    0.041   15.291    0.000\n#>   industri ~~                                         \n#>     strategi          0.874    0.020   44.744    0.000\n#>     regulasi          0.816    0.024   33.446    0.000\n#>   strategi ~~                                         \n#>     regulasi          0.762    0.027   27.976    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.568    0.568\n#>     0.833    0.833\n#>     0.715    0.715\n#>     0.822    0.822\n#>                   \n#>     0.729    0.729\n#>     0.746    0.746\n#>     0.623    0.623\n#>                   \n#>     0.874    0.874\n#>     0.816    0.816\n#>                   \n#>     0.762    0.762\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .A1                0.323    0.029   11.229    0.000\n#>    .A2                0.161    0.018    8.902    0.000\n#>    .A3                0.205    0.022    9.430    0.000\n#>    .A4                0.198    0.021    9.552    0.000\n#>    .B1                0.269    0.032    8.457    0.000\n#>    .B2                0.078    0.025    3.161    0.002\n#>    .C1                0.122    0.014    8.515    0.000\n#>    .C2                0.106    0.014    7.549    0.000\n#>    .D1                0.093    0.011    8.749    0.000\n#>    .D2                0.063    0.008    7.476    0.000\n#>    .D3                0.182    0.017   10.625    0.000\n#>    .D4                0.200    0.018   11.219    0.000\n#>    .E1                0.145    0.014   10.563    0.000\n#>    .E2                0.114    0.011   10.395    0.000\n#>    .E3                0.156    0.014   10.845    0.000\n#>    .E4                0.091    0.010    9.488    0.000\n#>    .E5                0.133    0.013   10.462    0.000\n#>    .E6                0.198    0.018   11.224    0.000\n#>    .F1                0.139    0.014    9.697    0.000\n#>    .F2                0.090    0.011    8.221    0.000\n#>    .F3                0.140    0.015    9.540    0.000\n#>    .F4                0.233    0.021   10.912    0.000\n#>     faktor            1.000                           \n#>     permintaan        1.000                           \n#>     industri          1.000                           \n#>     strategi          1.000                           \n#>     regulasi          1.000                           \n#>    .kesempatan        1.000                           \n#>    Std.lv  Std.all\n#>     0.323    0.502\n#>     0.161    0.239\n#>     0.205    0.271\n#>     0.198    0.280\n#>     0.269    0.339\n#>     0.078    0.126\n#>     0.122    0.203\n#>     0.106    0.171\n#>     0.093    0.151\n#>     0.063    0.114\n#>     0.182    0.270\n#>     0.200    0.365\n#>     0.145    0.211\n#>     0.114    0.195\n#>     0.156    0.242\n#>     0.091    0.141\n#>     0.133    0.201\n#>     0.198    0.304\n#>     0.139    0.190\n#>     0.090    0.130\n#>     0.140    0.181\n#>     0.233    0.306\n#>     1.000    1.000\n#>     1.000    1.000\n#>     1.000    1.000\n#>     1.000    1.000\n#>     1.000    1.000\n#>     0.206    0.206\n#sem.fit = sem(sem.model, data = datasem, std.lv=TRUE, orthogonal=TRUE)\n#summary(sem.fit, fit.measures=TRUE, standardized=TRUE)\n# Modification Indices\nmodificationIndices(sem.fit, minimum.value = 10)\n#>            lhs op rhs     mi    epc sepc.lv sepc.all\n#> 72      faktor =~  D3 10.792  0.143   0.143    0.174\n#> 82      faktor =~  F3 14.022 -0.170  -0.170   -0.193\n#> 99  permintaan =~  E6 13.919  0.142   0.142    0.176\n#> 112   industri =~  D3 19.393  0.315   0.315    0.383\n#> 134   strategi =~  E3 11.975 -0.144  -0.144   -0.179\n#> 152   regulasi =~  D3 18.808  0.197   0.197    0.240\n#> 157   regulasi =~  F4 13.142  0.272   0.272    0.312\n#> 168 kesempatan =~  D3 22.896  0.100   0.220    0.268\n#> 175 kesempatan =~  E6 25.214  0.153   0.337    0.418\n#> 176         A1 ~~  A2 15.863  0.068   0.068    0.298\n#> 270         B1 ~~  F4 14.265  0.063   0.063    0.253\n#> 317         D1 ~~  D3 10.752 -0.035  -0.035   -0.272\n#> 331         D2 ~~  E1 11.098  0.025   0.025    0.257\n#> 347         D3 ~~  E6 12.029  0.042   0.042    0.223\n#> 351         D3 ~~  F4 10.217 -0.043  -0.043   -0.208\n#> 352         D4 ~~  E1 11.953 -0.038  -0.038   -0.223\n#> 362         E1 ~~  E2 17.329  0.038   0.038    0.294\n#> 363         E1 ~~  E3 10.360  0.033   0.033    0.220\n#> 364         E1 ~~  E4 12.186 -0.031  -0.031   -0.266\n#> 371         E2 ~~  E3 11.663  0.032   0.032    0.236\n#> 373         E2 ~~  E5 10.449 -0.028  -0.028   -0.231\n#> 381         E3 ~~  E6 11.439 -0.039  -0.039   -0.221\n#> 386         E4 ~~  E5 25.380  0.043   0.043    0.388\n#> 398         E6 ~~  F2 14.478 -0.037  -0.037   -0.275\n#> 399         E6 ~~  F3 20.998  0.052   0.052    0.310\n#> 405         F2 ~~  F4 24.019 -0.058  -0.058   -0.404\n#> 406         F3 ~~  F4 14.294  0.050   0.050    0.279\n#>     sepc.nox\n#> 72     0.174\n#> 82    -0.193\n#> 99     0.176\n#> 112    0.383\n#> 134   -0.179\n#> 152    0.240\n#> 157    0.312\n#> 168    0.268\n#> 175    0.418\n#> 176    0.298\n#> 270    0.253\n#> 317   -0.272\n#> 331    0.257\n#> 347    0.223\n#> 351   -0.208\n#> 352   -0.223\n#> 362    0.294\n#> 363    0.220\n#> 364   -0.266\n#> 371    0.236\n#> 373   -0.231\n#> 381   -0.221\n#> 386    0.388\n#> 398   -0.275\n#> 399    0.310\n#> 405   -0.404\n#> 406    0.279\nsem.model2 = \"\nfaktor =~ A1 + A2 + A3 + A4\npermintaan =~ B1 + B2  \nindustri =~ C1 + C2  \nstrategi =~ D1 + D2 + D3 + D4\nregulasi =~ E1 + E2 + E3 + E4 + E5 + E6\nkesempatan =~ F1 + F2 + F3 + F4\nkesempatan ~ faktor + permintaan + industri + strategi + regulasi\nA1  ~~  A2\n\"\nsem.fit = sem(sem.model2, data = datasem, std.lv=TRUE)\nsummary(sem.fit, fit.measures=TRUE, standardized=TRUE)\n#> lavaan 0.6.17 ended normally after 94 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        60\n#> \n#>   Number of observations                           300\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                               540.535\n#>   Degrees of freedom                               193\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              7355.210\n#>   Degrees of freedom                               231\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.951\n#>   Tucker-Lewis Index (TLI)                       0.942\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -4600.548\n#>   Loglikelihood unrestricted model (H1)      -4330.280\n#>                                                       \n#>   Akaike (AIC)                                9321.095\n#>   Bayesian (BIC)                              9543.322\n#>   Sample-size adjusted Bayesian (SABIC)       9353.038\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.077\n#>   90 Percent confidence interval - lower         0.070\n#>   90 Percent confidence interval - upper         0.085\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    0.303\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.035\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   faktor =~                                           \n#>     A1                0.539    0.043   12.660    0.000\n#>     A2                0.702    0.039   18.009    0.000\n#>     A3                0.752    0.041   18.363    0.000\n#>     A4                0.720    0.040   18.060    0.000\n#>   permintaan =~                                       \n#>     B1                0.724    0.045   16.093    0.000\n#>     B2                0.739    0.038   19.507    0.000\n#>   industri =~                                         \n#>     C1                0.692    0.036   19.469    0.000\n#>     C2                0.717    0.036   20.171    0.000\n#>   strategi =~                                         \n#>     D1                0.723    0.035   20.813    0.000\n#>     D2                0.703    0.033   21.613    0.000\n#>     D3                0.702    0.038   18.345    0.000\n#>     D4                0.590    0.036   16.460    0.000\n#>   regulasi =~                                         \n#>     E1                0.736    0.038   19.615    0.000\n#>     E2                0.684    0.034   19.943    0.000\n#>     E3                0.699    0.037   18.964    0.000\n#>     E4                0.747    0.035   21.115    0.000\n#>     E5                0.726    0.037   19.826    0.000\n#>     E6                0.673    0.038   17.728    0.000\n#>   kesempatan =~                                       \n#>     F1                0.350    0.022   16.137    0.000\n#>     F2                0.352    0.021   16.726    0.000\n#>     F3                0.361    0.022   16.232    0.000\n#>     F4                0.330    0.022   14.836    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.539    0.672\n#>     0.702    0.854\n#>     0.752    0.864\n#>     0.720    0.855\n#>                   \n#>     0.724    0.813\n#>     0.739    0.935\n#>                   \n#>     0.692    0.892\n#>     0.717    0.912\n#>                   \n#>     0.723    0.922\n#>     0.703    0.941\n#>     0.702    0.855\n#>     0.590    0.797\n#>                   \n#>     0.736    0.888\n#>     0.684    0.897\n#>     0.699    0.870\n#>     0.747    0.927\n#>     0.726    0.894\n#>     0.673    0.834\n#>                   \n#>     0.771    0.900\n#>     0.776    0.933\n#>     0.796    0.905\n#>     0.727    0.833\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   kesempatan ~                                        \n#>     faktor            0.031    0.186    0.167    0.867\n#>     permintaan        0.087    0.122    0.709    0.478\n#>     industri          0.253    0.267    0.947    0.344\n#>     strategi          0.272    0.189    1.442    0.149\n#>     regulasi          1.441    0.190    7.578    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.014    0.014\n#>     0.039    0.039\n#>     0.115    0.115\n#>     0.123    0.123\n#>     0.654    0.654\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>  .A1 ~~                                               \n#>    .A2                0.068    0.019    3.588    0.000\n#>   faktor ~~                                           \n#>     permintaan        0.573    0.046   12.417    0.000\n#>     industri          0.837    0.025   33.458    0.000\n#>     strategi          0.716    0.033   21.421    0.000\n#>     regulasi          0.824    0.024   34.919    0.000\n#>   permintaan ~~                                       \n#>     industri          0.729    0.035   20.581    0.000\n#>     strategi          0.746    0.032   23.189    0.000\n#>     regulasi          0.623    0.041   15.292    0.000\n#>   industri ~~                                         \n#>     strategi          0.874    0.020   44.757    0.000\n#>     regulasi          0.816    0.024   33.429    0.000\n#>   strategi ~~                                         \n#>     regulasi          0.762    0.027   27.982    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.068    0.269\n#>                   \n#>     0.573    0.573\n#>     0.837    0.837\n#>     0.716    0.716\n#>     0.824    0.824\n#>                   \n#>     0.729    0.729\n#>     0.746    0.746\n#>     0.623    0.623\n#>                   \n#>     0.874    0.874\n#>     0.816    0.816\n#>                   \n#>     0.762    0.762\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .A1                0.353    0.032   11.133    0.000\n#>    .A2                0.182    0.020    9.132    0.000\n#>    .A3                0.192    0.022    8.905    0.000\n#>    .A4                0.190    0.021    9.171    0.000\n#>    .B1                0.270    0.032    8.454    0.000\n#>    .B2                0.078    0.025    3.155    0.002\n#>    .C1                0.123    0.014    8.573    0.000\n#>    .C2                0.104    0.014    7.494    0.000\n#>    .D1                0.093    0.011    8.748    0.000\n#>    .D2                0.063    0.008    7.481    0.000\n#>    .D3                0.182    0.017   10.624    0.000\n#>    .D4                0.200    0.018   11.218    0.000\n#>    .E1                0.145    0.014   10.565    0.000\n#>    .E2                0.114    0.011   10.392    0.000\n#>    .E3                0.157    0.014   10.844    0.000\n#>    .E4                0.092    0.010    9.490    0.000\n#>    .E5                0.132    0.013   10.456    0.000\n#>    .E6                0.197    0.018   11.222    0.000\n#>    .F1                0.140    0.014    9.700    0.000\n#>    .F2                0.090    0.011    8.219    0.000\n#>    .F3                0.140    0.015    9.538    0.000\n#>    .F4                0.233    0.021   10.912    0.000\n#>     faktor            1.000                           \n#>     permintaan        1.000                           \n#>     industri          1.000                           \n#>     strategi          1.000                           \n#>     regulasi          1.000                           \n#>    .kesempatan        1.000                           \n#>    Std.lv  Std.all\n#>     0.353    0.549\n#>     0.182    0.270\n#>     0.192    0.253\n#>     0.190    0.268\n#>     0.270    0.339\n#>     0.078    0.125\n#>     0.123    0.205\n#>     0.104    0.169\n#>     0.093    0.151\n#>     0.063    0.114\n#>     0.182    0.270\n#>     0.200    0.365\n#>     0.145    0.211\n#>     0.114    0.195\n#>     0.157    0.242\n#>     0.092    0.141\n#>     0.132    0.201\n#>     0.197    0.304\n#>     0.140    0.190\n#>     0.090    0.130\n#>     0.140    0.181\n#>     0.233    0.306\n#>     1.000    1.000\n#>     1.000    1.000\n#>     1.000    1.000\n#>     1.000    1.000\n#>     1.000    1.000\n#>     0.206    0.206"},{"path":"factor-analysis-and-structural-equation-modeling-sem.html","id":"visualisasi-sem","chapter":"7 Factor Analysis and Structural Equation Modeling (SEM)","heading":"7.2.1 Visualisasi SEM","text":"","code":"\nsemPaths(sem.fit)\nsemPaths(sem.fit, \"std\", \n         color = list(lat = \"green\", man = \"yellow\"), \n         edge.color=\"black\")\nsemPaths(sem.fit, \"std\", \n         color = list(lat = \"green\", man = \"yellow\"), \n         edge.color=\"black\", fade=FALSE)\nsemPaths(sem.fit, \"std\", \n         color = list(lat = \"green\", man = \"yellow\"), \n         edge.color=\"black\", \n         fade=FALSE, residuals=FALSE, exoCov=FALSE)"},{"path":"factor-analysis-and-structural-equation-modeling-sem.html","id":"pls-sem","chapter":"7 Factor Analysis and Structural Equation Modeling (SEM)","heading":"7.3 PLS SEM","text":"","code":"\n# source:https://rpubs.com/ifn1411/PLS\n# install plspm\n#install.packages(\"plspm\")\n# load plspm\nlibrary(plspm)\n#> Warning: package 'plspm' was built under R version 4.2.3\n#> \n#> Attaching package: 'plspm'\n#> The following objects are masked from 'package:psych':\n#> \n#>     alpha, rescale, unidim\n# load data spainmodel\ndata(spainfoot)\n# first 5 row of spainmodel data\nhead(spainfoot)\n#>            GSH GSA  SSH  SSA GCH GCA  CSH  CSA WMH WMA LWR\n#> Barcelona   61  44 0.95 0.95  14  21 0.47 0.32  14  13  10\n#> RealMadrid  49  34 1.00 0.84  29  23 0.37 0.37  14  11  10\n#> Sevilla     28  26 0.74 0.74  20  19 0.42 0.53  11  10   4\n#> AtleMadrid  47  33 0.95 0.84  23  34 0.37 0.16  13   7   6\n#> Villarreal  33  28 0.84 0.68  25  29 0.26 0.16  12   6   5\n#> Valencia    47  21 1.00 0.68  26  28 0.26 0.26  12   6   5\n#>            LRWL  YC RC\n#> Barcelona    22  76  6\n#> RealMadrid   18 115  9\n#> Sevilla       7 100  8\n#> AtleMadrid    9 116  5\n#> Villarreal   11 102  5\n#> Valencia      8 120  6\nAttack <-  c(0, 0, 0)\nDefense <- c(1, 0, 0)\nSuccess <- c(1, 0, 0)\n\nmodel_path <- rbind(Attack, Defense, Success)\ncolnames(model_path) <- rownames(model_path)\n\nmodel_path\n#>         Attack Defense Success\n#> Attack       0       0       0\n#> Defense      1       0       0\n#> Success      1       0       0\n# graph structural model\ninnerplot(model_path)\nAttack <-  c(0, 1, 0)\nDefense <- c(0, 0, 0)\nSuccess <- c(1, 1, 0)\n\nmodel_path2 <- rbind(Attack, Defense, Success)\ncolnames(model_path2) <- rownames(model_path2)\n\nmodel_path2\n#>         Attack Defense Success\n#> Attack       0       1       0\n#> Defense      0       0       0\n#> Success      1       1       0\n# graph structural model\ninnerplot(model_path2, txt.col = \"black\")\n# define latent variable associated with\nmodel_blocks <- list(1:4, 5:8, 9:12)\n\n# vector of modes (reflective)\nmodel_modes <- c(\"A\", \"A\", \"A\")\n\n# run plspm analysis\nmodel_pls <- plspm(Data = spainfoot, path_matrix = model_path, blocks = model_blocks, modes = model_modes)\n\nmodel_pls\n#> Partial Least Squares Path Modeling (PLS-PM) \n#> ---------------------------------------------\n#>    NAME             DESCRIPTION\n#> 1  $outer_model     outer model\n#> 2  $inner_model     inner model\n#> 3  $path_coefs      path coefficients matrix\n#> 4  $scores          latent variable scores\n#> 5  $crossloadings   cross-loadings\n#> 6  $inner_summary   summary inner model\n#> 7  $effects         total effects\n#> 8  $unidim          unidimensionality\n#> 9  $gof             goodness-of-fit\n#> 10 $boot            bootstrap results\n#> 11 $data            data matrix\n#> ---------------------------------------------\n#> You can also use the function 'summary'\n# Unidimensionality\nmodel_pls$unidim\n#>         Mode MVs   C.alpha     DG.rho  eig.1st   eig.2nd\n#> Attack     A   4 0.8905919 0.92456079 3.017160 0.7923055\n#> Defense    A   4 0.0000000 0.02601677 2.393442 1.1752781\n#> Success    A   4 0.9165491 0.94232868 3.217294 0.5370492\nplot(model_pls, what = \"loadings\")\n# Loadings and Communilaties\nmodel_pls$outer_model\n#>    name   block     weight    loading communality\n#> 1   GSH  Attack  0.3474771  0.9412506   0.8859527\n#> 2   GSA  Attack  0.2671782  0.8562398   0.7331465\n#> 3   SSH  Attack  0.2922077  0.8466039   0.7167381\n#> 4   SSA  Attack  0.2396012  0.8212987   0.6745316\n#> 5   GCH Defense -0.1198790  0.4762965   0.2268583\n#> 6   GCA Defense -0.4264164  0.8885714   0.7895590\n#> 7   CSH Defense  0.2949470 -0.7297095   0.5324759\n#> 8   CSA Defense  0.3898039 -0.8947452   0.8005689\n#> 9   WMH Success  0.2484276  0.7884562   0.6216632\n#> 10  WMA Success  0.2691511  0.8747163   0.7651285\n#> 11  LWR Success  0.2947322  0.9703409   0.9415614\n#> 12 LRWL Success  0.2998524  0.9428112   0.8888929\n#>    redundancy\n#> 1  0.00000000\n#> 2  0.00000000\n#> 3  0.00000000\n#> 4  0.00000000\n#> 5  0.05071506\n#> 6  0.17650898\n#> 7  0.11903706\n#> 8  0.17897028\n#> 9  0.49452090\n#> 10 0.60864477\n#> 11 0.74899365\n#> 12 0.70709694\n# Crossloadings\nmodel_pls$crossloadings\n#>    name   block     Attack    Defense    Success\n#> 1   GSH  Attack  0.9412506 -0.5139001  0.9019257\n#> 2   GSA  Attack  0.8562398 -0.3403294  0.7483558\n#> 3   SSH  Attack  0.8466039 -0.4124617  0.7781795\n#> 4   SSA  Attack  0.8212987 -0.3455460  0.6308989\n#> 5   GCH Defense -0.1302683  0.4762965 -0.1620567\n#> 6   GCA Defense -0.4633220  0.8885714 -0.5640722\n#> 7   CSH Defense  0.3204993 -0.7297095  0.4850456\n#> 8   CSA Defense  0.4235465 -0.8947452  0.5811253\n#> 9   WMH Success  0.7126127 -0.4120502  0.7884562\n#> 10  WMA Success  0.7720228 -0.7147787  0.8747163\n#> 11  LWR Success  0.8454164 -0.5345709  0.9703409\n#> 12 LRWL Success  0.8600973 -0.5910943  0.9428112\n# Coefficient of Determination\nmodel_pls$inner_model\n#> $Defense\n#>                Estimate Std. Error       t value   Pr(>|t|)\n#> Intercept  5.504973e-17  0.2076918  2.650549e-16 1.00000000\n#> Attack    -4.728148e-01  0.2076918 -2.276521e+00 0.03526176\n#> \n#> $Success\n#>               Estimate Std. Error      t value     Pr(>|t|)\n#> Intercept 7.783183e-17  0.1065936 7.301735e-16 1.000000e+00\n#> Attack    8.918971e-01  0.1065936 8.367266e+00 1.285711e-07\n# Redundancy\nmodel_pls$inner_summary\n#>               Type        R2 Block_Communality\n#> Attack   Exogenous 0.0000000         0.7525922\n#> Defense Endogenous 0.2235539         0.5873656\n#> Success Endogenous 0.7954804         0.8043115\n#>         Mean_Redundancy       AVE\n#> Attack        0.0000000 0.7525922\n#> Defense       0.1313078 0.5873656\n#> Success       0.6398141 0.8043115\n# Goodness-of-fit\nmodel_pls$gof\n#> [1] 0.6034738\nplot(model_pls, what = \"inner\", colpos = \"#6890c4BB\", colneg = \"#f9675dBB\", txt.col = \"black\", arr.tcol=\"black\")"},{"path":"analytic-hierarchy-process-ahp.html","id":"analytic-hierarchy-process-ahp","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8 Analytic Hierarchy Process (AHP)","text":"","code":""},{"path":"analytic-hierarchy-process-ahp.html","id":"prosedur-pengolahan-ahp","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1 Prosedur Pengolahan AHP","text":"","code":""},{"path":"analytic-hierarchy-process-ahp.html","id":"data-5","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.1 Data","text":"","code":"\nahpdata <- read.csv(\"Data/ahp.csv\")\nahpdata\n#>   Responden SAL_QL SAL_IW SAL_LC QL_IW QL_LC IW_LC J1_J2\n#> 1         1     -5     -2     -4     2     2    -2    -2\n#> 2         2     -7     -3     -3     3     3    -4    -3\n#>   J1_j3 J2_J3 J1_J2.1 J1_j3.1 J2_J3.1 J1_J2.2 J1_j3.2\n#> 1    -4    -2       2       3       3       7       3\n#> 2    -7    -1       3       3       3       4      -1\n#>   J2_J3.2 J1_J2.3 J1_j3.3 J2_J3.3\n#> 1      -3       4       7      -2\n#> 2      -3       5       2      -4"},{"path":"analytic-hierarchy-process-ahp.html","id":"analisis","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.2 Analisis","text":"","code":""},{"path":"analytic-hierarchy-process-ahp.html","id":"faktor","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.2.1 Faktor","text":"ahp.cr function calculates consistency ratio decision-maker, defined following equation:CR = (λ − n)/((n − 1)(RI))λ maximum eigenvalue pairwise comparison matrix, n number attributes, RI random index. Following Saaty Tran (2007), RI function n consistency ratio randomly generated pairwise comparison matrices.Saaty showed CR higher 0.1, choice deemed inconsistent","code":"\n# Mendefinisikan faktor\nfaktor <- c(\"SAL\", \"QL\", \"IW\", \"LC\")\n# Menampilkan data frame\nfaktor_data <- ahpdata[, 2:7]\nfaktor_data\n#>   SAL_QL SAL_IW SAL_LC QL_IW QL_LC IW_LC\n#> 1     -5     -2     -4     2     2    -2\n#> 2     -7     -3     -3     3     3    -4\n# install.packages(\"ahpsurvey\")\nlibrary(ahpsurvey)\n#> Warning: package 'ahpsurvey' was built under R version\n#> 4.2.3\nfaktor_data_mat <- ahp.mat(df = faktor_data, faktor, \n                           negconvert = TRUE)\nfaktor_data_mat\n#> [[1]]\n#>      SAL QL  IW  LC\n#> SAL 1.00  5 2.0 4.0\n#> QL  0.20  1 0.5 0.5\n#> IW  0.50  2 1.0 2.0\n#> LC  0.25  2 0.5 1.0\n#> \n#> [[2]]\n#>           SAL QL        IW        LC\n#> SAL 1.0000000  7 3.0000000 3.0000000\n#> QL  0.1428571  1 0.3333333 0.3333333\n#> IW  0.3333333  3 1.0000000 4.0000000\n#> LC  0.3333333  3 0.2500000 1.0000000\n# Consistency\nri <- ahp.ri(nsims = 10000, dim = 4, seed = 42)\nahp.cr(faktor_data_mat, faktor, ri)\n#> [1] 0.01780548 0.09677931\n#Treatement Consistency (Jika Tidak Konsisten)\n#faktor_data_mat <- ahp.harker(faktor_data_mat, faktor, iterations = 10, stopcr = 0.1)\n#ahp.cr(faktor_data_mat, faktor)"},{"path":"analytic-hierarchy-process-ahp.html","id":"individual-rangking-faktor","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.2.2 Individual Rangking Faktor","text":"","code":"\nlibrary(tidyverse)\n#> Warning: package 'tidyverse' was built under R version\n#> 4.2.3\n#> Warning: package 'ggplot2' was built under R version 4.2.3\n#> Warning: package 'tibble' was built under R version 4.2.3\n#> Warning: package 'tidyr' was built under R version 4.2.3\n#> Warning: package 'readr' was built under R version 4.2.3\n#> Warning: package 'purrr' was built under R version 4.2.3\n#> Warning: package 'dplyr' was built under R version 4.2.3\n#> Warning: package 'stringr' was built under R version 4.2.3\n#> Warning: package 'forcats' was built under R version 4.2.3\n#> Warning: package 'lubridate' was built under R version\n#> 4.2.3\n#> ── Attaching core tidyverse packages ──── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.4     ✔ readr     2.1.5\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#> ✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n#> ✔ purrr     1.0.2     \n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nlibrary(tibble)\nfaktor_ind <- ahp.indpref(faktor_data_mat, \n                          faktor, \n                          method = \"arithmetic\")\nround(faktor_ind, 3) %>% rownames_to_column('ID')\n#>   ID   SAL    QL    IW    LC\n#> 1  1 0.512 0.099 0.243 0.147\n#> 2  2 0.517 0.066 0.274 0.143"},{"path":"analytic-hierarchy-process-ahp.html","id":"aggregate-rangking-faktor","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.2.3 Aggregate Rangking Faktor","text":"","code":"\nfaktor_agg <- ahp.aggpref(faktor_data_mat, \n                          faktor, \n                          method = \"arithmetic\", \n                          aggmethod = \"arithmetic\")\nround(faktor_agg, 3) %>% t()\n#>        SAL    QL    IW    LC\n#> [1,] 0.514 0.082 0.259 0.145\nbarplot(faktor_agg,main=\"Rangking Faktor\")\nlibrary(ggplot2)\n# Mengubah Cat menjadi factor dengan label yang diinginkan\ndata = data.frame(\"Cat\"=row.names(data.frame(faktor_agg)),\n                  data.frame(faktor_agg))\ndata$Cat <- factor(data$Cat, \n                   levels = c(\"SAL\", \"QL\", \"IW\", \"LC\"),\n                   labels = c(\"Salary\", \"Quality of Life\", \n                              \"Interes in Work\", \"Location\"))\n# Mengurutkan\ndata$warna <- ifelse(data$faktor_agg == \n                       max(data$faktor_agg), \n                     \"terbesar\", \"lainnya\")\n# Buat grafik batang\nggplot(data, aes(x = Cat, \n                 y = faktor_agg, \n                 fill = warna)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = c(\"terbesar\" = \"#4682B4\", \n                               \"lainnya\" = \"#A9A9A9\")) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +  # Sembunyikan legenda\n  labs(\n    title = \"AHP: Rangking Faktor\",\n    y = \"Skor\",\n    x = \"\")"},{"path":"analytic-hierarchy-process-ahp.html","id":"alternatif","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.2.4 Alternatif","text":"","code":""},{"path":"analytic-hierarchy-process-ahp.html","id":"alternatif-untuk-faktor-salary","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.2.5 Alternatif untuk Faktor Salary","text":"","code":"\nlibrary(dplyr)\nalternatif <- c(\"J1\", \"J2\", \"J3\")\n\n# Menampilkan data frame\nalternatif_data1 <- ahpdata[,8:10]\nalternatif1 <- ahp.mat(df = alternatif_data1, \n                       atts = alternatif, \n                       negconvert = TRUE)\nalternatif1_agg <- ahp.aggpref(alternatif1, \n                               alternatif, \n                               method = \"arithmetic\", \n                               aggmethod = \"arithmetic\")\nround(alternatif1_agg, 3) %>% t()\n#>         J1    J2    J3\n#> [1,] 0.628 0.232 0.139\n#Consistency\nri <- ahp.ri(nsims = 10000, dim = 3, seed = 42)\nahp.cr(alternatif1, alternatif, ri)\n#> [1] 0.00000000 0.07669698"},{"path":"analytic-hierarchy-process-ahp.html","id":"alternatif-untuk-faktor-quality-of-life","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.2.6 Alternatif untuk Faktor Quality of Life","text":"","code":"\nalternatif_data2 <- ahpdata[,11:13]\nalternatif2 <- ahp.mat(df = alternatif_data2, \n                       atts = alternatif, \n                       negconvert = TRUE)\nalternatif2_agg <- ahp.aggpref(alternatif2, \n                               alternatif, \n                               method = \"arithmetic\", \n                               aggmethod = \"arithmetic\")\nround(alternatif2_agg, 3) %>% t()\n#>        J1    J2    J3\n#> [1,] 0.15 0.269 0.581\n#Consistency\nahp.cr(alternatif2, alternatif, ri)\n#> [1] 0.05121571 0.12952632"},{"path":"analytic-hierarchy-process-ahp.html","id":"alternatif-untuk-faktor-interest-in-work","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.2.7 Alternatif untuk Faktor Interest in Work","text":"","code":"\nalternatif_data3 <- ahpdata[,14:16]\nalternatif3 <- ahp.mat(df = alternatif_data3, \n                       atts = alternatif, \n                       negconvert = TRUE)\nalternatif3_agg <- ahp.aggpref(alternatif3, \n                               alternatif, \n                               method = \"arithmetic\", \n                               aggmethod = \"arithmetic\")\nround(alternatif3_agg, 3) %>% t()\n#>         J1    J2    J3\n#> [1,] 0.132 0.651 0.218\n#Consistency\nahp.cr(alternatif3, alternatif, ri)\n#> [1] 0.006706716 0.008789809"},{"path":"analytic-hierarchy-process-ahp.html","id":"alternatif-untuk-faktor-location","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.2.8 Alternatif untuk Faktor Location","text":"","code":"\nalternatif_data4 <- ahpdata[,17:19]\nalternatif4 <- ahp.mat(df = alternatif_data4, \n                       atts = alternatif, \n                       negconvert = TRUE)\nalternatif4_agg <- ahp.aggpref(alternatif4, \n                               alternatif, \n                               method = \"arithmetic\", \n                               aggmethod = \"arithmetic\")\nround(alternatif4_agg, 3) %>% t()\n#>         J1    J2    J3\n#> [1,] 0.104 0.597 0.299\n#Consistency\nahp.cr(alternatif4, alternatif, ri)\n#> [1] 0.16898990 0.02349155"},{"path":"analytic-hierarchy-process-ahp.html","id":"gabungan-alternatif","chapter":"8 Analytic Hierarchy Process (AHP)","heading":"8.1.2.9 Gabungan Alternatif","text":"","code":"\nalternatif_agg <- cbind(alternatif1_agg,alternatif2_agg,\n                        alternatif3_agg,alternatif4_agg) %*% faktor_agg\nalternatif_agg\n#>         [,1]\n#> J1 0.3844544\n#> J2 0.3964920\n#> J3 0.2190537\nbarplot(t(alternatif_agg) ,main=\"Rangking Alternatif\")\ndata = data.frame(\"Cat\"=row.names(data.frame(alternatif_agg)),\n                  data.frame(alternatif_agg))\ndata$Cat <- factor(data$Cat, \n                   levels = c( \"J1\" , \"J2\" ,\"J3\"),\n                   labels = c(\"Job1\", \"Job2\",\"Job3\"))\n# Buat grafik batang\ndata$warna <- ifelse(data$alternatif_agg == max(data$alternatif_agg), \n                     \"terbesar\", \"lainnya\")\n# Buat grafik batang\nggplot(data, aes(x = Cat, y = alternatif_agg, fill = warna)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = c(\"terbesar\" = \"#4682B4\", \n                               \"lainnya\" = \"#A9A9A9\")) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(\n    title = \"AHP: Rangking Alternatif\",\n    y = \"Skor\",\n    x = \"\")"}]
