[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative Methods with RStudio: Application for Management and Business Research",
    "section": "",
    "text": "Welcome\nThis is the code version of Quantitative Methods with RStudio: Application for Management and Business Research, a book released in 2024 by IPB Press. The book was written by Muhammad Firdaus, Farit M Afendi, Deri Siswara, and Nafisa Berliana Indah Pratiwi. You can order the full version here, which includes more detailed explanations.\nManagement quantitative analysis is widely utilized by students, lecturers, and researchers in Indonesia. This book aims to enhance the reputation of education and research in the country by presenting a variety of alternative analysis tools that are commonly used. Managers must accurately synthesize information during the decision-making process and prioritize various options precisely. Additionally, large volumes of transformed data such as customer identities and characteristics or consumer behavior survey results need to be synthesized properly.\nThe first chapter introduces RStudio software and the R programming language, while the second chapter focuses on nonparametric statistical analysis including correlation analysis of two nonparametric variables and causality relationships. Chapter three discusses logistic regression analysis for making practical decisions, followed by discriminant analysis in chapter four which models problems involving one dependent variable influenced by multiple independent variables.\nChapter five covers principal component analysis (PCA) and biplots to reduce a large selection of research variables into more compact dimensions. Chapter six delves into cluster analysis useful for mapping multiple entities whereas chapter seven comprehensively discusses factor analysis along with structural equation modeling (SEM), including PLS-SEM widely used for various problems involving latent variables such as prosperity, loyalty, and company performance.\nThe final chapter explores Analytic Hierarchy Process (AHP) aimed at determining priority choices based on hierarchical decision hierarchy using freely accessible RStudio software across all methods presented in this book. Updates will be made frequently.\nThis book may contain bugs/errors which readers can report at Buku.rstudio.ipb@gmail.com",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "01-Bab1.html",
    "href": "01-Bab1.html",
    "title": "2  Basics of R",
    "section": "",
    "text": "2.1 Introduction\nA &lt;- 2\nA # Print A\n\n[1] 2\nA = 2\nA\n\n[1] 2\nB &lt;- \"Halo Semua\"\nB\n\n[1] \"Halo Semua\"\na&lt;-10 # Space is not sensitive but lettercase is sensitive.\nA\n\n[1] 2\na\n\n[1] 10\n# Arithmetic operation\nx &lt;- 5\ny &lt;- 3\nx + y     \n\n[1] 8\n\nx - y     \n\n[1] 2\n\nx * y     \n\n[1] 15\n\nx / y     \n\n[1] 1.666667\n# Logic operation\na &lt;- TRUE\nb &lt;- FALSE\na & b     \n\n[1] FALSE\n\na | b     \n\n[1] TRUE\n\n!a        \n\n[1] FALSE\nx &lt;- 5\ny &lt;- 3\nx &gt; y     \n\n[1] TRUE\n\nx &lt; y     \n\n[1] FALSE\n\nx == y    \n\n[1] FALSE\n\nx &gt;= y    \n\n[1] TRUE\n\nx &lt;= y    \n\n[1] FALSE",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "01-Bab1.html#types-of-objects-in-r",
    "href": "01-Bab1.html#types-of-objects-in-r",
    "title": "2  Basics of R",
    "section": "2.2 Types of Objects in R",
    "text": "2.2 Types of Objects in R\n\n2.2.1 Vector\n\na1 &lt;- c(2,4,7,3) # Numeric vector\na2 &lt;- c(\"one\",\"two\",\"three\") # Character vector\na3 &lt;- c(TRUE,TRUE,TRUE,FALSE,TRUE,FALSE) # Logical vector\n\n\na1\n\n[1] 2 4 7 3\n\na3[4]        \n\n[1] FALSE\n\na2[c(1,3)]   \n\n[1] \"one\"   \"three\"\n\na1[-1]       \n\n[1] 4 7 3\n\na1[2:4]      \n\n[1] 4 7 3\n\n\n\na &lt;- c(1, 2, 3)\nb &lt;- c(4, 5, 6)\nc &lt;- c(a, b)      \nc                 \n\n[1] 1 2 3 4 5 6\n\nc[1:3]            \n\n[1] 1 2 3\n\nd &lt;- a + b        \nd                 \n\n[1] 5 7 9\n\n\n\na4 &lt;- 1:12 \nb1 &lt;- matrix(a4,3,4)\nb2 &lt;- matrix(a4,3,4,byrow=TRUE) \nb3 &lt;- matrix(1:14,4,4)\n\n\nb1\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\n\n\nb2\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\n\n\nb3\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11    1\n[4,]    4    8   12    2\n\n\n\nb2[2,3]   \n\n[1] 7\n\n\n\nb2[1:2,]  \n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n\n\n\nb2[c(1,3),-2] \n\n     [,1] [,2] [,3]\n[1,]    1    3    4\n[2,]    9   11   12\n\n\n\ndim(b2) \n\n[1] 3 4\n\n\n\nm1 &lt;- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2, ncol = 3)\nm2 &lt;- matrix(c(7, 8, 9, 10, 11, 12), nrow = 2, ncol = 3)\n\n\nm3 &lt;- m1 + m2\nm3\n\n     [,1] [,2] [,3]\n[1,]    8   12   16\n[2,]   10   14   18\n\n\n\nm4 &lt;- m1 %*% t(m2)\nm4\n\n     [,1] [,2]\n[1,]   89   98\n[2,]  116  128\n\n\n\n\n2.2.2 Factor\n\na5 &lt;- c(\"A\",\"B\",\"AB\",\"O\")\nd1 &lt;- factor(a5) \nlevels(d1)\n\n[1] \"A\"  \"AB\" \"B\"  \"O\" \n\n\n\nlevels(d1) &lt;- c(\"Darah A\",\"Darah AB\",\"Darah B\",\"Darah O\")\nd1\n\n[1] Darah A  Darah B  Darah AB Darah O \nLevels: Darah A Darah AB Darah B Darah O\n\n\n\na6 &lt;- c(\"SMA\",\"SD\",\"SMP\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\",\"SMA\")\nd5 &lt;- factor(a6, levels=c(\"SD\",\"SMP\",\"SMA\")) # Skala pengukuran ordinal  \nlevels(d5) \n\n[1] \"SD\"  \"SMP\" \"SMA\"\n\n\n\nd5\n\n [1] SMA SD  SMP SMA SMA SMA SMA SMA SMA SMA SMA SMA SMA\nLevels: SD SMP SMA\n\n\n\n\n2.2.3 List\n\na1; b2; d1\n\n[1] 2 4 7 3\n\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\n\n[1] Darah A  Darah B  Darah AB Darah O \nLevels: Darah A Darah AB Darah B Darah O\n\n\n\ne1 &lt;- list(a1,b2,d1)\ne2 &lt;- list(vect=a1,mat=b2,fac=d1) \ne1\n\n[[1]]\n[1] 2 4 7 3\n\n[[2]]\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\n[[3]]\n[1] Darah A  Darah B  Darah AB Darah O \nLevels: Darah A Darah AB Darah B Darah O\n\ne2\n\n$vect\n[1] 2 4 7 3\n\n$mat\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\n$fac\n[1] Darah A  Darah B  Darah AB Darah O \nLevels: Darah A Darah AB Darah B Darah O\n\n\n\ne1[[1]][2] \n\n[1] 4\n\ne2$fac \n\n[1] Darah A  Darah B  Darah AB Darah O \nLevels: Darah A Darah AB Darah B Darah O\n\ne2[2] \n\n$mat\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\nnames(e2)\n\n[1] \"vect\" \"mat\"  \"fac\" \n\n\n\n\n2.2.4 Data Frame\n\nAngka &lt;- 11:15\nHuruf &lt;- factor(LETTERS[6:10])\nf1 &lt;- data.frame(Angka,Huruf)\nf1\n\n  Angka Huruf\n1    11     F\n2    12     G\n3    13     H\n4    14     I\n5    15     J\n\n\n\nf1[1,2] \n\n[1] F\nLevels: F G H I J\n\nf1$Angka \n\n[1] 11 12 13 14 15\n\nf1[,\"Huruf\"] \n\n[1] F G H I J\nLevels: F G H I J\n\ncolnames(f1) \n\n[1] \"Angka\" \"Huruf\"\n\n\n\nstr(f1)\n\n'data.frame':   5 obs. of  2 variables:\n $ Angka: int  11 12 13 14 15\n $ Huruf: Factor w/ 5 levels \"F\",\"G\",\"H\",\"I\",..: 1 2 3 4 5",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "01-Bab1.html#data-frame-management",
    "href": "01-Bab1.html#data-frame-management",
    "title": "2  Basics of R",
    "section": "2.3 Data Frame Management",
    "text": "2.3 Data Frame Management\n\ndata(iris) \n\n\nhead(iris) \n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\ntail(iris) \n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n145          6.7         3.3          5.7         2.5 virginica\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica\n\n\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n2.3.1 R Package\n\n# install.packages(\"readxl\") - code to install R package\nlibrary(readxl)\n\n\n#install.packages(\"dplyr\")\nlibrary(dplyr)\n\n\n\n2.3.2 Data Management With dplyr\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\nirisbaru  &lt;- mutate(iris, sepal2 = Sepal.Length + Sepal.Width)\n\n\nhead(irisbaru)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species sepal2\n1          5.1         3.5          1.4         0.2  setosa    8.6\n2          4.9         3.0          1.4         0.2  setosa    7.9\n3          4.7         3.2          1.3         0.2  setosa    7.9\n4          4.6         3.1          1.5         0.2  setosa    7.7\n5          5.0         3.6          1.4         0.2  setosa    8.6\n6          5.4         3.9          1.7         0.4  setosa    9.3\n\n\n\nirisetosa &lt;- filter(iris, Species==\"setosa\")\nhead(irisetosa)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\n\nirisversicolor &lt;- filter(iris, Species==\"setosa\"& Petal.Length==1.3)\nhead(irisversicolor)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          4.7         3.2          1.3         0.2  setosa\n2          5.4         3.9          1.3         0.4  setosa\n3          5.5         3.5          1.3         0.2  setosa\n4          4.4         3.0          1.3         0.2  setosa\n5          5.0         3.5          1.3         0.3  setosa\n6          4.5         2.3          1.3         0.3  setosa\n\n\n\niris3 &lt;- select(iris, Sepal.Length, Species)\nhead(iris3)\n\n  Sepal.Length Species\n1          5.1  setosa\n2          4.9  setosa\n3          4.7  setosa\n4          4.6  setosa\n5          5.0  setosa\n6          5.4  setosa\n\n\n\niris4 &lt;- arrange(iris, Petal.Width)\nhead(iris4)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          4.9         3.1          1.5         0.1  setosa\n2          4.8         3.0          1.4         0.1  setosa\n3          4.3         3.0          1.1         0.1  setosa\n4          5.2         4.1          1.5         0.1  setosa\n5          4.9         3.6          1.4         0.1  setosa\n6          5.1         3.5          1.4         0.2  setosa\n\n\n\niris4 &lt;- arrange(iris, Species, desc(Petal.Width))\nhead(iris4)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.0         3.5          1.6         0.6  setosa\n2          5.1         3.3          1.7         0.5  setosa\n3          5.4         3.9          1.7         0.4  setosa\n4          5.7         4.4          1.5         0.4  setosa\n5          5.4         3.9          1.3         0.4  setosa\n6          5.1         3.7          1.5         0.4  setosa\n\n\n\nnames(iris4)[1] &lt;- \"length\" \nhead(iris4)\n\n  length Sepal.Width Petal.Length Petal.Width Species\n1    5.0         3.5          1.6         0.6  setosa\n2    5.1         3.3          1.7         0.5  setosa\n3    5.4         3.9          1.7         0.4  setosa\n4    5.7         4.4          1.5         0.4  setosa\n5    5.4         3.9          1.3         0.4  setosa\n6    5.1         3.7          1.5         0.4  setosa\n\n\n\nhead(iris4[,c(-1,-3)])\n\n  Sepal.Width Petal.Width Species\n1         3.5         0.6  setosa\n2         3.3         0.5  setosa\n3         3.9         0.4  setosa\n4         4.4         0.4  setosa\n5         3.9         0.4  setosa\n6         3.7         0.4  setosa\n\n\n\niris %&gt;% group_by(Species) %&gt;% summarise(rata2_Sepal.Width = mean(Sepal.Width))\n\n# A tibble: 3 × 2\n  Species    rata2_Sepal.Width\n  &lt;fct&gt;                  &lt;dbl&gt;\n1 setosa                  3.43\n2 versicolor              2.77\n3 virginica               2.97",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "01-Bab1.html#visualization",
    "href": "01-Bab1.html#visualization",
    "title": "2  Basics of R",
    "section": "2.4 Visualization",
    "text": "2.4 Visualization\n\n2.4.1 Histogram\n\nhist(iris$Sepal.Length)\n\n\n\n\n\n\n\n\n\n\n2.4.2 Box Plot\n\nboxplot(iris$Sepal.Length)\n\n\n\n\n\n\n\n\n\n\n2.4.3 Barplot\n\ntable(iris$Species)\n\n\n    setosa versicolor  virginica \n        50         50         50 \n\n\n\nbarplot(table(iris$Species))\n\n\n\n\n\n\n\n\n\n\n2.4.4 Pie Chart\n\npie(table(iris$Species))\n\n\n\n\n\n\n\n\n\n\n2.4.5 Scatter Plot\n\nplot(iris$Sepal.Length,iris$Sepal.Width)\n\n\n\n\n\n\n\n\n\nplot(iris$Sepal.Length, iris$Sepal.Width, main = \"Sepal Length vs. Sepal Width\", \n     xlab = \"Sepal Length\", ylab = \"Sepal Width\", col = \"red\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "02-Bab2.html",
    "href": "02-Bab2.html",
    "title": "3  Nonparametric Statistics",
    "section": "",
    "text": "3.1 Correlation\n# Membuat data contoh\n# Membuat vektor untuk responden, X, dan Y\nX &lt;- c(2, 1, 6, 11, 7, 11, 1, 12, 13, 13, 11)\nY &lt;- c(9, 8, 16, 13, 11, 12, 7, 7, 13, 17, 10)\n\n# Membuat dataframe\ndataku &lt;- data.frame(X = X, Y = Y)\n\n# Menampilkan data\ndataku\n\n    X  Y\n1   2  9\n2   1  8\n3   6 16\n4  11 13\n5   7 11\n6  11 12\n7   1  7\n8  12  7\n9  13 13\n10 13 17\n11 11 10\n# Menggunakan fungsi cor.test untuk menghitung Tau-Kendall\ncor.test(dataku$X, dataku$Y, method = \"kendall\")\n\n\n    Kendall's rank correlation tau\n\ndata:  dataku$X and dataku$Y\nz = 1.7529, p-value = 0.07962\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.4273658\n# Menggunakan fungsi cor.test untuk menghitung korelasi Spearman\ncor.test(dataku$X, dataku$Y, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  dataku$X and dataku$Y\nS = 108.98, p-value = 0.1134\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.5046513",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Nonparametric Statistics</span>"
    ]
  },
  {
    "objectID": "02-Bab2.html#correlation",
    "href": "02-Bab2.html#correlation",
    "title": "3  Nonparametric Statistics",
    "section": "",
    "text": "3.1.1 Chi-Square Test\n\n# Membuat data contoh\n# Data asli dalam bentuk tabel silang\nfrekuensi &lt;- matrix(c(30, 21, 30, 19, 15, 35), nrow = 2)\nrownames(frekuensi) &lt;- c(\"Kontrak\", \"Tetap\")\ncolnames(frekuensi) &lt;- c(\"Rendah\", \"Sedang\", \"Tinggi\")\n\n# Inisiasi vektor kosong untuk menyimpan data\nStatus_Pegawai &lt;- c()\nTingkat_Produktivitas &lt;- c()\n\n# Mengulang setiap kombinasi sesuai dengan frekuensinya\nfor (i in 1:nrow(frekuensi)) {\n  for (j in 1:ncol(frekuensi)) {\n    Status_Pegawai &lt;- c(Status_Pegawai, \n                        rep(rownames(frekuensi)[i],\n                            frekuensi[i, j]))\n    \n    Tingkat_Produktivitas &lt;- c(Tingkat_Produktivitas, \n                               rep(colnames(frekuensi)[j], \n                                   frekuensi[i, j]))\n  }\n}\n\n# Membuat dataframe\ndataku2 &lt;- data.frame(Status_Pegawai, \n                      Tingkat_Produktivitas)\n# Menampilkan data\nhead(dataku2)\n\n  Status_Pegawai Tingkat_Produktivitas\n1        Kontrak                Rendah\n2        Kontrak                Rendah\n3        Kontrak                Rendah\n4        Kontrak                Rendah\n5        Kontrak                Rendah\n6        Kontrak                Rendah\n\n\n\n# Transformasi menejadi factor\ndataku2$Status_Pegawai &lt;- as.factor(dataku2$Status_Pegawai)\ndataku2$Tingkat_Produktivitas &lt;- as.factor(dataku2$Tingkat_Produktivitas)\n\nsummary(dataku2)\n\n Status_Pegawai Tingkat_Produktivitas\n Kontrak:75     Rendah:51            \n Tetap  :75     Sedang:49            \n                Tinggi:50            \n\n\n\n# Melakukan tabel kontingensi\ndataku2_kt &lt;- table(dataku2$Status_Pegawai, dataku2$Tingkat_Produktivitas)\ndataku2_kt\n\n         \n          Rendah Sedang Tinggi\n  Kontrak     30     30     15\n  Tetap       21     19     35\n\n\n\n# Melakukan uji Chi-Square\nchisq.test(dataku2_kt)\n\n\n    Pearson's Chi-squared test\n\ndata:  dataku2_kt\nX-squared = 12.058, df = 2, p-value = 0.002408",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Nonparametric Statistics</span>"
    ]
  },
  {
    "objectID": "02-Bab2.html#difference-test",
    "href": "02-Bab2.html#difference-test",
    "title": "3  Nonparametric Statistics",
    "section": "3.2 Difference Test",
    "text": "3.2 Difference Test\n\n3.2.1 Two sample test (Independent)\n\n3.2.1.1 Mann-Whitney Test\n\n# Membuat data contoh\n# Vektor data untuk efisiensi pada skala besar dan kecil\nefisiensi_besar &lt;- c(1.31, 1.25, 1.32, 1.3, 1.33, 1.31, 1.35, 1.34, 0.28, 1.34, 1.28)\nefisiensi_kecil &lt;- c(1.21, 1.28, 1.32, 1.25, 1.27, 1.31, 1.26, 1.31, 1.24, 1.22)\n\n\nwilcox.test(efisiensi_besar, efisiensi_kecil)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  efisiensi_besar and efisiensi_kecil\nW = 82.5, p-value = 0.05614\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n3.2.1.2 Chi-Square Test\n\n\n\n3.2.2 More than two sample test (Independent)\n\n3.2.2.1 Kruskal-Wallis Test\n\n# Membuat data contoh\n# Membuat vektor untuk Industri A, B, dan C\nindustri_A &lt;- c(2.33, 2.79, 3.01, 2.33, 1.22, 2.79, 1.9, 1.65)\nindustri_B &lt;- c(2.33, 2.33, 2.79, 3.01, 1.99, 2.45)\nindustri_C &lt;- c(1.06, 1.37, 1.09, 1.65, 1.44, 1.11) \n\n# Membuat vektor industri\nindustri &lt;- c(rep(\"Industri A\", length(industri_A)), \n              rep(\"Industri B\", length(industri_B)), \n              rep(\"Industri C\", length(industri_C)))\n\n# Menggabungkan semua vektor value\nnilai &lt;- c(industri_A, industri_B, industri_C)\n\n# Membuat data frame\ndataku4 &lt;- data.frame(industri, nilai)\n\n# Menampilkan data frame\ndataku4$industri &lt;- as.factor(dataku4$industri)\ndataku4\n\n     industri nilai\n1  Industri A  2.33\n2  Industri A  2.79\n3  Industri A  3.01\n4  Industri A  2.33\n5  Industri A  1.22\n6  Industri A  2.79\n7  Industri A  1.90\n8  Industri A  1.65\n9  Industri B  2.33\n10 Industri B  2.33\n11 Industri B  2.79\n12 Industri B  3.01\n13 Industri B  1.99\n14 Industri B  2.45\n15 Industri C  1.06\n16 Industri C  1.37\n17 Industri C  1.09\n18 Industri C  1.65\n19 Industri C  1.44\n20 Industri C  1.11\n\n\n\n# Uji kruskal wallis\nkruskal.test(nilai ~ industri, data = dataku4)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  nilai by industri\nKruskal-Wallis chi-squared = 10.619, df = 2, p-value = 0.004943\n\n\n\n# Post hoc kruskal-wallis - Uji Dun\n#installed.packages(\"FSA\")\nlibrary(FSA)\ndunnTest(nilai ~ industri, data = dataku4)\n\n               Comparison          Z     P.unadj      P.adj\n1 Industri A - Industri B -0.6428883 0.520296550 0.52029655\n2 Industri A - Industri C  2.6109139 0.009030062 0.01806012\n3 Industri B - Industri C  3.0436533 0.002337243 0.00701173\n\n\n\n\n3.2.2.2 Chi-Square Test\n\n\n\n3.2.3 Two sample test (Dependent)\n\n3.2.3.1 Sign Test\n\n# Membuat data contoh\n# Data Skor Kepuasan\nproduk_lama &lt;- c(16, 15, 18, 16, 17, 18, 20, 15, 14, 16, 19, 17)\nproduk_baru &lt;- c(18, 17, 16, 19, 17, 20, 18, 16, 15, 18, 20, 18)\n# Data Responden\nresponden &lt;- c(1:12)\n# Membuat data frame\ndataku5 &lt;- data.frame(Responden = c(rep(responden, 2)),\n                      Produk = factor(c(rep(\"Produk Lama\", length(produk_lama)), \n                                        rep(\"Produk Baru\", length(produk_baru)))),\n                      Skor_Kepuasan = c(produk_lama, produk_baru))\n# Menampilkan data frame\ndataku5\n\n   Responden      Produk Skor_Kepuasan\n1          1 Produk Lama            16\n2          2 Produk Lama            15\n3          3 Produk Lama            18\n4          4 Produk Lama            16\n5          5 Produk Lama            17\n6          6 Produk Lama            18\n7          7 Produk Lama            20\n8          8 Produk Lama            15\n9          9 Produk Lama            14\n10        10 Produk Lama            16\n11        11 Produk Lama            19\n12        12 Produk Lama            17\n13         1 Produk Baru            18\n14         2 Produk Baru            17\n15         3 Produk Baru            16\n16         4 Produk Baru            19\n17         5 Produk Baru            17\n18         6 Produk Baru            20\n19         7 Produk Baru            18\n20         8 Produk Baru            16\n21         9 Produk Baru            15\n22        10 Produk Baru            18\n23        11 Produk Baru            20\n24        12 Produk Baru            18\n\n\n\n# Menghitung perbedaan\ndiff &lt;- dataku5[dataku5$Produk == 'Produk Baru', ]$Skor_Kepuasan - dataku5[dataku5$Produk == 'Produk Lama', ]$Skor_Kepuasan\n\n# Menghitung jumlah perbedaan yang positif\njumlah_positif &lt;- sum(diff &gt; 0)\n\n\n# Melakukan uji tanda\nbinom.test(jumlah_positif, length(diff), \n           p = 0.5, \n           alternative = \"two.sided\")\n\n\n    Exact binomial test\n\ndata:  jumlah_positif and length(diff)\nnumber of successes = 9, number of trials = 12, p-value = 0.146\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.4281415 0.9451394\nsample estimates:\nprobability of success \n                  0.75 \n\n\nInterpretation: https://www.geeksforgeeks.org/sign-test-in-r/\n\n\n\n3.2.4 More than two sample test (Dependent)\n\n3.2.4.1 Friedman Test\n\n# Membuat data contoh\ndataku6 &lt;- matrix(c(1.24,1.50,1.62,\n              1.71,1.85,2.05,\n              1.37,2.12,1.68,\n              2.53,1.87,2.62,\n              1.23,1.34,1.51,\n              1.94,2.33,2.86,\n              1.72,1.43,2.86), nrow = 7, byrow = TRUE,\n              dimnames = list(Person= as.character(1:7),\n              Obat = c(\"Obat A\",\"Obat B\",\"Obat C\")))\ndataku6\n\n      Obat\nPerson Obat A Obat B Obat C\n     1   1.24   1.50   1.62\n     2   1.71   1.85   2.05\n     3   1.37   2.12   1.68\n     4   2.53   1.87   2.62\n     5   1.23   1.34   1.51\n     6   1.94   2.33   2.86\n     7   1.72   1.43   2.86\n\n\n\nfriedman.test(dataku6)\n\n\n    Friedman rank sum test\n\ndata:  dataku6\nFriedman chi-squared = 8.8571, df = 2, p-value = 0.01193\n\n\n\n\n3.2.4.2 Cochran Test\n\n# Membuat data contoh\n## Input data\nresponden &lt;- c(1:8)\nproduk_A &lt;- c(\"Tidak\",\"Tidak\",\"Ya\",\"Ya\",\"Ya\",\"Tidak\",\"Tidak\",\"Tidak\")\nproduk_B &lt;- c(\"Tidak\",\"Ya\",\"Ya\",\"Ya\",\"Tidak\",\"Tidak\",\"Ya\",\"Tidak\")\nproduk_C &lt;- c(\"Ya\",\"Tidak\",\"Tidak\",\"Ya\",\"Tidak\",\"Ya\",\"Ya\",\"Tidak\")\ndataku7 &lt;- data.frame(responden, produk_A, produk_B, produk_C)\ndataku7$produk_A &lt;- as.factor(dataku7$produk_A)\ndataku7$produk_B &lt;- as.factor(dataku7$produk_B)\ndataku7$produk_C &lt;- as.factor(dataku7$produk_C)\ndataku7\n\n  responden produk_A produk_B produk_C\n1         1    Tidak    Tidak       Ya\n2         2    Tidak       Ya    Tidak\n3         3       Ya       Ya    Tidak\n4         4       Ya       Ya       Ya\n5         5       Ya    Tidak    Tidak\n6         6    Tidak    Tidak       Ya\n7         7    Tidak       Ya       Ya\n8         8    Tidak    Tidak    Tidak\n\n\n\ndataku7 &lt;-ifelse(dataku7==\"Ya\", 1,0)\n\n\n#install.packages(\"nonpar\")\nlibrary(nonpar)\ncochrans.q(as.matrix(dataku7[,-1]), alpha = 0.05)\n\n\n Cochran's Q Test \n \n H0: There is no difference in the effectiveness of treatments. \n HA: There is a difference in the effectiveness of treatments. \n \n Q = 0.333333333333333 \n \n Degrees of Freedom = 2 \n \n Significance Level = 0.05 \n The p-value is  0.846481724890614",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Nonparametric Statistics</span>"
    ]
  },
  {
    "objectID": "03-Bab3.html",
    "href": "03-Bab3.html",
    "title": "4  Logistic Regression",
    "section": "",
    "text": "4.1 Regresi Logistik Biner",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "03-Bab3.html#regresi-logistik-biner",
    "href": "03-Bab3.html#regresi-logistik-biner",
    "title": "4  Logistic Regression",
    "section": "",
    "text": "4.1.1 Data\n\ncredit &lt;- read.csv(\"Data/credit.csv\")\nhead(credit[,1:5],10)\n\n   creditability account.balance duration credit.amount saving.balance\n1              1               1       18          1049              1\n2              1               1        9          2799              1\n3              1               2       12           841              2\n4              1               1       12          2122              1\n5              1               1       12          2171              1\n6              1               1       10          2241              1\n7              1               1        8          3398              1\n8              1               1        6          1361              1\n9              1               4       18          1098              1\n10             1               2       24          3758              3\n\n\n\nstr(credit)\n\n'data.frame':   1000 obs. of  14 variables:\n $ creditability   : int  1 1 1 1 1 1 1 1 1 1 ...\n $ account.balance : int  1 1 2 1 1 1 1 1 4 2 ...\n $ duration        : int  18 9 12 12 12 10 8 6 18 24 ...\n $ credit.amount   : int  1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ...\n $ saving.balance  : int  1 1 2 1 1 1 1 1 1 3 ...\n $ employment.year : int  2 3 4 3 3 2 4 2 1 1 ...\n $ installment.rate: int  4 2 2 3 4 1 1 2 4 1 ...\n $ marital.status  : int  2 3 2 3 3 3 3 3 2 2 ...\n $ duration.address: int  4 2 4 2 4 3 4 4 4 4 ...\n $ age             : int  21 36 23 39 38 48 39 40 65 23 ...\n $ dependents      : int  1 2 1 2 1 2 1 2 1 1 ...\n $ number.of.credit: int  1 2 1 2 2 2 2 1 2 1 ...\n $ occupation      : int  3 3 2 2 2 2 2 2 1 1 ...\n $ previous.credit : int  4 4 2 4 4 4 4 4 4 2 ...\n\n\n\nlibrary(dplyr)\ncredit &lt;- credit %&gt;% mutate(across(-c(duration,\n                            credit.amount,\n                            age),as.factor))\nstr(credit)\n\n'data.frame':   1000 obs. of  14 variables:\n $ creditability   : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 2 2 2 2 ...\n $ account.balance : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 1 2 1 1 1 1 1 4 2 ...\n $ duration        : int  18 9 12 12 12 10 8 6 18 24 ...\n $ credit.amount   : int  1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ...\n $ saving.balance  : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 2 1 1 1 1 1 1 3 ...\n $ employment.year : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 2 3 4 3 3 2 4 2 1 1 ...\n $ installment.rate: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 4 2 2 3 4 1 1 2 4 1 ...\n $ marital.status  : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 2 3 2 3 3 3 3 3 2 2 ...\n $ duration.address: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 4 2 4 2 4 3 4 4 4 4 ...\n $ age             : int  21 36 23 39 38 48 39 40 65 23 ...\n $ dependents      : Factor w/ 2 levels \"1\",\"2\": 1 2 1 2 1 2 1 2 1 1 ...\n $ number.of.credit: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 1 2 2 2 2 1 2 1 ...\n $ occupation      : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 3 3 2 2 2 2 2 2 1 1 ...\n $ previous.credit : Factor w/ 5 levels \"0\",\"1\",\"2\",\"3\",..: 5 5 3 5 5 5 5 5 5 3 ...\n\n\n\n\n4.1.2 Pemodelan\n\nlogreg1 &lt;- glm(creditability~.,data=credit,family = \"binomial\")\nsummary(logreg1)\n\n\nCall:\nglm(formula = creditability ~ ., family = \"binomial\", data = credit)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        2.990e-01  8.942e-01   0.334 0.738097    \naccount.balance2   4.346e-01  2.013e-01   2.159 0.030852 *  \naccount.balance3   9.490e-01  3.602e-01   2.635 0.008421 ** \naccount.balance4   1.804e+00  2.222e-01   8.119 4.69e-16 ***\nduration          -2.705e-02  8.818e-03  -3.068 0.002156 ** \ncredit.amount     -1.025e-04  4.161e-05  -2.465 0.013718 *  \nsaving.balance2    1.293e-01  2.701e-01   0.479 0.632222    \nsaving.balance3    4.144e-01  3.987e-01   1.039 0.298644    \nsaving.balance4    1.241e+00  5.032e-01   2.467 0.013629 *  \nsaving.balance5    8.811e-01  2.463e-01   3.577 0.000347 ***\nemployment.year2  -1.432e-01  4.109e-01  -0.348 0.727561    \nemployment.year3   2.530e-01  3.957e-01   0.639 0.522582    \nemployment.year4   7.646e-01  4.258e-01   1.796 0.072572 .  \nemployment.year5   2.386e-01  3.962e-01   0.602 0.547012    \ninstallment.rate2 -2.841e-01  2.953e-01  -0.962 0.336089    \ninstallment.rate3 -5.122e-01  3.217e-01  -1.592 0.111374    \ninstallment.rate4 -9.279e-01  2.872e-01  -3.230 0.001236 ** \nmarital.status2    1.744e-01  3.742e-01   0.466 0.641255    \nmarital.status3    7.482e-01  3.670e-01   2.039 0.041468 *  \nmarital.status4    5.577e-01  4.371e-01   1.276 0.201928    \nduration.address2 -7.104e-01  2.832e-01  -2.509 0.012122 *  \nduration.address3 -5.443e-01  3.163e-01  -1.721 0.085314 .  \nduration.address4 -4.386e-01  2.762e-01  -1.588 0.112244    \nage                1.125e-02  8.468e-03   1.329 0.183990    \ndependents2       -2.607e-01  2.387e-01  -1.092 0.274669    \nnumber.of.credit2 -4.177e-01  2.315e-01  -1.805 0.071133 .  \nnumber.of.credit3 -4.131e-01  5.951e-01  -0.694 0.487625    \nnumber.of.credit4 -4.589e-01  9.908e-01  -0.463 0.643240    \noccupation2       -8.953e-02  6.276e-01  -0.143 0.886557    \noccupation3       -1.487e-01  6.048e-01  -0.246 0.805804    \noccupation4        1.276e-02  6.087e-01   0.021 0.983277    \nprevious.credit1  -3.136e-01  5.178e-01  -0.606 0.544686    \nprevious.credit2   6.063e-01  4.149e-01   1.461 0.143896    \nprevious.credit3   8.090e-01  4.531e-01   1.785 0.074205 .  \nprevious.credit4   1.511e+00  4.169e-01   3.625 0.000288 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1221.7  on 999  degrees of freedom\nResidual deviance:  956.0  on 965  degrees of freedom\nAIC: 1026\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n4.1.3 Odds Ratio\n\nbeta = round(coef(logreg1),2)\nOR = round(exp(beta),2)\ncbind(beta, OR)\n\n                   beta   OR\n(Intercept)        0.30 1.35\naccount.balance2   0.43 1.54\naccount.balance3   0.95 2.59\naccount.balance4   1.80 6.05\nduration          -0.03 0.97\ncredit.amount      0.00 1.00\nsaving.balance2    0.13 1.14\nsaving.balance3    0.41 1.51\nsaving.balance4    1.24 3.46\nsaving.balance5    0.88 2.41\nemployment.year2  -0.14 0.87\nemployment.year3   0.25 1.28\nemployment.year4   0.76 2.14\nemployment.year5   0.24 1.27\ninstallment.rate2 -0.28 0.76\ninstallment.rate3 -0.51 0.60\ninstallment.rate4 -0.93 0.39\nmarital.status2    0.17 1.19\nmarital.status3    0.75 2.12\nmarital.status4    0.56 1.75\nduration.address2 -0.71 0.49\nduration.address3 -0.54 0.58\nduration.address4 -0.44 0.64\nage                0.01 1.01\ndependents2       -0.26 0.77\nnumber.of.credit2 -0.42 0.66\nnumber.of.credit3 -0.41 0.66\nnumber.of.credit4 -0.46 0.63\noccupation2       -0.09 0.91\noccupation3       -0.15 0.86\noccupation4        0.01 1.01\nprevious.credit1  -0.31 0.73\nprevious.credit2   0.61 1.84\nprevious.credit3   0.81 2.25\nprevious.credit4   1.51 4.53\n\n\n\n\n4.1.4 Multikolineratitas\n\nlibrary(car)\nvif(logreg1)\n\n                     GVIF Df GVIF^(1/(2*Df))\naccount.balance  1.283532  3        1.042480\nduration         1.828834  1        1.352344\ncredit.amount    2.284117  1        1.511330\nsaving.balance   1.286469  4        1.031989\nemployment.year  2.406179  4        1.116005\ninstallment.rate 1.443706  3        1.063114\nmarital.status   1.439516  3        1.062599\nduration.address 1.502426  3        1.070201\nage              1.365556  1        1.168570\ndependents       1.177252  1        1.085012\nnumber.of.credit 2.060162  3        1.128020\noccupation       1.893863  3        1.112307\nprevious.credit  2.136438  4        1.099541\n\n\n\n\n4.1.5 Akurasi\n\npred_clas &lt;- ifelse(logreg1$fitted.values &gt; 0.5, 1, 0)\nconf_matrix &lt;- table(credit$creditability, pred_clas)\nconf_matrix\n\n   pred_clas\n      0   1\n  0 145 155\n  1  68 632\n\n\n\npaste0(\"Akurasi Model:\")\n\n[1] \"Akurasi Model:\"\n\naccuracy &lt;- sum(diag(conf_matrix)) / sum(conf_matrix)\naccuracy\n\n[1] 0.777\n\n\n\n\n4.1.6 Kebaikan Model\n\n#install.packages(\"performance\")\nlibrary(performance)\n#Outliers\nperformance::check_outliers(logreg1)\n\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n\n\n\n#Metrik\nperformance(logreg1)\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC | Tjur's R2 |  RMSE | Sigma | Log_loss\n---------------------------------------------------------------------\n1025.995 | 1028.609 | 1197.767 |     0.254 | 0.395 | 1.000 |    0.478\n\nAIC      | Score_log | Score_spherical |   PCP\n----------------------------------------------\n1025.995 |      -Inf |           0.001 | 0.687\n\n\n\n#Goodness Of Fit\nperformance_hosmer(logreg1)\n\n# Hosmer-Lemeshow Goodness-of-Fit Test\n\n  Chi-squared: 8.472\n           df: 8    \n      p-value: 0.389",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "03-Bab3.html#regresi-logistik-nominal-atau-multinominal",
    "href": "03-Bab3.html#regresi-logistik-nominal-atau-multinominal",
    "title": "4  Logistic Regression",
    "section": "4.2 Regresi Logistik Nominal atau Multinominal",
    "text": "4.2 Regresi Logistik Nominal atau Multinominal\n\n4.2.1 Data\n\nlibrary(readxl)\nstudents &lt;- read_excel(\"Data/students.xlsx\")\nhead(students,10)\n\n# A tibble: 10 × 6\n   gender ses    prog      read write  math\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 female low    vocation    34    35    41\n 2 male   middle general     34    33    41\n 3 male   high   vocation    39    39    44\n 4 male   low    vocation    37    37    42\n 5 male   middle vocation    39    31    40\n 6 female high   general     42    36    42\n 7 male   middle vocation    31    36    46\n 8 male   middle vocation    50    31    40\n 9 female middle vocation    39    41    33\n10 male   middle vocation    34    37    46\n\n\n\nstr(students)\n\ntibble [200 × 6] (S3: tbl_df/tbl/data.frame)\n $ gender: chr [1:200] \"female\" \"male\" \"male\" \"male\" ...\n $ ses   : chr [1:200] \"low\" \"middle\" \"high\" \"low\" ...\n $ prog  : chr [1:200] \"vocation\" \"general\" \"vocation\" \"vocation\" ...\n $ read  : num [1:200] 34 34 39 37 39 42 31 50 39 34 ...\n $ write : num [1:200] 35 33 39 37 31 36 36 31 41 37 ...\n $ math  : num [1:200] 41 41 44 42 40 42 46 40 33 46 ...\n\n\n\n\n4.2.2 Ubah jadi faktor\n\nlibrary(dplyr)\nstudents &lt;- students %&gt;% mutate(across(-c(read,write,math),as.factor))\nstudents$prog2 &lt;- relevel(students$prog, ref = \"academic\")\nstr(students)\n\ntibble [200 × 7] (S3: tbl_df/tbl/data.frame)\n $ gender: Factor w/ 2 levels \"female\",\"male\": 1 2 2 2 2 1 2 2 1 2 ...\n $ ses   : Factor w/ 3 levels \"high\",\"low\",\"middle\": 2 3 1 2 3 1 3 3 3 3 ...\n $ prog  : Factor w/ 3 levels \"academic\",\"general\",..: 3 2 3 3 3 2 3 3 3 3 ...\n $ read  : num [1:200] 34 34 39 37 39 42 31 50 39 34 ...\n $ write : num [1:200] 35 33 39 37 31 36 36 31 41 37 ...\n $ math  : num [1:200] 41 41 44 42 40 42 46 40 33 46 ...\n $ prog2 : Factor w/ 3 levels \"academic\",\"general\",..: 3 2 3 3 3 2 3 3 3 3 ...\n\n\n\ntable(students$ses, students$prog)\n\n        \n         academic general vocation\n  high         42       9        7\n  low          19      16       12\n  middle       44      20       31\n\n\n\ntable(students$gender, students$prog)\n\n        \n         academic general vocation\n  female       58      24       27\n  male         47      21       23\n\n\n\n\n4.2.3 Pemodelan\n\n#install.packages(\"nnet\")\nlibrary(nnet)\nlogmultinom &lt;- multinom(prog2 ~ ses + gender + write + read, data = students)\n\n# weights:  21 (12 variable)\ninitial  value 219.722458 \niter  10 value 176.754587\nfinal  value 174.725397 \nconverged\n\n\n\nsummary(logmultinom)\n\nCall:\nmultinom(formula = prog2 ~ ses + gender + write + read, data = students)\n\nCoefficients:\n         (Intercept)    seslow sesmiddle gendermale       write        read\ngeneral     2.621831 1.0038426 0.5651588  0.1273914 -0.02860308 -0.04730781\nvocation    6.505182 0.6239396 1.1539447 -0.3105237 -0.08243508 -0.07108839\n\nStd. Errors:\n         (Intercept)    seslow sesmiddle gendermale      write       read\ngeneral     1.434514 0.5323398 0.4713812  0.4137756 0.02686316 0.02480868\nvocation    1.524572 0.6200276 0.5231819  0.4414783 0.02793343 0.02752520\n\nResidual Deviance: 349.4508 \nAIC: 373.4508 \n\n\n\nz &lt;- summary(logmultinom)$coefficients/summary(logmultinom)$standard.errors\n# 2-tailed z test\np &lt;- (1 - pnorm(abs(z), 0, 1)) * 2\np\n\n          (Intercept)     seslow  sesmiddle gendermale       write        read\ngeneral  6.759775e-02 0.05933302 0.23055043  0.7581770 0.286980200 0.056532815\nvocation 1.982164e-05 0.31426675 0.02741006  0.4818237 0.003166173 0.009804037\n\n\n\n\n4.2.4 Odds Ratio\n\nexp(coef(logmultinom))\n\n         (Intercept)   seslow sesmiddle gendermale     write      read\ngeneral      13.7609 2.728747  1.759727   1.135862 0.9718021 0.9537938\nvocation    668.5973 1.866266  3.170676   0.733063 0.9208712 0.9313796\n\n\n\n\n4.2.5 Multikolineratitas\n\nlibrary(car)\nvif(logmultinom)\n\n            GVIF Df GVIF^(1/(2*Df))\nses     6.640420  2        1.605273\ngender  2.650955  1        1.628175\nwrite  66.396002  1        8.148374\nread   53.940932  1        7.344449\n\n\n\n\n4.2.6 Akurasi\n\ndf &lt;- students[,c(\"ses\",\"gender\",\"write\",\"read\")]\n\n\n#install.packages(\"caret\")\nlibrary(caret)\nprediksi &lt;- predict(logmultinom, df, type = \"class\")\nconfusionMatrix(as.factor(prediksi), \n                students$prog2)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction academic general vocation\n  academic       90      25       21\n  general         3       7        4\n  vocation       12      13       25\n\nOverall Statistics\n                                         \n               Accuracy : 0.61           \n                 95% CI : (0.5387, 0.678)\n    No Information Rate : 0.525          \n    P-Value [Acc &gt; NIR] : 0.009485       \n                                         \n                  Kappa : 0.3094         \n                                         \n Mcnemar's Test P-Value : 1.959e-05      \n\nStatistics by Class:\n\n                     Class: academic Class: general Class: vocation\nSensitivity                   0.8571         0.1556          0.5000\nSpecificity                   0.5158         0.9548          0.8333\nPos Pred Value                0.6618         0.5000          0.5000\nNeg Pred Value                0.7656         0.7957          0.8333\nPrevalence                    0.5250         0.2250          0.2500\nDetection Rate                0.4500         0.0350          0.1250\nDetection Prevalence          0.6800         0.0700          0.2500\nBalanced Accuracy             0.6865         0.5552          0.6667\n\n\n\n\n4.2.7 Kebaikan Model\n\nlogmultinom0 &lt;- multinom(prog2 ~ 1, data = students)\n\n# weights:  6 (2 variable)\ninitial  value 219.722458 \nfinal  value 204.096674 \nconverged\n\n#install.packages(\"lmtest\")\nlibrary(lmtest)\nlrtest(logmultinom0,logmultinom)\n\nLikelihood ratio test\n\nModel 1: prog2 ~ 1\nModel 2: prog2 ~ ses + gender + write + read\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   2 -204.10                         \n2  12 -174.72 10 58.743  6.263e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "03-Bab3.html#regresi-logistik-ordinal",
    "href": "03-Bab3.html#regresi-logistik-ordinal",
    "title": "4  Logistic Regression",
    "section": "4.3 Regresi Logistik Ordinal",
    "text": "4.3 Regresi Logistik Ordinal\n\n4.3.1 Data\n\ncrash &lt;- read.csv(\"Data/crash.csv\")\nhead(crash,10)\n\n   Gender Location SeatBelt Respon\n1  Female    Urban      Yes      1\n2    Male    Urban      Yes      1\n3    Male    Urban       No      1\n4  Female    Urban       No      1\n5    Male    Rural      Yes      1\n6  Female    Rural      Yes      1\n7    Male    Rural       No      1\n8  Female    Rural       No      1\n9  Female    Urban       No      3\n10 Female    Rural       No      3\n\n\n\nlibrary(dplyr)\ncrash &lt;- crash %&gt;% mutate(across(-c(Respon),as.factor))\nstr(crash)\n\n'data.frame':   80 obs. of  4 variables:\n $ Gender  : Factor w/ 2 levels \"Female\",\"Male\": 1 2 2 1 2 1 2 1 1 1 ...\n $ Location: Factor w/ 2 levels \"Rural\",\"Urban\": 2 2 2 2 1 1 1 1 2 1 ...\n $ SeatBelt: Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 1 2 2 1 1 1 1 ...\n $ Respon  : int  1 1 1 1 1 1 1 1 3 3 ...\n\n\n\ncrash$Respon &lt;- ordered(crash$Respon, levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"))\nstr(crash)\n\n'data.frame':   80 obs. of  4 variables:\n $ Gender  : Factor w/ 2 levels \"Female\",\"Male\": 1 2 2 1 2 1 2 1 1 1 ...\n $ Location: Factor w/ 2 levels \"Rural\",\"Urban\": 2 2 2 2 1 1 1 1 2 1 ...\n $ SeatBelt: Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 1 2 2 1 1 1 1 ...\n $ Respon  : Ord.factor w/ 5 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 1 1 1 1 1 1 1 1 3 3 ...\n\n\n\n\n4.3.2 Pemodelan\n\n#install.packages(\"MASS\")\nlibrary(MASS)\norderlog &lt;- polr(Respon~., method='logistic',data=crash)\nsummary(orderlog)\n\nCall:\npolr(formula = Respon ~ ., data = crash, method = \"logistic\")\n\nCoefficients:\n                 Value Std. Error t value\nGenderMale    -0.05369     0.3974 -0.1351\nLocationUrban  0.05661     0.3958  0.1430\nSeatBeltYes   -0.31102     0.3974 -0.7827\n\nIntercepts:\n    Value   Std. Error t value\n1|2 -1.5425  0.4450    -3.4664\n2|3 -0.5523  0.4060    -1.3603\n3|4  0.2649  0.3966     0.6678\n4|5  1.2472  0.4264     2.9249\n\nResidual Deviance: 256.8444 \nAIC: 270.8444 \n\n\n\n\n4.3.3 Odds Ratio\n\nkoefisien&lt;-coef(summary(orderlog)) \nexp(koefisien[,1])\n\n   GenderMale LocationUrban   SeatBeltYes           1|2           2|3 \n    0.9477303     1.0582414     0.7327004     0.2138542     0.5756362 \n          3|4           4|5 \n    1.3032362     3.4805710 \n\n\n\n# menghitung pvalue\np &lt;- pnorm(abs(koefisien[,\"t value\"]), lower.tail = FALSE)*2\n(ctabel&lt;-cbind(round(koefisien,2), \"pvalue\"=round(p,3))) \n\n              Value Std. Error t value pvalue\nGenderMale    -0.05       0.40   -0.14  0.893\nLocationUrban  0.06       0.40    0.14  0.886\nSeatBeltYes   -0.31       0.40   -0.78  0.434\n1|2           -1.54       0.44   -3.47  0.001\n2|3           -0.55       0.41   -1.36  0.174\n3|4            0.26       0.40    0.67  0.504\n4|5            1.25       0.43    2.92  0.003\n\n\n\n\n4.3.4 Multikolineratitas\n\nlibrary(car)\nvif(orderlog)\n\n  Gender Location SeatBelt \n1.002035 1.001265 1.001814 \n\n\n\n\n4.3.5 Akurasi\n\ndf &lt;- crash[,1:3]\nprediksi &lt;- predict(orderlog, df, type = \"class\")\nconfusionMatrix(as.factor(prediksi), \n                crash$Respon)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  1  2  3  4  5\n         1 10  8  7  7  8\n         2  0  0  0  0  0\n         3  0  0  0  0  0\n         4  0  0  0  0  0\n         5  6  8  9  9  8\n\nOverall Statistics\n                                          \n               Accuracy : 0.225           \n                 95% CI : (0.1391, 0.3321)\n    No Information Rate : 0.2             \n    P-Value [Acc &gt; NIR] : 0.3292          \n                                          \n                  Kappa : 0.0312          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5\nSensitivity            0.6250      0.0      0.0      0.0      0.5\nSpecificity            0.5312      1.0      1.0      1.0      0.5\nPos Pred Value         0.2500      NaN      NaN      NaN      0.2\nNeg Pred Value         0.8500      0.8      0.8      0.8      0.8\nPrevalence             0.2000      0.2      0.2      0.2      0.2\nDetection Rate         0.1250      0.0      0.0      0.0      0.1\nDetection Prevalence   0.5000      0.0      0.0      0.0      0.5\nBalanced Accuracy      0.5781      0.5      0.5      0.5      0.5\n\n\n\n\n4.3.6 Kebaikan Model\n\norderlog0 &lt;-polr(Respon~1, method = \"logistic\", data = crash)\n#install.packages(\"lmtest\")\nlibrary(lmtest)\nlrtest(orderlog0,orderlog)\n\nLikelihood ratio test\n\nModel 1: Respon ~ 1\nModel 2: Respon ~ Gender + Location + SeatBelt\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)\n1   4 -128.75                     \n2   7 -128.42  3 0.6657     0.8813",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "04-Bab4.html",
    "href": "04-Bab4.html",
    "title": "5  Discriminant Analysis",
    "section": "",
    "text": "5.1 Analisis Diskriminan Dua Grup",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "04-Bab4.html#analisis-diskriminan-dua-grup",
    "href": "04-Bab4.html#analisis-diskriminan-dua-grup",
    "title": "5  Discriminant Analysis",
    "section": "",
    "text": "5.1.1 Data\n\nlibrary(readxl)\npinjaman &lt;- read_excel(\"Data/pinjaman.xlsx\")\nhead(pinjaman,10)\n\n# A tibble: 10 × 6\n      X1    X2    X3    X4    X5     Y\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1    98    35    12     4     4     1\n 2    65    44     5     3     1     1\n 3    22    50     0     2     7     1\n 4    78    60    34     5     5     1\n 5    50    31     4     2     2     1\n 6    21    30     5     3     7     1\n 7    42    32    21     4    11     1\n 8    20    41    10     2     3     1\n 9    33    25     0     3     6     1\n10    57    32     8     2     5     1\n\n\n\nstr(pinjaman)\n\ntibble [32 × 6] (S3: tbl_df/tbl/data.frame)\n $ X1: num [1:32] 98 65 22 78 50 21 42 20 33 57 ...\n $ X2: num [1:32] 35 44 50 60 31 30 32 41 25 32 ...\n $ X3: num [1:32] 12 5 0 34 4 5 21 10 0 8 ...\n $ X4: num [1:32] 4 3 2 5 2 3 4 2 3 2 ...\n $ X5: num [1:32] 4 1 7 5 2 7 11 3 6 5 ...\n $ Y : num [1:32] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\npinjaman$Y &lt;- as.factor(pinjaman$Y)\nstr(pinjaman)\n\ntibble [32 × 6] (S3: tbl_df/tbl/data.frame)\n $ X1: num [1:32] 98 65 22 78 50 21 42 20 33 57 ...\n $ X2: num [1:32] 35 44 50 60 31 30 32 41 25 32 ...\n $ X3: num [1:32] 12 5 0 34 4 5 21 10 0 8 ...\n $ X4: num [1:32] 4 3 2 5 2 3 4 2 3 2 ...\n $ X5: num [1:32] 4 1 7 5 2 7 11 3 6 5 ...\n $ Y : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 2 2 2 2 ...\n\n\n\nlibrary(psych)\npairs.panels(pinjaman[1:5],\n             gap = 0,\n             bg = c(\"red\", \"green\")[pinjaman$Y],\n             pch = 21)\n\n\n\n\n\n\n\n\n\n\n5.1.2 Pemodelan Linier\n\nlibrary(MASS)\nmodellda1 &lt;- lda(Y ~ X1 + X2 + X3 + X4 + X5, data=pinjaman)\nmodellda1\n\nCall:\nlda(Y ~ X1 + X2 + X3 + X4 + X5, data = pinjaman)\n\nPrior probabilities of groups:\n     0      1 \n0.4375 0.5625 \n\nGroup means:\n        X1       X2       X3       X4       X5\n0 23.07143 26.78571 23.21429 3.428571 4.071429\n1 44.33333 34.38889 11.72222 2.888889 4.500000\n\nCoefficients of linear discriminants:\n            LD1\nX1  0.037015853\nX2 -0.004820049\nX3 -0.043555291\nX4 -0.477408359\nX5 -0.008483836\n\n\n\n\n5.1.3 Uji Signifikansi Fungsi Diskriminan\n\nm &lt;- manova(cbind(pinjaman$X1,pinjaman$X2,pinjaman$X3,\n                  pinjaman$X4,pinjaman$X5) ~ pinjaman$Y)\nsummary(m, test = 'Wilks')\n\n           Df   Wilks approx F num Df den Df  Pr(&gt;F)  \npinjaman$Y  1 0.62715   3.0915      5     26 0.02544 *\nResiduals  30                                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n5.1.4 Akurasi\n\np &lt;- predict(modellda1, pinjaman)\nldahist(data = p$x, g = pinjaman$Y)\n\n\n\n\n\n\n\n\n\nlibrary(caret)\nconfusionMatrix(p$class,pinjaman$Y)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0  9  4\n         1  5 14\n                                          \n               Accuracy : 0.7188          \n                 95% CI : (0.5325, 0.8625)\n    No Information Rate : 0.5625          \n    P-Value [Acc &gt; NIR] : 0.0523          \n                                          \n                  Kappa : 0.424           \n                                          \n Mcnemar's Test P-Value : 1.0000          \n                                          \n            Sensitivity : 0.6429          \n            Specificity : 0.7778          \n         Pos Pred Value : 0.6923          \n         Neg Pred Value : 0.7368          \n             Prevalence : 0.4375          \n         Detection Rate : 0.2812          \n   Detection Prevalence : 0.4062          \n      Balanced Accuracy : 0.7103          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\n\nmean(p$class==pinjaman$Y)\n\n[1] 0.71875\n\n\n\n#install.packages(\"klaR\")\nlibrary(klaR)\n#Partition plot\npartimat(Y~., data = pinjaman, method = \"lda\")\n\n\n\n\n\n\n\n\n\npartimat(Y~., data = pinjaman, method = \"qda\")\n\n\n\n\n\n\n\n\n\n\n5.1.5 Pemodelan Quadratik\n\nmodellda2 &lt;- qda(Y ~ X1 + X2 + X3 + X4 + X5, data=pinjaman)\nmodellda2\n\nCall:\nqda(Y ~ X1 + X2 + X3 + X4 + X5, data = pinjaman)\n\nPrior probabilities of groups:\n     0      1 \n0.4375 0.5625 \n\nGroup means:\n        X1       X2       X3       X4       X5\n0 23.07143 26.78571 23.21429 3.428571 4.071429\n1 44.33333 34.38889 11.72222 2.888889 4.500000\n\n\n\np &lt;- predict(modellda2, pinjaman)\nmean(p$class==pinjaman$Y)\n\n[1] 0.84375\n\n\n\n\n5.1.6 Tipe Diskriminan Lainnya\n\n# Mixture discriminant analysis - MDA\n# install.packages(\"mda\")\nlibrary(mda)\nmodellda3 &lt;- mda(Y ~ X1 + X2 + X3 + X4 + X5, data=pinjaman)\np &lt;- predict(modellda3, pinjaman)\nmean(p==pinjaman$Y)\n\n[1] 0.875\n\n\n\n# Flexible discriminant analysis - FDA\nmodellda4 &lt;- fda(Y ~ X1 + X2 + X3 + X4 + X5, data=pinjaman)\np &lt;- predict(modellda4, pinjaman)\nmean(p==pinjaman$Y)\n\n[1] 0.71875\n\n\n\n# Regularized discriminant analysis - RDA\nmodellda5 &lt;- rda(Y ~ X1 + X2 + X3 + X4 + X5, data=pinjaman)\np &lt;- predict(modellda5, pinjaman)\nmean(p$class==pinjaman$Y)\n\n[1] 0.71875",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "04-Bab4.html#analisis-diskriminan-tiga-grup",
    "href": "04-Bab4.html#analisis-diskriminan-tiga-grup",
    "title": "5  Discriminant Analysis",
    "section": "5.2 Analisis Diskriminan Tiga Grup",
    "text": "5.2 Analisis Diskriminan Tiga Grup\n\n5.2.1 Data\n\ndata(\"iris\")\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\nlibrary(MASS)\nlda.iris &lt;- lda(Species ~ ., iris)\nlda.iris \n\nCall:\nlda(Species ~ ., data = iris)\n\nPrior probabilities of groups:\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\nGroup means:\n           Sepal.Length Sepal.Width Petal.Length Petal.Width\nsetosa            5.006       3.428        1.462       0.246\nversicolor        5.936       2.770        4.260       1.326\nvirginica         6.588       2.974        5.552       2.026\n\nCoefficients of linear discriminants:\n                    LD1         LD2\nSepal.Length  0.8293776 -0.02410215\nSepal.Width   1.5344731 -2.16452123\nPetal.Length -2.2012117  0.93192121\nPetal.Width  -2.8104603 -2.83918785\n\nProportion of trace:\n   LD1    LD2 \n0.9912 0.0088 \n\n\n\n\n5.2.2 Uji Signifikansi Fungsi Diskriminan\n\nm &lt;- manova(cbind(iris$Sepal.Length,iris$Sepal.Width,iris$Petal.Length,\n                  iris$Petal.Width) ~ iris$Species)\nsummary(m, test = 'Wilks')\n\n              Df    Wilks approx F num Df den Df    Pr(&gt;F)    \niris$Species   2 0.023439   199.15      8    288 &lt; 2.2e-16 ***\nResiduals    147                                              \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n5.2.3 Akurasi\n\np &lt;- predict(lda.iris, iris)\nldahist(data = p$x, g = iris$Species)\n\n\n\n\n\n\n\n\n\ntable(p$class,iris$Species)\n\n            \n             setosa versicolor virginica\n  setosa         50          0         0\n  versicolor      0         48         1\n  virginica       0          2        49\n\n\n\nmean(p$class==iris$Species)\n\n[1] 0.98\n\n\n\n\n5.2.4 Visualisasi\n\nlibrary(ggplot2)\nlda.data &lt;- cbind(iris,  p$x)\nggplot(lda.data, aes(LD1, LD2)) +\n  geom_point(aes(color = Species)) + theme_classic()\n\n\n\n\n\n\n\n\n\n\n5.2.5 Pemodelan Quadratik\n\nqda.iris &lt;- qda(Species ~ ., data=iris)\nqda.iris\n\nCall:\nqda(Species ~ ., data = iris)\n\nPrior probabilities of groups:\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\nGroup means:\n           Sepal.Length Sepal.Width Petal.Length Petal.Width\nsetosa            5.006       3.428        1.462       0.246\nversicolor        5.936       2.770        4.260       1.326\nvirginica         6.588       2.974        5.552       2.026\n\np &lt;- predict(qda.iris, iris)\nmean(p$class==iris$Species)\n\n[1] 0.98\n\n\n\n\n5.2.6 Tipe Diskriminan Lainnya\n\n# Mixture discriminant analysis - MDA\n# install.packages(\"mda\")\nlibrary(mda)\nmda.iris &lt;- mda(Species ~ ., data=iris)\nmda.iris\n\nCall:\nmda(formula = Species ~ ., data = iris)\n\nDimension: 4 \n\nPercent Between-Group Variance Explained:\n    v1     v2     v3     v4 \n 96.14  98.47  99.89 100.00 \n\nDegrees of Freedom (per dimension): 5 \n\nTraining Misclassification Error: 0.02 ( N = 150 )\n\nDeviance: 15.249 \n\np &lt;- predict(mda.iris, iris)\nmean(p==iris$Species)\n\n[1] 0.98\n\n\n\n# Flexible discriminant analysis - FDA\nfda.iris &lt;- fda(Species ~ ., data=iris)\nfda.iris\n\nCall:\nfda(formula = Species ~ ., data = iris)\n\nDimension: 2 \n\nPercent Between-Group Variance Explained:\n    v1     v2 \n 99.12 100.00 \n\nDegrees of Freedom (per dimension): 5 \n\nTraining Misclassification Error: 0.02 ( N = 150 )\n\np &lt;- predict(fda.iris, iris)\nmean(p==iris$Species)\n\n[1] 0.98\n\n\n\n# Regularized discriminant analysis - RDA\nrda.iris &lt;- rda(Species ~ ., data=iris)\nrda.iris\n\nCall: \nrda(formula = Species ~ ., data = iris)\n\nRegularization parameters: \n    gamma    lambda \n0.1051791 0.9596476 \n\nPrior probabilities of groups: \n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\nMisclassification rate: \n       apparent: 2 %\ncross-validated: 2 %\n\np &lt;- predict(rda.iris, iris)\nmean(p$class==iris$Species)\n\n[1] 0.98",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "05-Bab5.html",
    "href": "05-Bab5.html",
    "title": "6  Cluster Analysis",
    "section": "",
    "text": "6.1 Metode berhirarki\nRef: https://rpubs.com/odenipinedo/cluster-analysis-in-R\nlibrary(readxl)\nProvinsi &lt;- read_excel(\"Data/provinsi.xlsx\")\nProv.scaled = scale(Provinsi[,c(4:8)])\nrownames(Prov.scaled) = Provinsi$Provinsi\nhead(Prov.scaled)\n\n               IPM         UHH        RLS         PPK       Gini\nAceh    0.20822137  0.04044611  0.7444782 -0.62264434 -0.8089350\nSumut   0.20085709 -0.39282591  1.0245728 -0.11277090 -0.6516207\nSumbar  0.36532598 -0.23835502  0.4747574  0.01481560 -1.2546590\nRiau    0.50033775  0.59428078  0.5162529  0.19012890 -0.9138112\nJambi   0.05848104  0.50762638 -0.1165536 -0.18648754 -0.6778397\nSumsel -0.21890679 -0.08765171 -0.2825356 -0.02582306  0.1349510\n## membuat dissimilarity matrix\ndprov = dist(Prov.scaled, method=\"euclidean\")\nc.comp = hclust(dprov, method = \"complete\")\ncor(dprov , cophenetic(c.comp))\n\n[1] 0.7853523\nc.sing = hclust(dprov, method = \"single\")\ncor(dprov , cophenetic(c.sing))\n\n[1] 0.7905858\nc.avrg = hclust(dprov, method = \"average\")\ncor(dprov , cophenetic(c.avrg))\n\n[1] 0.8092689\nc.ward = hclust(dprov, method = \"ward.D\")\ncor(dprov , cophenetic(c.ward))\n\n[1] 0.5336018\nc.ctrd = hclust(dprov, method = \"centroid\")\ncor(dprov , cophenetic(c.ctrd))\n\n[1] 0.7700878\nlibrary(factoextra)\nfviz_dend(c.avrg, cex = 0.5, \n          main = \"Cluster Dendrogram average linkage\")\navg_coph &lt;- cophenetic(c.avrg)\navg_clust &lt;- cutree(c.avrg, k = 4)\ntable(avg_clust)\n\navg_clust\n 1  2  3  4 \n26  1  1  6\nfviz_dend(c.avrg, k = 4, \n          k_colors = \"jco\", \n          rect = T, \n          main = \"Average Linkage Cluster\")\nlibrary(clValid)\nlibrary(cluster)\n# internal measures\ninternal &lt;- clValid(Prov.scaled, nClust = 2:6, \n                    clMethods = \"hierarchical\", \n                    validation = \"internal\", \n                    metric = \"euclidean\",\n                    method = \"average\")\nsummary(internal)\n\n\nClustering Methods:\n hierarchical \n\nCluster sizes:\n 2 3 4 5 6 \n\nValidation Measures:\n                                 2       3       4       5       6\n                                                                  \nhierarchical Connectivity   4.5246 10.3012 11.6345 18.3198 24.1508\n             Dunn           0.3637  0.3703  0.3703  0.3224  0.3592\n             Silhouette     0.4915  0.3484  0.3092  0.2567  0.3117\n\nOptimal Scores:\n\n             Score  Method       Clusters\nConnectivity 4.5246 hierarchical 2       \nDunn         0.3703 hierarchical 3       \nSilhouette   0.4915 hierarchical 2\nfviz_dend(c.avrg, k = 2, \n          k_colors = \"jco\", \n          rect = T, \n          main = \"Average Linkage Cluster\")\ngroup = cutree(c.avrg, k = 2)\ngroup\n\n     Aceh     Sumut    Sumbar      Riau     Jambi    Sumsel  Bengkulu   Lampung \n        1         1         1         1         1         1         1         1 \n    Babel     Kepri       DKI     Jabar    Jateng       DIY     Jatim    Banten \n        1         1         2         1         1         2         1         1 \n     Bali       NTB       NTT    Kalbar   Kalteng    Kalsel    Kaltim   Kaltara \n        1         1         1         1         1         1         1         1 \n    Sulut   Sulteng    Sulsel    Sultra Gorontalo    Sulbar    Maluku     Malut \n        1         1         1         1         1         1         1         1 \n    Pabar     Papua \n        1         1\nfviz_cluster(list(data = Prov.scaled, \n                  cluster = group)) + \n  theme_minimal()\nprcomp(Prov.scaled)\n\nStandard deviations (1, .., p=5):\n[1] 1.7653705 1.0227284 0.7270850 0.5299864 0.1671984\n\nRotation (n x k) = (5 x 5):\n            PC1         PC2          PC3           PC4         PC5\nIPM  -0.5601680 -0.05311199 -0.005227509 -0.0006949187 -0.82665781\nUHH  -0.4513030  0.05646383 -0.811065327  0.2024129889  0.30714735\nRLS  -0.4591728 -0.33781331  0.497619343  0.5648220282  0.32923179\nPPK  -0.5069166  0.09086739  0.227624805 -0.7546468667  0.33685862\nGini -0.1213811  0.93360390  0.206658283  0.2655422416  0.02073819",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Cluster Analysis</span>"
    ]
  },
  {
    "objectID": "05-Bab5.html#metode-tidak-berhirarki---kmeans",
    "href": "05-Bab5.html#metode-tidak-berhirarki---kmeans",
    "title": "6  Cluster Analysis",
    "section": "6.2 Metode tidak berhirarki - kmeans",
    "text": "6.2 Metode tidak berhirarki - kmeans\n\nfviz_nbclust(Prov.scaled, kmeans, method = \"wss\")\n\n\n\n\n\n\n\n\n\nfviz_nbclust(Prov.scaled, kmeans, method = \"silhouette\")\n\n\n\n\n\n\n\n\n\nset.seed(1)\nkm = kmeans(Prov.scaled, centers=4)\nkm\n\nK-means clustering with 4 clusters of sizes 5, 7, 16, 6\n\nCluster means:\n          IPM        UHH        RLS         PPK       Gini\n1  1.67223995  1.1202353  1.3689855  1.75840321  0.6331131\n2  0.22785944  0.6620973 -0.1491572  0.09292014  0.9739608\n3 -0.08819085 -0.1001318  0.1246391 -0.24567350 -0.7991029\n4 -1.42419372 -1.4389581 -1.2991755 -0.91861351  0.4670591\n\nClustering vector:\n     Aceh     Sumut    Sumbar      Riau     Jambi    Sumsel  Bengkulu   Lampung \n        3         3         3         3         3         3         3         3 \n    Babel     Kepri       DKI     Jabar    Jateng       DIY     Jatim    Banten \n        3         1         1         2         2         1         2         2 \n     Bali       NTB       NTT    Kalbar   Kalteng    Kalsel    Kaltim   Kaltara \n        1         4         4         3         3         3         1         3 \n    Sulut   Sulteng    Sulsel    Sultra Gorontalo    Sulbar    Maluku     Malut \n        2         3         2         2         4         4         3         3 \n    Pabar     Papua \n        4         4 \n\nWithin cluster sum of squares by cluster:\n[1] 17.054859  7.933134 22.111511  7.711994\n (between_SS / total_SS =  66.8 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\nfviz_cluster(list(data = Prov.scaled, cluster = km$cluster)) + theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Cluster Analysis</span>"
    ]
  },
  {
    "objectID": "06-Bab6.html",
    "href": "06-Bab6.html",
    "title": "7  PCA Analysis and Biplot",
    "section": "",
    "text": "7.1 PCA\n# impor data dari excel, beri nama: Provinsi\nlibrary(readxl)\nProvinsi = read_excel(\"Data/provinsi.xlsx\")\nProv.scaled = scale(Provinsi[,c(4:8)])\nround(cor(Prov.scaled),3)\n\n       IPM   UHH    RLS   PPK   Gini\nIPM  1.000 0.780  0.811 0.872  0.159\nUHH  0.780 1.000  0.447 0.581  0.153\nRLS  0.811 0.447  1.000 0.637 -0.059\nPPK  0.872 0.581  0.637 1.000  0.249\nGini 0.159 0.153 -0.059 0.249  1.000\n# PCA langkah manual\nProv.eigen = eigen(cov(Prov.scaled))\nProv.eigen\n\neigen() decomposition\n$values\n[1] 3.11653307 1.04597347 0.52865259 0.28088555 0.02795532\n\n$vectors\n           [,1]        [,2]         [,3]          [,4]        [,5]\n[1,] -0.5601680 -0.05311199  0.005227509 -0.0006949187  0.82665781\n[2,] -0.4513030  0.05646383  0.811065327  0.2024129889 -0.30714735\n[3,] -0.4591728 -0.33781331 -0.497619343  0.5648220282 -0.32923179\n[4,] -0.5069166  0.09086739 -0.227624805 -0.7546468667 -0.33685862\n[5,] -0.1213811  0.93360390 -0.206658283  0.2655422416 -0.02073819\nProv.eigen$values\n\n[1] 3.11653307 1.04597347 0.52865259 0.28088555 0.02795532\n\nProv.eigen$values/5\n\n[1] 0.623306615 0.209194694 0.105730518 0.056177109 0.005591064\n\ncumsum(Prov.eigen$values/5)\n\n[1] 0.6233066 0.8325013 0.9382318 0.9944089 1.0000000\nProv.pc = as.matrix(Prov.scaled) %*% Prov.eigen$vectors\nround(Prov.pc,3)\n\n        [,1]   [,2]   [,3]   [,4]   [,5]\n [1,] -0.063 -1.072 -0.028  0.684  0.141\n [2,] -0.269 -0.998 -0.667  0.411  0.001\n [3,] -0.170 -1.363 -0.172 -0.125  0.240\n [4,] -0.771 -1.003  0.373  0.025  0.016\n [5,] -0.032 -0.585  0.653 -0.002  0.008\n [6,]  0.289  0.226  0.046 -0.122 -0.055\n [7,]  0.167 -0.380 -0.246  0.160  0.149\n [8,]  0.632 -0.498  0.644 -0.115 -0.054\n [9,] -0.057 -1.798  0.675 -1.464 -0.089\n[10,] -2.171 -0.475 -1.111 -0.280 -0.100\n[11,] -5.201  0.488 -1.517 -0.455 -0.423\n[12,] -0.699  0.908  0.818  0.388 -0.141\n[13,] -0.467  0.567  1.901 -0.226 -0.064\n[14,] -3.637  1.770  0.377  0.349  0.361\n[15,] -0.211  1.726  0.527 -0.300  0.118\n[16,] -0.763  0.414 -0.365 -0.198  0.007\n[17,] -1.962  0.494  0.024 -0.719  0.052\n[18,]  1.779  0.864 -0.537 -0.824  0.322\n[19,]  2.630  0.251 -0.136  0.131  0.011\n[20,]  1.501 -0.351  1.137 -0.243 -0.049\n[21,]  0.004 -0.801  0.195 -0.277 -0.039\n[22,]  0.104 -0.191 -0.358 -0.828  0.030\n[23,] -2.225 -0.963  0.752  0.305  0.020\n[24,] -0.162 -1.278  1.179  0.698 -0.173\n[25,] -1.101  0.544 -0.154  0.823 -0.143\n[26,]  0.847 -0.438 -0.472  0.097  0.061\n[27,] -0.276  1.813 -0.105  0.254  0.105\n[28,] -0.147  0.982  0.109  0.925 -0.004\n[29,]  1.266  1.405 -0.356 -0.169  0.136\n[30,]  2.501 -0.280 -0.787 -0.540  0.062\n[31,]  0.929 -1.487 -1.397  0.735  0.080\n[32,]  1.193 -0.966 -0.326  0.739 -0.008\n[33,]  2.735  0.936 -0.533  0.218 -0.091\n[34,]  3.806  1.539 -0.145 -0.057 -0.487\n# dengan fungsi prcomp\npc = prcomp(x = Prov.scaled, center=TRUE, scale=TRUE)\nsummary(pc)\n\nImportance of components:\n                          PC1    PC2    PC3     PC4     PC5\nStandard deviation     1.7654 1.0227 0.7271 0.52999 0.16720\nProportion of Variance 0.6233 0.2092 0.1057 0.05618 0.00559\nCumulative Proportion  0.6233 0.8325 0.9382 0.99441 1.00000\n\nround(pc$x,3)#scores\n\n         PC1    PC2    PC3    PC4    PC5\n [1,] -0.063 -1.072  0.028  0.684 -0.141\n [2,] -0.269 -0.998  0.667  0.411 -0.001\n [3,] -0.170 -1.363  0.172 -0.125 -0.240\n [4,] -0.771 -1.003 -0.373  0.025 -0.016\n [5,] -0.032 -0.585 -0.653 -0.002 -0.008\n [6,]  0.289  0.226 -0.046 -0.122  0.055\n [7,]  0.167 -0.380  0.246  0.160 -0.149\n [8,]  0.632 -0.498 -0.644 -0.115  0.054\n [9,] -0.057 -1.798 -0.675 -1.464  0.089\n[10,] -2.171 -0.475  1.111 -0.280  0.100\n[11,] -5.201  0.488  1.517 -0.455  0.423\n[12,] -0.699  0.908 -0.818  0.388  0.141\n[13,] -0.467  0.567 -1.901 -0.226  0.064\n[14,] -3.637  1.770 -0.377  0.349 -0.361\n[15,] -0.211  1.726 -0.527 -0.300 -0.118\n[16,] -0.763  0.414  0.365 -0.198 -0.007\n[17,] -1.962  0.494 -0.024 -0.719 -0.052\n[18,]  1.779  0.864  0.537 -0.824 -0.322\n[19,]  2.630  0.251  0.136  0.131 -0.011\n[20,]  1.501 -0.351 -1.137 -0.243  0.049\n[21,]  0.004 -0.801 -0.195 -0.277  0.039\n[22,]  0.104 -0.191  0.358 -0.828 -0.030\n[23,] -2.225 -0.963 -0.752  0.305 -0.020\n[24,] -0.162 -1.278 -1.179  0.698  0.173\n[25,] -1.101  0.544  0.154  0.823  0.143\n[26,]  0.847 -0.438  0.472  0.097 -0.061\n[27,] -0.276  1.813  0.105  0.254 -0.105\n[28,] -0.147  0.982 -0.109  0.925  0.004\n[29,]  1.266  1.405  0.356 -0.169 -0.136\n[30,]  2.501 -0.280  0.787 -0.540 -0.062\n[31,]  0.929 -1.487  1.397  0.735 -0.080\n[32,]  1.193 -0.966  0.326  0.739  0.008\n[33,]  2.735  0.936  0.533  0.218  0.091\n[34,]  3.806  1.539  0.145 -0.057  0.487\nround(pc$rotation,3)  #loadings\n\n        PC1    PC2    PC3    PC4    PC5\nIPM  -0.560 -0.053 -0.005 -0.001 -0.827\nUHH  -0.451  0.056 -0.811  0.202  0.307\nRLS  -0.459 -0.338  0.498  0.565  0.329\nPPK  -0.507  0.091  0.228 -0.755  0.337\nGini -0.121  0.934  0.207  0.266  0.021\nplot(pc)\n\n\n\n\n\n\n\nscreeplot(x = pc, type=\"line\", main=\"Scree plot\")\n# korelasi variabel asli dengan PC\ndata = cbind(Prov.pc, Prov.scaled)\nkorelasi = cor(data)\nkorelasi[6:10,1:2]\n\n                           \nIPM  -0.9889040 -0.05431915\nUHH  -0.7967169  0.05774717\nRLS  -0.8106101 -0.34549128\nPPK  -0.8948956  0.09293267\nGini -0.2142826  0.95482326",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>PCA Analysis and Biplot</span>"
    ]
  },
  {
    "objectID": "06-Bab6.html#biplot",
    "href": "06-Bab6.html#biplot",
    "title": "7  PCA Analysis and Biplot",
    "section": "7.2 Biplot",
    "text": "7.2 Biplot\n\n# biplot\nlibrary(factoextra)\nfviz_pca(pc)\n\n\n\n\n\n\n\n\n\n# alternatif bentuk biplot\n# install.packages(\"remotes\")\n# remotes::install_github(\"vqv/ggbiplot\")\nlibrary(ggbiplot)\nggbiplot(pc)\n\n\n\n\n\n\n\n\n\nbiplot = ggbiplot(pcobj = pc,\n                  choices = c(1,2),\n                  obs.scale = 1, var.scale = 1,\n                  labels = row.names(Provinsi),\n                  varname.size = 3,\n                  varname.abbrev = FALSE,\n                  var.axes = TRUE,\n                  group = Provinsi$Region)\nbiplot\n\n\n\n\n\n\n\n\n\nbiplot2 = biplot + theme_bw() + \n  theme(legend.position=\"bottom\") + \n  labs(\n  title = \"PCA Indikator Kualitas Hidup Provinsi\", \n  color = \"Region\")\nbiplot2",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>PCA Analysis and Biplot</span>"
    ]
  },
  {
    "objectID": "07-Bab7.html",
    "href": "07-Bab7.html",
    "title": "8  Factor Analysis and Structural Equation Modeling (SEM)",
    "section": "",
    "text": "8.1 Analisis Faktor\nharga &lt;- read.csv(\"Data/harga.csv\")\nhead(harga)\n\n         City Bread Burger Milk Oranges Tomatoes\n1    Atlanta   24.5   94.5 73.9    80.1     41.6\n2  Baltimore   26.5   91.0 67.5    74.6     33.3\n3     Boston   29.7  100.8 61.4   104.0     59.6\n4    Buffalo   22.8   86.6 65.3   118.4     61.2\n5    Chicago   26.7   86.7 62.7   105.9     60.2\n6 Cincinnati   25.3  102.5 63.3    99.3     45.6\nstr(harga)\n\n'data.frame':   23 obs. of  6 variables:\n $ City    : chr  \"Atlanta \" \"Baltimore \" \"Boston \" \"Buffalo \" ...\n $ Bread   : num  24.5 26.5 29.7 22.8 26.7 25.3 22.8 23.3 24.1 29.3 ...\n $ Burger  : num  94.5 91 100.8 86.6 86.7 ...\n $ Milk    : num  73.9 67.5 61.4 65.3 62.7 63.3 52.4 62.5 51.5 80.2 ...\n $ Oranges : num  80.1 74.6 104 118.4 105.9 ...\n $ Tomatoes: num  41.6 33.3 59.6 61.2 60.2 45.6 60.1 60.8 60.5 71.7 ...",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Factor Analysis and Structural Equation Modeling (SEM)</span>"
    ]
  },
  {
    "objectID": "07-Bab7.html#analisis-faktor",
    "href": "07-Bab7.html#analisis-faktor",
    "title": "8  Factor Analysis and Structural Equation Modeling (SEM)",
    "section": "",
    "text": "8.1.1 EFA\n\nlibrary(corrplot)\ncorrplot(cor(harga[,2:6]), method=\"number\")\n\n\n\n\n\n\n\n\n\nlibrary(psych)\nKMO(harga[,2:6])\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = harga[, 2:6])\nOverall MSA =  0.52\nMSA for each item = \n   Bread   Burger     Milk  Oranges Tomatoes \n    0.52     0.58     0.59     0.49     0.48 \n\n\n\n# Bartlett's Test of Sphericity\ncortest.bartlett(harga[,2:6])\n\n$chisq\n[1] 36.46285\n\n$p.value\n[1] 7.006877e-05\n\n$df\n[1] 10\n\n\n\n# Anti image correlation (AIC)\ncorrplot(KMO(harga[,2:6])$ImCo, method=\"number\") \n\n\n\n\n\n\n\n\n\n# Determinan positif\ndet(cor(harga[,2:6]))\n\n[1] 0.1541406\n\n\n\n# Principal component analysis (PCA)\npca1 = princomp(harga[,2:6], scores=TRUE, cor=TRUE)\nsummary(pca1)\n\nImportance of components:\n                          Comp.1    Comp.2    Comp.3     Comp.4     Comp.5\nStandard deviation     1.4841538 1.2325047 0.8824610 0.55357732 0.43935672\nProportion of Variance 0.4405425 0.3038136 0.1557475 0.06128957 0.03860687\nCumulative Proportion  0.4405425 0.7443561 0.9001036 0.96139313 1.00000000\n\n\n\nscree(harga[,2:6])\n\n\n\n\n\n\n\n\n\n# Menentukan faktor loading Analisis faktor loading\nloadings(pca1)\n\n\nLoadings:\n         Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nBread     0.436  0.484  0.354  0.597  0.306\nBurger    0.542  0.292  0.307 -0.657 -0.309\nMilk      0.346  0.308 -0.866        -0.163\nOranges   0.410 -0.579  0.108  0.399 -0.571\nTomatoes  0.478 -0.500 -0.137 -0.211  0.677\n\n               Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nSS loadings       1.0    1.0    1.0    1.0    1.0\nProportion Var    0.2    0.2    0.2    0.2    0.2\nCumulative Var    0.2    0.4    0.6    0.8    1.0\n\n\n\n# Rotasi untuk mengkonfirmasi hasil analisis loading\nfa1 = factanal(harga[,2:6], factor=2, rotation=\"varimax\")\nfa1\n\n\nCall:\nfactanal(x = harga[, 2:6], factors = 2, rotation = \"varimax\")\n\nUniquenesses:\n   Bread   Burger     Milk  Oranges Tomatoes \n   0.239    0.318    0.830    0.420    0.005 \n\nLoadings:\n         Factor1 Factor2\nBread             0.868 \nBurger    0.195   0.803 \nMilk      0.135   0.390 \nOranges   0.756         \nTomatoes  0.985   0.157 \n\n               Factor1 Factor2\nSS loadings      1.605   1.583\nProportion Var   0.321   0.317\nCumulative Var   0.321   0.638\n\nTest of the hypothesis that 2 factors are sufficient.\nThe chi square statistic is 1.16 on 1 degree of freedom.\nThe p-value is 0.282 \n\n\n\n# Diagram jalur hasil analisis EFA dan menampilkan faktor loading-nya\nfa.diagram(fa1$loadings, digits = 3)\n\n\n\n\n\n\n\n\n\n\n8.1.2 CFA\n\n# Spesifikasi model\nattach(harga)\nmodel1 &lt;- \"\nF1 =~ Tomatoes + Oranges\nF2 =~ Bread + Burger + Milk\nF1 ~~ F2 \"\n\n\nlibrary(lavaan)\nfitmod = cfa(model1, data = harga)\nsummary(fitmod, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-19 ended normally after 85 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        11\n\n  Number of observations                            23\n\nModel Test User Model:\n                                                      \n  Test statistic                                 3.642\n  Degrees of freedom                                 4\n  P-value (Chi-square)                           0.457\n\nModel Test Baseline Model:\n\n  Test statistic                                43.007\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.027\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -367.812\n  Loglikelihood unrestricted model (H1)       -365.991\n                                                      \n  Akaike (AIC)                                 757.623\n  Bayesian (BIC)                               770.114\n  Sample-size adjusted Bayesian (SABIC)        736.072\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.302\n  P-value H_0: RMSEA &lt;= 0.050                    0.487\n  P-value H_0: RMSEA &gt;= 0.080                    0.469\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.065\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  F1 =~                                                                 \n    Tomatoes          1.000                              10.659    1.062\n    Oranges           0.934    0.580    1.611    0.107    9.952    0.715\n  F2 =~                                                                 \n    Bread             1.000                               1.622    0.662\n    Burger            4.700    2.464    1.907    0.056    7.623    1.032\n    Milk              1.307    0.858    1.523    0.128    2.119    0.312\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  F1 ~~                                                                 \n    F2                5.161    4.482    1.151    0.250    0.299    0.299\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Tomatoes        -12.966   66.742   -0.194    0.846  -12.966   -0.129\n   .Oranges          94.906   64.476    1.472    0.141   94.906    0.489\n   .Bread             3.381    1.581    2.138    0.033    3.381    0.562\n   .Burger           -3.518   27.199   -0.129    0.897   -3.518   -0.064\n   .Milk             41.714   12.439    3.354    0.001   41.714    0.903\n    F1              113.605   72.842    1.560    0.119    1.000    1.000\n    F2                2.631    1.912    1.376    0.169    1.000    1.000\n\n\n\nfitmeasures(fitmod)\n\n                 npar                  fmin                 chisq \n               11.000                 0.079                 3.642 \n                   df                pvalue        baseline.chisq \n                4.000                 0.457                43.007 \n          baseline.df       baseline.pvalue                   cfi \n               10.000                 0.000                 1.000 \n                  tli                  nnfi                   rfi \n                1.027                 1.027                 0.788 \n                  nfi                  pnfi                   ifi \n                0.915                 0.366                 1.009 \n                  rni                  logl     unrestricted.logl \n                1.011              -367.812              -365.991 \n                  aic                   bic                ntotal \n              757.623               770.114                23.000 \n                 bic2                 rmsea        rmsea.ci.lower \n              736.072                 0.000                 0.000 \n       rmsea.ci.upper        rmsea.ci.level          rmsea.pvalue \n                0.302                 0.900                 0.487 \n       rmsea.close.h0 rmsea.notclose.pvalue     rmsea.notclose.h0 \n                0.050                 0.469                 0.080 \n                  rmr            rmr_nomean                  srmr \n                2.823                 2.823                 0.065 \n         srmr_bentler   srmr_bentler_nomean                  crmr \n                0.065                 0.065                 0.080 \n          crmr_nomean            srmr_mplus     srmr_mplus_nomean \n                0.080                 0.065                 0.065 \n                cn_05                 cn_01                   gfi \n               60.915                84.843                 0.947 \n                 agfi                  pgfi                   mfi \n                0.803                 0.253                 1.008 \n                 ecvi \n                1.115 \n\n\n\nlibrary(semPlot)\nsemPaths(fitmod, what='std', layout='tree', title = TRUE, \n         posCol = 1, nDigits = 3, \n         edge.label.cex=0.7, \n         exoVar = FALSE, \n         sizeMan = 5, \n         sizeLat = 5)\n\n\n\n\n\n\n\n\n\n# Estimasi Reliabilitas alpha cronbach\npsych::alpha(harga[,2:6])\n\n\nReliability analysis   \nCall: psych::alpha(x = harga[, 2:6])\n\n  raw_alpha std.alpha G6(smc) average_r S/N ase mean  sd median_r\n      0.63      0.67    0.77      0.29 2.1 0.1   67 5.8     0.26\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.32  0.63  0.82\nDuhachek  0.42  0.63  0.83\n\n Reliability if an item is dropped:\n         raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nBread         0.64      0.63    0.68      0.30 1.7    0.110 0.065  0.26\nBurger        0.56      0.54    0.63      0.23 1.2    0.107 0.083  0.13\nMilk          0.64      0.68    0.78      0.34 2.1    0.091 0.096  0.26\nOranges       0.55      0.65    0.66      0.32 1.9    0.140 0.043  0.32\nTomatoes      0.37      0.59    0.61      0.26 1.4    0.197 0.062  0.27\n\n Item statistics \n          n raw.r std.r r.cor r.drop mean   sd\nBread    23  0.38  0.64  0.56   0.30   25  2.5\nBurger   23  0.62  0.77  0.72   0.41   92  7.6\nMilk     23  0.42  0.56  0.36   0.20   62  7.0\nOranges  23  0.82  0.61  0.56   0.49  103 14.2\nTomatoes 23  0.86  0.71  0.68   0.71   52 10.3",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Factor Analysis and Structural Equation Modeling (SEM)</span>"
    ]
  },
  {
    "objectID": "07-Bab7.html#model-persamaan-struktural-sem",
    "href": "07-Bab7.html#model-persamaan-struktural-sem",
    "title": "8  Factor Analysis and Structural Equation Modeling (SEM)",
    "section": "8.2 Model Persamaan Struktural (SEM)",
    "text": "8.2 Model Persamaan Struktural (SEM)\n\nlibrary(lavaan)  \nlibrary(semPlot)\n\n\nlibrary(readxl)\ndatasem &lt;- read_excel(\"Data/Datalikert.xlsx\")\nhead(datasem[,1:5])\n\n# A tibble: 6 × 5\n  Perusahaan Provinsi   Pulau    A1    A2\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1          1 Jawa Barat Jawa      4     5\n2          2 Jawa Timur Jawa      5     5\n3          3 Jawa Timur Jawa      4     4\n4          4 Jawa Barat Jawa      4     4\n5          5 Jawa Timur Jawa      4     4\n6          6 Jawa Timur Jawa      4     4\n\n\n\nstr(datasem)\n\ntibble [300 × 45] (S3: tbl_df/tbl/data.frame)\n $ Perusahaan: num [1:300] 1 2 3 4 5 6 7 8 9 10 ...\n $ Provinsi  : chr [1:300] \"Jawa Barat\" \"Jawa Timur\" \"Jawa Timur\" \"Jawa Barat\" ...\n $ Pulau     : chr [1:300] \"Jawa\" \"Jawa\" \"Jawa\" \"Jawa\" ...\n $ A1        : num [1:300] 4 5 4 4 4 4 4 5 4 5 ...\n $ A2        : num [1:300] 5 5 4 4 4 4 4 5 4 5 ...\n $ A3        : num [1:300] 5 5 4 3 4 5 4 5 3 5 ...\n $ A4        : num [1:300] 4 5 4 4 3 4 4 5 3 5 ...\n $ A5        : num [1:300] 4 4 4 4 4 4 4 5 3 5 ...\n $ A6        : num [1:300] 4 5 4 4 4 4 4 5 3 4 ...\n $ A7        : num [1:300] 5 5 5 4 4 4 4 5 3 5 ...\n $ A8        : num [1:300] 5 5 5 4 4 4 4 5 3 4 ...\n $ Atotal    : num [1:300] 36 39 34 31 31 33 32 40 26 38 ...\n $ B1        : num [1:300] 4 4 4 4 3 5 3 3 3 4 ...\n $ B2        : num [1:300] 4 4 4 3 4 4 3 3 2 4 ...\n $ Btotal    : num [1:300] 8 8 8 7 7 9 6 6 5 8 ...\n $ C1        : num [1:300] 4 4 4 4 4 4 4 5 3 4 ...\n $ C2        : num [1:300] 4 4 4 4 4 4 4 4 3 4 ...\n $ Ctotal    : num [1:300] 8 8 8 8 8 8 8 9 6 8 ...\n $ D1        : num [1:300] 4 5 4 4 4 4 4 4 3 4 ...\n $ D2        : num [1:300] 4 5 4 3 4 5 4 4 2 4 ...\n $ D3        : num [1:300] 4 5 4 4 4 4 4 4 3 4 ...\n $ D4        : num [1:300] 4 5 4 5 4 4 4 4 3 4 ...\n $ Dtotal    : num [1:300] 16 20 16 16 16 17 16 16 11 16 ...\n $ E1        : num [1:300] 5 5 4 4 4 4 4 4 3 5 ...\n $ E2        : num [1:300] 5 5 4 4 4 5 4 4 3 5 ...\n $ E3        : num [1:300] 5 5 4 4 4 5 4 5 4 5 ...\n $ E4        : num [1:300] 4 5 4 3 4 5 4 4 3 4 ...\n $ E5        : num [1:300] 4 5 4 4 3 5 4 4 3 4 ...\n $ E6        : num [1:300] 4 5 4 4 4 4 4 4 3 4 ...\n $ E7        : num [1:300] 4 5 4 4 4 5 4 4 3 4 ...\n $ E8        : num [1:300] 4 5 4 4 3 5 4 4 3 4 ...\n $ E9        : num [1:300] 4 5 4 4 4 4 4 4 3 4 ...\n $ E10       : num [1:300] 4 5 4 4 4 5 4 5 3 4 ...\n $ E11       : num [1:300] 4 5 4 3 3 5 4 5 3 4 ...\n $ E12       : num [1:300] 5 5 4 4 4 5 4 5 3 5 ...\n $ Etotal    : num [1:300] 52 60 48 46 45 57 48 52 37 52 ...\n $ F1        : num [1:300] 5 5 4 4 4 5 4 4 2 4 ...\n $ F2        : num [1:300] 4 5 4 4 4 5 4 4 3 3 ...\n $ F3        : num [1:300] 4 5 4 4 4 4 4 4 2 3 ...\n $ F4        : num [1:300] 4 5 4 4 4 5 4 5 3 4 ...\n $ F5        : num [1:300] 4 5 4 4 3 5 4 4 3 3 ...\n $ F6        : num [1:300] 4 5 4 4 3 4 4 5 3 4 ...\n $ F7        : num [1:300] 4 5 4 4 3 4 4 4 3 4 ...\n $ F8        : num [1:300] 4 5 4 4 4 5 4 4 3 4 ...\n $ Ftotal    : num [1:300] 33 40 32 32 29 37 32 34 22 29 ...\n\n\n\nattach(datasem)\ntable(A1)\n\nA1\n  1   2   3   4   5 \n  3   4  37 121 135 \n\n\n\nbarplot(table(A1))\n\n\n\n\n\n\n\n\n\n# Spesifikasi Model\nsem.model = \"\nfaktor =~ A1 + A2 + A3 + A4\npermintaan =~ B1 + B2  \nindustri =~ C1 + C2  \nstrategi =~ D1 + D2 + D3 + D4\nregulasi =~ E1 + E2 + E3 + E4 + E5 + E6\nkesempatan =~ F1 + F2 + F3 + F4\nkesempatan ~ faktor + permintaan + industri + strategi + regulasi\"\n\n\nsem.fit = sem(sem.model, data = datasem)\nsummary(sem.fit, fit.measures=TRUE)\n\nlavaan 0.6-19 ended normally after 90 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        59\n\n  Number of observations                           300\n\nModel Test User Model:\n                                                      \n  Test statistic                               555.757\n  Degrees of freedom                               194\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              7355.210\n  Degrees of freedom                               231\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.949\n  Tucker-Lewis Index (TLI)                       0.940\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4608.159\n  Loglikelihood unrestricted model (H1)      -4330.280\n                                                      \n  Akaike (AIC)                                9334.318\n  Bayesian (BIC)                              9552.841\n  Sample-size adjusted Bayesian (SABIC)       9365.728\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.079\n  90 Percent confidence interval - lower         0.071\n  90 Percent confidence interval - upper         0.087\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.410\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.035\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  faktor =~                                           \n    A1                1.000                           \n    A2                1.266    0.089   14.271    0.000\n    A3                1.312    0.094   13.991    0.000\n    A4                1.261    0.091   13.913    0.000\n  permintaan =~                                       \n    B1                1.000                           \n    B2                1.020    0.063   16.072    0.000\n  industri =~                                         \n    C1                1.000                           \n    C2                1.035    0.044   23.446    0.000\n  strategi =~                                         \n    D1                1.000                           \n    D2                0.973    0.033   29.472    0.000\n    D3                0.972    0.043   22.590    0.000\n    D4                0.817    0.042   19.325    0.000\n  regulasi =~                                         \n    E1                1.000                           \n    E2                0.929    0.039   23.666    0.000\n    E3                0.950    0.043   22.088    0.000\n    E4                1.015    0.039   25.697    0.000\n    E5                0.985    0.042   23.464    0.000\n    E6                0.913    0.045   20.186    0.000\n  kesempatan =~                                       \n    F1                1.000                           \n    F2                1.006    0.038   26.712    0.000\n    F3                1.033    0.042   24.672    0.000\n    F4                0.943    0.046   20.414    0.000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  kesempatan ~                                        \n    faktor            0.016    0.111    0.146    0.884\n    permintaan        0.042    0.059    0.705    0.481\n    industri          0.129    0.133    0.976    0.329\n    strategi          0.131    0.091    1.449    0.147\n    regulasi          0.685    0.077    8.860    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  faktor ~~                                           \n    permintaan        0.233    0.034    6.785    0.000\n    industri          0.327    0.037    8.729    0.000\n    strategi          0.292    0.035    8.242    0.000\n    regulasi          0.343    0.039    8.730    0.000\n  permintaan ~~                                       \n    industri          0.366    0.043    8.447    0.000\n    strategi          0.391    0.045    8.713    0.000\n    regulasi          0.332    0.043    7.797    0.000\n  industri ~~                                         \n    strategi          0.437    0.043   10.274    0.000\n    regulasi          0.416    0.043    9.764    0.000\n  strategi ~~                                         \n    regulasi          0.405    0.042    9.580    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .A1                0.323    0.029   11.229    0.000\n   .A2                0.161    0.018    8.902    0.000\n   .A3                0.205    0.022    9.430    0.000\n   .A4                0.198    0.021    9.552    0.000\n   .B1                0.269    0.032    8.457    0.000\n   .B2                0.078    0.025    3.161    0.002\n   .C1                0.122    0.014    8.515    0.000\n   .C2                0.106    0.014    7.549    0.000\n   .D1                0.093    0.011    8.749    0.000\n   .D2                0.063    0.008    7.476    0.000\n   .D3                0.182    0.017   10.625    0.000\n   .D4                0.200    0.018   11.219    0.000\n   .E1                0.145    0.014   10.563    0.000\n   .E2                0.114    0.011   10.395    0.000\n   .E3                0.156    0.014   10.845    0.000\n   .E4                0.091    0.010    9.488    0.000\n   .E5                0.133    0.013   10.462    0.000\n   .E6                0.198    0.018   11.224    0.000\n   .F1                0.139    0.014    9.697    0.000\n   .F2                0.090    0.011    8.221    0.000\n   .F3                0.140    0.015    9.540    0.000\n   .F4                0.233    0.021   10.912    0.000\n    faktor            0.321    0.047    6.841    0.000\n    permintaan        0.525    0.065    8.048    0.000\n    industri          0.480    0.049    9.751    0.000\n    strategi          0.522    0.050   10.406    0.000\n    regulasi          0.542    0.055    9.811    0.000\n   .kesempatan        0.122    0.015    8.068    0.000\n\n\n\nsem.fit = sem(sem.model, data = datasem, std.lv=TRUE)\nsummary(sem.fit, fit.measures=TRUE, standardized=TRUE)\n\nlavaan 0.6-19 ended normally after 90 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        59\n\n  Number of observations                           300\n\nModel Test User Model:\n                                                      \n  Test statistic                               555.757\n  Degrees of freedom                               194\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              7355.210\n  Degrees of freedom                               231\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.949\n  Tucker-Lewis Index (TLI)                       0.940\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4608.159\n  Loglikelihood unrestricted model (H1)      -4330.280\n                                                      \n  Akaike (AIC)                                9334.318\n  Bayesian (BIC)                              9552.841\n  Sample-size adjusted Bayesian (SABIC)       9365.728\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.079\n  90 Percent confidence interval - lower         0.071\n  90 Percent confidence interval - upper         0.087\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.410\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.035\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  faktor =~                                                             \n    A1                0.566    0.041   13.681    0.000    0.566    0.706\n    A2                0.717    0.038   18.699    0.000    0.717    0.872\n    A3                0.743    0.041   18.064    0.000    0.743    0.854\n    A4                0.714    0.040   17.894    0.000    0.714    0.849\n  permintaan =~                                                         \n    B1                0.725    0.045   16.097    0.000    0.725    0.813\n    B2                0.739    0.038   19.509    0.000    0.739    0.935\n  industri =~                                                           \n    C1                0.692    0.036   19.503    0.000    0.692    0.893\n    C2                0.717    0.036   20.132    0.000    0.717    0.911\n  strategi =~                                                           \n    D1                0.723    0.035   20.812    0.000    0.723    0.922\n    D2                0.703    0.033   21.615    0.000    0.703    0.941\n    D3                0.702    0.038   18.344    0.000    0.702    0.855\n    D4                0.590    0.036   16.459    0.000    0.590    0.797\n  regulasi =~                                                           \n    E1                0.736    0.038   19.623    0.000    0.736    0.888\n    E2                0.684    0.034   19.941    0.000    0.684    0.897\n    E3                0.699    0.037   18.967    0.000    0.699    0.870\n    E4                0.747    0.035   21.120    0.000    0.747    0.927\n    E5                0.725    0.037   19.819    0.000    0.725    0.894\n    E6                0.673    0.038   17.720    0.000    0.673    0.834\n  kesempatan =~                                                         \n    F1                0.350    0.022   16.135    0.000    0.771    0.900\n    F2                0.352    0.021   16.722    0.000    0.776    0.933\n    F3                0.361    0.022   16.227    0.000    0.796    0.905\n    F4                0.330    0.022   14.833    0.000    0.727    0.833\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  kesempatan ~                                                          \n    faktor            0.026    0.180    0.146    0.884    0.012    0.012\n    permintaan        0.086    0.123    0.705    0.481    0.039    0.039\n    industri          0.256    0.263    0.973    0.331    0.116    0.116\n    strategi          0.272    0.188    1.447    0.148    0.123    0.123\n    regulasi          1.443    0.190    7.608    0.000    0.654    0.654\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  faktor ~~                                                             \n    permintaan        0.568    0.046   12.297    0.000    0.568    0.568\n    industri          0.833    0.025   33.258    0.000    0.833    0.833\n    strategi          0.715    0.033   21.548    0.000    0.715    0.715\n    regulasi          0.822    0.023   35.175    0.000    0.822    0.822\n  permintaan ~~                                                         \n    industri          0.729    0.035   20.610    0.000    0.729    0.729\n    strategi          0.746    0.032   23.194    0.000    0.746    0.746\n    regulasi          0.623    0.041   15.291    0.000    0.623    0.623\n  industri ~~                                                           \n    strategi          0.874    0.020   44.744    0.000    0.874    0.874\n    regulasi          0.816    0.024   33.446    0.000    0.816    0.816\n  strategi ~~                                                           \n    regulasi          0.762    0.027   27.976    0.000    0.762    0.762\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .A1                0.323    0.029   11.229    0.000    0.323    0.502\n   .A2                0.161    0.018    8.902    0.000    0.161    0.239\n   .A3                0.205    0.022    9.430    0.000    0.205    0.271\n   .A4                0.198    0.021    9.552    0.000    0.198    0.280\n   .B1                0.269    0.032    8.457    0.000    0.269    0.339\n   .B2                0.078    0.025    3.161    0.002    0.078    0.126\n   .C1                0.122    0.014    8.515    0.000    0.122    0.203\n   .C2                0.106    0.014    7.549    0.000    0.106    0.171\n   .D1                0.093    0.011    8.749    0.000    0.093    0.151\n   .D2                0.063    0.008    7.476    0.000    0.063    0.114\n   .D3                0.182    0.017   10.625    0.000    0.182    0.270\n   .D4                0.200    0.018   11.219    0.000    0.200    0.365\n   .E1                0.145    0.014   10.563    0.000    0.145    0.211\n   .E2                0.114    0.011   10.395    0.000    0.114    0.195\n   .E3                0.156    0.014   10.845    0.000    0.156    0.242\n   .E4                0.091    0.010    9.488    0.000    0.091    0.141\n   .E5                0.133    0.013   10.462    0.000    0.133    0.201\n   .E6                0.198    0.018   11.224    0.000    0.198    0.304\n   .F1                0.139    0.014    9.697    0.000    0.139    0.190\n   .F2                0.090    0.011    8.221    0.000    0.090    0.130\n   .F3                0.140    0.015    9.540    0.000    0.140    0.181\n   .F4                0.233    0.021   10.912    0.000    0.233    0.306\n    faktor            1.000                               1.000    1.000\n    permintaan        1.000                               1.000    1.000\n    industri          1.000                               1.000    1.000\n    strategi          1.000                               1.000    1.000\n    regulasi          1.000                               1.000    1.000\n   .kesempatan        1.000                               0.206    0.206\n\n\n\n#sem.fit = sem(sem.model, data = datasem, std.lv=TRUE, orthogonal=TRUE)\n#summary(sem.fit, fit.measures=TRUE, standardized=TRUE)\n\n\n# Modification Indices\nmodificationIndices(sem.fit, minimum.value = 10)\n\n           lhs op rhs     mi    epc sepc.lv sepc.all sepc.nox\n72      faktor =~  D3 10.792  0.143   0.143    0.174    0.174\n82      faktor =~  F3 14.022 -0.170  -0.170   -0.193   -0.193\n99  permintaan =~  E6 13.919  0.142   0.142    0.176    0.176\n112   industri =~  D3 19.393  0.315   0.315    0.383    0.383\n134   strategi =~  E3 11.975 -0.144  -0.144   -0.179   -0.179\n152   regulasi =~  D3 18.808  0.197   0.197    0.240    0.240\n157   regulasi =~  F4 13.142  0.272   0.272    0.312    0.312\n168 kesempatan =~  D3 22.896  0.100   0.220    0.268    0.268\n175 kesempatan =~  E6 25.214  0.153   0.337    0.418    0.418\n176         A1 ~~  A2 15.863  0.068   0.068    0.298    0.298\n270         B1 ~~  F4 14.265  0.063   0.063    0.253    0.253\n317         D1 ~~  D3 10.752 -0.035  -0.035   -0.272   -0.272\n331         D2 ~~  E1 11.098  0.025   0.025    0.257    0.257\n347         D3 ~~  E6 12.029  0.042   0.042    0.223    0.223\n351         D3 ~~  F4 10.217 -0.043  -0.043   -0.208   -0.208\n352         D4 ~~  E1 11.953 -0.038  -0.038   -0.223   -0.223\n362         E1 ~~  E2 17.329  0.038   0.038    0.294    0.294\n363         E1 ~~  E3 10.360  0.033   0.033    0.220    0.220\n364         E1 ~~  E4 12.186 -0.031  -0.031   -0.266   -0.266\n371         E2 ~~  E3 11.663  0.032   0.032    0.236    0.236\n373         E2 ~~  E5 10.449 -0.028  -0.028   -0.231   -0.231\n381         E3 ~~  E6 11.439 -0.039  -0.039   -0.221   -0.221\n386         E4 ~~  E5 25.380  0.043   0.043    0.388    0.388\n398         E6 ~~  F2 14.478 -0.037  -0.037   -0.275   -0.275\n399         E6 ~~  F3 20.998  0.052   0.052    0.310    0.310\n405         F2 ~~  F4 24.019 -0.058  -0.058   -0.404   -0.404\n406         F3 ~~  F4 14.294  0.050   0.050    0.279    0.279\n\n\n\nsem.model2 = \"\nfaktor =~ A1 + A2 + A3 + A4\npermintaan =~ B1 + B2  \nindustri =~ C1 + C2  \nstrategi =~ D1 + D2 + D3 + D4\nregulasi =~ E1 + E2 + E3 + E4 + E5 + E6\nkesempatan =~ F1 + F2 + F3 + F4\nkesempatan ~ faktor + permintaan + industri + strategi + regulasi\nA1  ~~  A2\n\"\n\n\nsem.fit = sem(sem.model2, data = datasem, std.lv=TRUE)\nsummary(sem.fit, fit.measures=TRUE, standardized=TRUE)\n\nlavaan 0.6-19 ended normally after 94 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        60\n\n  Number of observations                           300\n\nModel Test User Model:\n                                                      \n  Test statistic                               540.535\n  Degrees of freedom                               193\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              7355.210\n  Degrees of freedom                               231\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.951\n  Tucker-Lewis Index (TLI)                       0.942\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4600.548\n  Loglikelihood unrestricted model (H1)      -4330.280\n                                                      \n  Akaike (AIC)                                9321.095\n  Bayesian (BIC)                              9543.322\n  Sample-size adjusted Bayesian (SABIC)       9353.038\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.077\n  90 Percent confidence interval - lower         0.070\n  90 Percent confidence interval - upper         0.085\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.303\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.035\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  faktor =~                                                             \n    A1                0.539    0.043   12.660    0.000    0.539    0.672\n    A2                0.702    0.039   18.009    0.000    0.702    0.854\n    A3                0.752    0.041   18.363    0.000    0.752    0.864\n    A4                0.720    0.040   18.060    0.000    0.720    0.855\n  permintaan =~                                                         \n    B1                0.724    0.045   16.093    0.000    0.724    0.813\n    B2                0.739    0.038   19.507    0.000    0.739    0.935\n  industri =~                                                           \n    C1                0.692    0.036   19.469    0.000    0.692    0.892\n    C2                0.717    0.036   20.171    0.000    0.717    0.912\n  strategi =~                                                           \n    D1                0.723    0.035   20.813    0.000    0.723    0.922\n    D2                0.703    0.033   21.613    0.000    0.703    0.941\n    D3                0.702    0.038   18.345    0.000    0.702    0.855\n    D4                0.590    0.036   16.460    0.000    0.590    0.797\n  regulasi =~                                                           \n    E1                0.736    0.038   19.615    0.000    0.736    0.888\n    E2                0.684    0.034   19.943    0.000    0.684    0.897\n    E3                0.699    0.037   18.964    0.000    0.699    0.870\n    E4                0.747    0.035   21.115    0.000    0.747    0.927\n    E5                0.726    0.037   19.826    0.000    0.726    0.894\n    E6                0.673    0.038   17.728    0.000    0.673    0.834\n  kesempatan =~                                                         \n    F1                0.350    0.022   16.137    0.000    0.771    0.900\n    F2                0.352    0.021   16.726    0.000    0.776    0.933\n    F3                0.361    0.022   16.232    0.000    0.796    0.905\n    F4                0.330    0.022   14.836    0.000    0.727    0.833\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  kesempatan ~                                                          \n    faktor            0.031    0.186    0.167    0.867    0.014    0.014\n    permintaan        0.087    0.122    0.709    0.478    0.039    0.039\n    industri          0.253    0.267    0.947    0.344    0.115    0.115\n    strategi          0.272    0.189    1.442    0.149    0.123    0.123\n    regulasi          1.441    0.190    7.578    0.000    0.654    0.654\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .A1 ~~                                                                 \n   .A2                0.068    0.019    3.588    0.000    0.068    0.269\n  faktor ~~                                                             \n    permintaan        0.573    0.046   12.417    0.000    0.573    0.573\n    industri          0.837    0.025   33.458    0.000    0.837    0.837\n    strategi          0.716    0.033   21.421    0.000    0.716    0.716\n    regulasi          0.824    0.024   34.919    0.000    0.824    0.824\n  permintaan ~~                                                         \n    industri          0.729    0.035   20.581    0.000    0.729    0.729\n    strategi          0.746    0.032   23.189    0.000    0.746    0.746\n    regulasi          0.623    0.041   15.292    0.000    0.623    0.623\n  industri ~~                                                           \n    strategi          0.874    0.020   44.757    0.000    0.874    0.874\n    regulasi          0.816    0.024   33.429    0.000    0.816    0.816\n  strategi ~~                                                           \n    regulasi          0.762    0.027   27.982    0.000    0.762    0.762\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .A1                0.353    0.032   11.133    0.000    0.353    0.549\n   .A2                0.182    0.020    9.132    0.000    0.182    0.270\n   .A3                0.192    0.022    8.905    0.000    0.192    0.253\n   .A4                0.190    0.021    9.171    0.000    0.190    0.268\n   .B1                0.270    0.032    8.454    0.000    0.270    0.339\n   .B2                0.078    0.025    3.155    0.002    0.078    0.125\n   .C1                0.123    0.014    8.573    0.000    0.123    0.205\n   .C2                0.104    0.014    7.494    0.000    0.104    0.169\n   .D1                0.093    0.011    8.748    0.000    0.093    0.151\n   .D2                0.063    0.008    7.481    0.000    0.063    0.114\n   .D3                0.182    0.017   10.624    0.000    0.182    0.270\n   .D4                0.200    0.018   11.218    0.000    0.200    0.365\n   .E1                0.145    0.014   10.565    0.000    0.145    0.211\n   .E2                0.114    0.011   10.392    0.000    0.114    0.195\n   .E3                0.157    0.014   10.844    0.000    0.157    0.242\n   .E4                0.092    0.010    9.490    0.000    0.092    0.141\n   .E5                0.132    0.013   10.456    0.000    0.132    0.201\n   .E6                0.197    0.018   11.222    0.000    0.197    0.304\n   .F1                0.140    0.014    9.700    0.000    0.140    0.190\n   .F2                0.090    0.011    8.219    0.000    0.090    0.130\n   .F3                0.140    0.015    9.538    0.000    0.140    0.181\n   .F4                0.233    0.021   10.912    0.000    0.233    0.306\n    faktor            1.000                               1.000    1.000\n    permintaan        1.000                               1.000    1.000\n    industri          1.000                               1.000    1.000\n    strategi          1.000                               1.000    1.000\n    regulasi          1.000                               1.000    1.000\n   .kesempatan        1.000                               0.206    0.206\n\n\n\n8.2.1 Visualisasi SEM\n\nsemPaths(sem.fit)\n\n\n\n\n\n\n\n\n\nsemPaths(sem.fit, \"std\", \n         color = list(lat = \"green\", man = \"yellow\"), \n         edge.color=\"black\")\n\n\n\n\n\n\n\n\n\nsemPaths(sem.fit, \"std\", \n         color = list(lat = \"green\", man = \"yellow\"), \n         edge.color=\"black\", fade=FALSE)\n\n\n\n\n\n\n\n\n\nsemPaths(sem.fit, \"std\", \n         color = list(lat = \"green\", man = \"yellow\"), \n         edge.color=\"black\", \n         fade=FALSE, residuals=FALSE, exoCov=FALSE)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Factor Analysis and Structural Equation Modeling (SEM)</span>"
    ]
  },
  {
    "objectID": "07-Bab7.html#pls-sem",
    "href": "07-Bab7.html#pls-sem",
    "title": "8  Factor Analysis and Structural Equation Modeling (SEM)",
    "section": "8.3 PLS SEM",
    "text": "8.3 PLS SEM\n\n# source:https://rpubs.com/ifn1411/PLS\n# install plspm\n#install.packages(\"plspm\")\n# load plspm\nlibrary(plspm)\n\n\n# load data spainmodel\ndata(spainfoot)\n# first 5 row of spainmodel data\nhead(spainfoot)\n\n           GSH GSA  SSH  SSA GCH GCA  CSH  CSA WMH WMA LWR LRWL  YC RC\nBarcelona   61  44 0.95 0.95  14  21 0.47 0.32  14  13  10   22  76  6\nRealMadrid  49  34 1.00 0.84  29  23 0.37 0.37  14  11  10   18 115  9\nSevilla     28  26 0.74 0.74  20  19 0.42 0.53  11  10   4    7 100  8\nAtleMadrid  47  33 0.95 0.84  23  34 0.37 0.16  13   7   6    9 116  5\nVillarreal  33  28 0.84 0.68  25  29 0.26 0.16  12   6   5   11 102  5\nValencia    47  21 1.00 0.68  26  28 0.26 0.26  12   6   5    8 120  6\n\n\n\nAttack &lt;-  c(0, 0, 0)\nDefense &lt;- c(1, 0, 0)\nSuccess &lt;- c(1, 0, 0)\n\nmodel_path &lt;- rbind(Attack, Defense, Success)\ncolnames(model_path) &lt;- rownames(model_path)\n\nmodel_path\n\n        Attack Defense Success\nAttack       0       0       0\nDefense      1       0       0\nSuccess      1       0       0\n\n\n\n# graph structural model\ninnerplot(model_path)\n\n\n\n\n\n\n\n\n\nAttack &lt;-  c(0, 1, 0)\nDefense &lt;- c(0, 0, 0)\nSuccess &lt;- c(1, 1, 0)\n\nmodel_path2 &lt;- rbind(Attack, Defense, Success)\ncolnames(model_path2) &lt;- rownames(model_path2)\n\nmodel_path2\n\n        Attack Defense Success\nAttack       0       1       0\nDefense      0       0       0\nSuccess      1       1       0\n\n\n\n# graph structural model\ninnerplot(model_path2, txt.col = \"black\")\n\n\n\n\n\n\n\n\n\n# define latent variable associated with\nmodel_blocks &lt;- list(1:4, 5:8, 9:12)\n\n# vector of modes (reflective)\nmodel_modes &lt;- c(\"A\", \"A\", \"A\")\n\n# run plspm analysis\nmodel_pls &lt;- plspm(Data = spainfoot, path_matrix = model_path, blocks = model_blocks, modes = model_modes)\n\nmodel_pls\n\nPartial Least Squares Path Modeling (PLS-PM) \n---------------------------------------------\n   NAME             DESCRIPTION\n1  $outer_model     outer model\n2  $inner_model     inner model\n3  $path_coefs      path coefficients matrix\n4  $scores          latent variable scores\n5  $crossloadings   cross-loadings\n6  $inner_summary   summary inner model\n7  $effects         total effects\n8  $unidim          unidimensionality\n9  $gof             goodness-of-fit\n10 $boot            bootstrap results\n11 $data            data matrix\n---------------------------------------------\nYou can also use the function 'summary' \n\n\n\n# Unidimensionality\nmodel_pls$unidim\n\n        Mode MVs   C.alpha     DG.rho  eig.1st   eig.2nd\nAttack     A   4 0.8905919 0.92456079 3.017160 0.7923055\nDefense    A   4 0.0000000 0.02601677 2.393442 1.1752781\nSuccess    A   4 0.9165491 0.94232868 3.217294 0.5370492\n\n\n\nplot(model_pls, what = \"loadings\")\n\n\n\n\n\n\n\n\n\n# Loadings and Communilaties\nmodel_pls$outer_model\n\n   name   block     weight    loading communality redundancy\n1   GSH  Attack  0.3474771  0.9412506   0.8859527 0.00000000\n2   GSA  Attack  0.2671782  0.8562398   0.7331465 0.00000000\n3   SSH  Attack  0.2922077  0.8466039   0.7167381 0.00000000\n4   SSA  Attack  0.2396012  0.8212987   0.6745316 0.00000000\n5   GCH Defense -0.1198790  0.4762965   0.2268583 0.05071506\n6   GCA Defense -0.4264164  0.8885714   0.7895590 0.17650898\n7   CSH Defense  0.2949470 -0.7297095   0.5324759 0.11903706\n8   CSA Defense  0.3898039 -0.8947452   0.8005689 0.17897028\n9   WMH Success  0.2484276  0.7884562   0.6216632 0.49452090\n10  WMA Success  0.2691511  0.8747163   0.7651285 0.60864477\n11  LWR Success  0.2947322  0.9703409   0.9415614 0.74899365\n12 LRWL Success  0.2998524  0.9428112   0.8888929 0.70709694\n\n\n\n# Crossloadings\nmodel_pls$crossloadings\n\n   name   block     Attack    Defense    Success\n1   GSH  Attack  0.9412506 -0.5139001  0.9019257\n2   GSA  Attack  0.8562398 -0.3403294  0.7483558\n3   SSH  Attack  0.8466039 -0.4124617  0.7781795\n4   SSA  Attack  0.8212987 -0.3455460  0.6308989\n5   GCH Defense -0.1302683  0.4762965 -0.1620567\n6   GCA Defense -0.4633220  0.8885714 -0.5640722\n7   CSH Defense  0.3204993 -0.7297095  0.4850456\n8   CSA Defense  0.4235465 -0.8947452  0.5811253\n9   WMH Success  0.7126127 -0.4120502  0.7884562\n10  WMA Success  0.7720228 -0.7147787  0.8747163\n11  LWR Success  0.8454164 -0.5345709  0.9703409\n12 LRWL Success  0.8600973 -0.5910943  0.9428112\n\n\n\n# Coefficient of Determination\nmodel_pls$inner_model\n\n$Defense\n               Estimate Std. Error       t value   Pr(&gt;|t|)\nIntercept  5.504973e-17  0.2076918  2.650549e-16 1.00000000\nAttack    -4.728148e-01  0.2076918 -2.276521e+00 0.03526176\n\n$Success\n              Estimate Std. Error      t value     Pr(&gt;|t|)\nIntercept 7.783183e-17  0.1065936 7.301735e-16 1.000000e+00\nAttack    8.918971e-01  0.1065936 8.367266e+00 1.285711e-07\n\n\n\n# Redundancy\nmodel_pls$inner_summary\n\n              Type        R2 Block_Communality Mean_Redundancy       AVE\nAttack   Exogenous 0.0000000         0.7525922       0.0000000 0.7525922\nDefense Endogenous 0.2235539         0.5873656       0.1313078 0.5873656\nSuccess Endogenous 0.7954804         0.8043115       0.6398141 0.8043115\n\n\n\n# Goodness-of-fit\nmodel_pls$gof\n\n[1] 0.6034738\n\n\n\nplot(model_pls, what = \"inner\", colpos = \"#6890c4BB\", colneg = \"#f9675dBB\", txt.col = \"black\", arr.tcol=\"black\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Factor Analysis and Structural Equation Modeling (SEM)</span>"
    ]
  },
  {
    "objectID": "08-Bab8.html",
    "href": "08-Bab8.html",
    "title": "9  Analytic Hierarchy Process (AHP)",
    "section": "",
    "text": "9.1 Prosedur Pengolahan AHP",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Analytic Hierarchy Process (AHP)</span>"
    ]
  },
  {
    "objectID": "08-Bab8.html#prosedur-pengolahan-ahp",
    "href": "08-Bab8.html#prosedur-pengolahan-ahp",
    "title": "9  Analytic Hierarchy Process (AHP)",
    "section": "",
    "text": "9.1.1 Data\n\nahpdata &lt;- read.csv(\"Data/ahp.csv\")\nahpdata\n\n  Responden SAL_QL SAL_IW SAL_LC QL_IW QL_LC IW_LC J1_J2 J1_j3 J2_J3 J1_J2.1\n1         1     -5     -2     -4     2     2    -2    -2    -4    -2       2\n2         2     -7     -3     -3     3     3    -4    -3    -7    -1       3\n  J1_j3.1 J2_J3.1 J1_J2.2 J1_j3.2 J2_J3.2 J1_J2.3 J1_j3.3 J2_J3.3\n1       3       3       7       3      -3       4       7      -2\n2       3       3       4      -1      -3       5       2      -4\n\n\n\n\n9.1.2 Analisis\n\n9.1.2.1 Faktor\n\n# Mendefinisikan faktor\nfaktor &lt;- c(\"SAL\", \"QL\", \"IW\", \"LC\")\n# Menampilkan data frame\nfaktor_data &lt;- ahpdata[, 2:7]\nfaktor_data\n\n  SAL_QL SAL_IW SAL_LC QL_IW QL_LC IW_LC\n1     -5     -2     -4     2     2    -2\n2     -7     -3     -3     3     3    -4\n\n\n\n# install.packages(\"ahpsurvey\")\nlibrary(ahpsurvey)\nfaktor_data_mat &lt;- ahp.mat(df = faktor_data, faktor, \n                           negconvert = TRUE)\nfaktor_data_mat\n\n[[1]]\n     SAL QL  IW  LC\nSAL 1.00  5 2.0 4.0\nQL  0.20  1 0.5 0.5\nIW  0.50  2 1.0 2.0\nLC  0.25  2 0.5 1.0\n\n[[2]]\n          SAL QL        IW        LC\nSAL 1.0000000  7 3.0000000 3.0000000\nQL  0.1428571  1 0.3333333 0.3333333\nIW  0.3333333  3 1.0000000 4.0000000\nLC  0.3333333  3 0.2500000 1.0000000\n\n\n\n# Consistency\nri &lt;- ahp.ri(nsims = 10000, dim = 4, seed = 42)\nahp.cr(faktor_data_mat, faktor, ri)\n\n[1] 0.01780548 0.09677931\n\n\n\n#Treatement Consistency (Jika Tidak Konsisten)\n#faktor_data_mat &lt;- ahp.harker(faktor_data_mat, faktor, iterations = 10, stopcr = 0.1)\n#ahp.cr(faktor_data_mat, faktor)\n\nThe ahp.cr function calculates the consistency ratio of each decision-maker, defined by the following equation:\nCR = (λ − n)/((n − 1)(RI))\nWhere λ is the maximum eigenvalue of the pairwise comparison matrix, n is the number of attributes, and RI is the random index. Following Saaty and Tran (2007), the RI is a function of n and is the consistency ratio of randomly generated pairwise comparison matrices.\nSaaty showed that when the CR is higher than 0.1, the choice is deemed to be inconsistent\n\n\n9.1.2.2 Individual Rangking Faktor\n\nlibrary(tidyverse)\nlibrary(tibble)\nfaktor_ind &lt;- ahp.indpref(faktor_data_mat, \n                          faktor, \n                          method = \"arithmetic\")\nround(faktor_ind, 3) %&gt;% rownames_to_column('ID')\n\n  ID   SAL    QL    IW    LC\n1  1 0.512 0.099 0.243 0.147\n2  2 0.517 0.066 0.274 0.143\n\n\n\n\n9.1.2.3 Aggregate Rangking Faktor\n\nfaktor_agg &lt;- ahp.aggpref(faktor_data_mat, \n                          faktor, \n                          method = \"arithmetic\", \n                          aggmethod = \"arithmetic\")\nround(faktor_agg, 3) %&gt;% t()\n\n       SAL    QL    IW    LC\n[1,] 0.514 0.082 0.259 0.145\n\n\n\nbarplot(faktor_agg,main=\"Rangking Faktor\")\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\n# Mengubah Cat menjadi factor dengan label yang diinginkan\ndata = data.frame(\"Cat\"=row.names(data.frame(faktor_agg)),\n                  data.frame(faktor_agg))\ndata$Cat &lt;- factor(data$Cat, \n                   levels = c(\"SAL\", \"QL\", \"IW\", \"LC\"),\n                   labels = c(\"Salary\", \"Quality of Life\", \n                              \"Interes in Work\", \"Location\"))\n# Mengurutkan\ndata$warna &lt;- ifelse(data$faktor_agg == \n                       max(data$faktor_agg), \n                     \"terbesar\", \"lainnya\")\n# Buat grafik batang\nggplot(data, aes(x = Cat, \n                 y = faktor_agg, \n                 fill = warna)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = c(\"terbesar\" = \"#4682B4\", \n                               \"lainnya\" = \"#A9A9A9\")) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +  # Sembunyikan legenda\n  labs(\n    title = \"AHP: Rangking Faktor\",\n    y = \"Skor\",\n    x = \"\")\n\n\n\n\n\n\n\n\n\n\n9.1.2.4 Alternatif\n\n\n9.1.2.5 Alternatif untuk Faktor Salary\n\nlibrary(dplyr)\nalternatif &lt;- c(\"J1\", \"J2\", \"J3\")\n\n# Menampilkan data frame\nalternatif_data1 &lt;- ahpdata[,8:10]\nalternatif1 &lt;- ahp.mat(df = alternatif_data1, \n                       atts = alternatif, \n                       negconvert = TRUE)\nalternatif1_agg &lt;- ahp.aggpref(alternatif1, \n                               alternatif, \n                               method = \"arithmetic\", \n                               aggmethod = \"arithmetic\")\nround(alternatif1_agg, 3) %&gt;% t()\n\n        J1    J2    J3\n[1,] 0.628 0.232 0.139\n\n\n\n#Consistency\nri &lt;- ahp.ri(nsims = 10000, dim = 3, seed = 42)\nahp.cr(alternatif1, alternatif, ri)\n\n[1] 0.00000000 0.07669698\n\n\n\n\n9.1.2.6 Alternatif untuk Faktor Quality of Life\n\nalternatif_data2 &lt;- ahpdata[,11:13]\nalternatif2 &lt;- ahp.mat(df = alternatif_data2, \n                       atts = alternatif, \n                       negconvert = TRUE)\nalternatif2_agg &lt;- ahp.aggpref(alternatif2, \n                               alternatif, \n                               method = \"arithmetic\", \n                               aggmethod = \"arithmetic\")\nround(alternatif2_agg, 3) %&gt;% t()\n\n       J1    J2    J3\n[1,] 0.15 0.269 0.581\n\n\n\n#Consistency\nahp.cr(alternatif2, alternatif, ri)\n\n[1] 0.05121571 0.12952632\n\n\n\n\n9.1.2.7 Alternatif untuk Faktor Interest in Work\n\nalternatif_data3 &lt;- ahpdata[,14:16]\nalternatif3 &lt;- ahp.mat(df = alternatif_data3, \n                       atts = alternatif, \n                       negconvert = TRUE)\nalternatif3_agg &lt;- ahp.aggpref(alternatif3, \n                               alternatif, \n                               method = \"arithmetic\", \n                               aggmethod = \"arithmetic\")\nround(alternatif3_agg, 3) %&gt;% t()\n\n        J1    J2    J3\n[1,] 0.132 0.651 0.218\n\n\n\n#Consistency\nahp.cr(alternatif3, alternatif, ri)\n\n[1] 0.006706716 0.008789809\n\n\n\n\n9.1.2.8 Alternatif untuk Faktor Location\n\nalternatif_data4 &lt;- ahpdata[,17:19]\nalternatif4 &lt;- ahp.mat(df = alternatif_data4, \n                       atts = alternatif, \n                       negconvert = TRUE)\nalternatif4_agg &lt;- ahp.aggpref(alternatif4, \n                               alternatif, \n                               method = \"arithmetic\", \n                               aggmethod = \"arithmetic\")\nround(alternatif4_agg, 3) %&gt;% t()\n\n        J1    J2    J3\n[1,] 0.104 0.597 0.299\n\n\n\n#Consistency\nahp.cr(alternatif4, alternatif, ri)\n\n[1] 0.16898990 0.02349155\n\n\n\n\n9.1.2.9 Gabungan Alternatif\n\nalternatif_agg &lt;- cbind(alternatif1_agg,alternatif2_agg,\n                        alternatif3_agg,alternatif4_agg) %*% faktor_agg\nalternatif_agg\n\n        [,1]\nJ1 0.3844544\nJ2 0.3964920\nJ3 0.2190537\n\n\n\nbarplot(t(alternatif_agg) ,main=\"Rangking Alternatif\")\n\n\n\n\n\n\n\n\n\ndata = data.frame(\"Cat\"=row.names(data.frame(alternatif_agg)),\n                  data.frame(alternatif_agg))\ndata$Cat &lt;- factor(data$Cat, \n                   levels = c( \"J1\" , \"J2\" ,\"J3\"),\n                   labels = c(\"Job1\", \"Job2\",\"Job3\"))\n# Buat grafik batang\ndata$warna &lt;- ifelse(data$alternatif_agg == max(data$alternatif_agg), \n                     \"terbesar\", \"lainnya\")\n# Buat grafik batang\nggplot(data, aes(x = Cat, y = alternatif_agg, fill = warna)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = c(\"terbesar\" = \"#4682B4\", \n                               \"lainnya\" = \"#A9A9A9\")) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(\n    title = \"AHP: Rangking Alternatif\",\n    y = \"Skor\",\n    x = \"\")",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Analytic Hierarchy Process (AHP)</span>"
    ]
  }
]